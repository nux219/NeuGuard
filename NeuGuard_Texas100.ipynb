{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# coding: utf-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import argparse\n",
    "import pickle\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "import shutil\n",
    "\n",
    "import time\n",
    "import random\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from utils import Bar, Logger, AverageMeter, accuracy, mkdir_p, savefig\n",
    "from pruned_layers import *\n",
    "import numpy as np\n",
    "from matplotlib import pyplot\n",
    "# from matplotlib import pyplot\n",
    "from matplotlib.pylab import plt\n",
    "\n",
    "from privacy_risk_score_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import urllib\n",
    "import tarfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "use_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "DATASET_PATH = './datasets/texas/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "if not os.path.isdir(DATASET_PATH):\n",
    "    mkdir_p(DATASET_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "DATASET_FEATURES = os.path.join(DATASET_PATH,'texas/100/feats')\n",
    "DATASET_LABELS = os.path.join(DATASET_PATH,'texas/100/labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "if not os.path.isfile(DATASET_FEATURES):\n",
    "    print(\"Dowloading the dataset...\")\n",
    "    urllib.urlretrieve(\"https://www.comp.nus.edu.sg/~reza/files/dataset_texas.tgz\",os.path.join(DATASET_PATH,'tmp.tgz'))\n",
    "    print('Dataset Downloaded')\n",
    "    tar = tarfile.open(os.path.join(DATASET_PATH,'tmp.tgz'))\n",
    "    tar.extractall(path=DATASET_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "X=[]\n",
    "Y=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# data_set_features =np.genfromtxt(DATASET_FEATURES,delimiter=',')\n",
    "# data_set_label =np.genfromtxt(DATASET_LABELS,delimiter=',')\n",
    "\n",
    "# X = data_set_features.astype(np.float64)\n",
    "# Y = data_set_label.astype(np.int32)-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# np.savez('texas100_data', x = X, y = Y)\n",
    "# np.savez('texas100_index', x = init_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "npzdata=np.load('./texas100_data.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "X=npzdata['x'][:,:]\n",
    "Y=npzdata['y'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# np.array_equal(X, X_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# # larger model\n",
    "# class Texas(nn.Module):\n",
    "#     def __init__(self,num_classes=100):\n",
    "#         super(Texas, self).__init__()\n",
    "#         self.features = nn.Sequential(\n",
    "# #             nn.Linear(6169,1024),\n",
    "#             PruneLinear(6169,2048),\n",
    "#             nn.Tanh(),\n",
    "#             PruneLinear(2048,1024),\n",
    "#             nn.Tanh(),\n",
    "#             PruneLinear(1024,512),\n",
    "#             nn.Tanh(),\n",
    "#             PruneLinear(512,256),\n",
    "#             nn.Tanh(),\n",
    "#             PruneLinear(256,128),\n",
    "#             nn.Tanh(),\n",
    "#         )\n",
    "#         self.classifier = nn.Linear(128,num_classes)\n",
    "# #         for key in self.state_dict():\n",
    "# #             if key.split('.')[-1] == 'weight':    \n",
    "# #                 nn.init.normal(self.state_dict()[key], std=0.01)\n",
    "# #                 print (key)\n",
    "                \n",
    "# #             elif key.split('.')[-1] == 'bias':\n",
    "# #                 self.state_dict()[key][...] = 0\n",
    "        \n",
    "#     def forward(self,x):\n",
    "#         hidden_out = self.features(x)\n",
    "        \n",
    "#         return self.classifier(hidden_out),hidden_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# larger model\n",
    "class Texas_layer_out(nn.Module):\n",
    "    def __init__(self,num_classes=100):\n",
    "        super(Texas_layer_out, self).__init__()\n",
    "#         self.features = nn.Sequential(\n",
    "#             nn.Linear(6169,1024),\n",
    "        self.fc1 = PruneLinear(6169,1024)\n",
    "        self.tanh1 = nn.Tanh()\n",
    "#         self.fc2 = PruneLinear(2048,1024)\n",
    "#         self.tanh2 = nn.Tanh()\n",
    "        self.fc3 = PruneLinear(1024,512)\n",
    "        self.tanh3 = nn.Tanh()\n",
    "        self.fc4 = PruneLinear(512,256)\n",
    "        self.tanh4 = nn.Tanh()\n",
    "        self.fc5 = PruneLinear(256,128)\n",
    "        self.tanh5 = nn.Tanh()\n",
    "#         )\n",
    "        self.classifier = nn.Linear(128,num_classes)\n",
    "#         for key in self.state_dict():\n",
    "#             if key.split('.')[-1] == 'weight':    \n",
    "#                 nn.init.normal(self.state_dict()[key], std=0.01)\n",
    "#                 print (key)\n",
    "                \n",
    "#             elif key.split('.')[-1] == 'bias':\n",
    "#                 self.state_dict()[key][...] = 0\n",
    "        \n",
    "    def forward(self,x):\n",
    "        y = self.fc1(x)\n",
    "        y1 = self.tanh1(y)\n",
    "#         y = self.fc2(y1)\n",
    "#         y2 = self.tanh2(y)\n",
    "        y = self.fc3(y1)\n",
    "        y3 = self.tanh3(y)\n",
    "        y = self.fc4(y3)\n",
    "        y4 = self.tanh4(y)\n",
    "        y = self.fc5(y4)\n",
    "        y5 = self.tanh5(y)\n",
    "        output = self.classifier(y5)\n",
    "        \n",
    "        return output, y1, y3, y4, y5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# larger model\n",
    "class Texas_layer_out_scale(nn.Module):\n",
    "    def __init__(self,num_classes=100, q = 100, alpha = 1):\n",
    "        super(Texas_layer_out_scale, self).__init__()\n",
    "#         self.features = nn.Sequential(\n",
    "#             nn.Linear(6169,1024),\n",
    "        self.fc1 = PruneLinear(6169,1024)\n",
    "        self.tanh1 = nn.Tanh()\n",
    "#         self.fc2 = PruneLinear(2048,1024)\n",
    "#         self.tanh2 = nn.Tanh()\n",
    "        self.fc3 = PruneLinear(1024,512)\n",
    "        self.tanh3 = nn.Tanh()\n",
    "        self.fc4 = PruneLinear(512,256)\n",
    "        self.tanh4 = nn.Tanh()\n",
    "        self.fc5 = PruneLinear(256,128)\n",
    "        self.tanh5 = nn.Tanh()\n",
    "#         )\n",
    "        self.classifier = nn.Linear(128,num_classes)\n",
    "    \n",
    "        self.q = q\n",
    "        self.alpha = alpha\n",
    "#         for key in self.state_dict():\n",
    "#             if key.split('.')[-1] == 'weight':    \n",
    "#                 nn.init.normal(self.state_dict()[key], std=0.01)\n",
    "#                 print (key)\n",
    "                \n",
    "#             elif key.split('.')[-1] == 'bias':\n",
    "#                 self.state_dict()[key][...] = 0\n",
    "        \n",
    "    def forward(self,x):\n",
    "        y = self.fc1(x)\n",
    "        y1 = self.tanh1(y)\n",
    "        y1 = scale_by_percentage(y1, q=self.q, alpha = self.alpha)\n",
    "#         y = self.fc2(y1)\n",
    "#         y2 = self.tanh2(y)\n",
    "        y = self.fc3(y1)\n",
    "        y3 = self.tanh3(y)\n",
    "        y3 = scale_by_percentage(y3, q=self.q, alpha = self.alpha)\n",
    "        y = self.fc4(y3)\n",
    "        y4 = self.tanh4(y)\n",
    "        y4 = scale_by_percentage(y4, q=self.q, alpha = self.alpha)\n",
    "        y = self.fc5(y4)\n",
    "        y5 = self.tanh5(y)\n",
    "        y5 = scale_by_percentage(y5, q=self.q, alpha = self.alpha)\n",
    "        output = self.classifier(y5)\n",
    "        \n",
    "        return output, y1, y3, y4, y5\n",
    "\n",
    "    \n",
    "# def scale_by_percentage(x, q=5.0, alpha = 1):\n",
    "#     \"\"\"\n",
    "#     scale paramters by threshold.\n",
    "\n",
    "#     \"\"\"\n",
    "#     temp_shape = x.shape\n",
    "#     weight = x.data.cpu().numpy()\n",
    "#     flattened_weights = np.abs(weight.flatten())\n",
    "#     nonzero = flattened_weights[np.nonzero(flattened_weights)]\n",
    "#     percentile_value = np.percentile(nonzero, q)\n",
    "#     mask = np.ones(flattened_weights.shape)\n",
    "#     new_mask = np.where(flattened_weights >= percentile_value, alpha, mask)\n",
    "#     new_mask = new_mask.reshape(temp_shape)\n",
    "#     new_feature_map = np.asarray(weight * new_mask, dtype=np.float32)\n",
    "#     x.data = torch.from_numpy(new_feature_map).cuda()\n",
    "#     return x\n",
    "\n",
    "def scale_by_percentage(x, q=5.0, alpha = 1):\n",
    "    \"\"\"\n",
    "    scale paramters by threshold.\n",
    "\n",
    "    \"\"\"\n",
    "    temp_shape = x.shape\n",
    "    weight = x.data.cpu().numpy()\n",
    "    flattened_weights = np.abs(weight.flatten())\n",
    "#     flattened_weights = np.abs(weight)\n",
    "#     percentile_value = np.percentile(flattened_weights, q)\n",
    "    nonzero = flattened_weights[np.nonzero(flattened_weights)]\n",
    "    percentile_value  = np.percentile(nonzero, q)\n",
    "    amp = alpha - 1.\n",
    "    \n",
    "    tweight = x.data\n",
    "    new_mask = (tweight >= percentile_value)*amp  + 1.\n",
    "    \n",
    "#     mask = np.ones(flattened_weights.shape)\n",
    "#     new_mask = np.where(flattened_weights >= percentile_value, alpha, mask)\n",
    "\n",
    "##     new_mask = (flattened_weights >= percentile_value)*amp + 1.\n",
    "\n",
    "#     new_mask = new_mask.reshape(temp_shape)\n",
    "#     new_feature_map = np.asarray(weight * new_mask, dtype=np.float32)\n",
    "#     x.data = torch.from_numpy(new_feature_map).cuda()\n",
    "    x.data  = new_mask * tweight\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# larger model\n",
    "class Texas_layer_out_scale2(nn.Module):\n",
    "    def __init__(self,num_classes=100, q = 100, alpha = 1):\n",
    "        super(Texas_layer_out_scale2, self).__init__()\n",
    "#         self.features = nn.Sequential(\n",
    "#             nn.Linear(6169,1024),\n",
    "        self.fc1 = PruneLinear(6169,1024)\n",
    "        self.tanh1 = nn.Tanh()\n",
    "#         self.fc2 = PruneLinear(2048,1024)\n",
    "#         self.tanh2 = nn.Tanh()\n",
    "        self.fc3 = PruneLinear(1024,512)\n",
    "        self.tanh3 = nn.Tanh()\n",
    "        self.fc4 = PruneLinear(512,256)\n",
    "        self.tanh4 = nn.Tanh()\n",
    "        self.fc5 = PruneLinear(256,128)\n",
    "        self.tanh5 = nn.Tanh()\n",
    "#         )\n",
    "        self.classifier = nn.Linear(128,num_classes)\n",
    "    \n",
    "        self.q = q\n",
    "        self.alpha = alpha\n",
    "#         for key in self.state_dict():\n",
    "#             if key.split('.')[-1] == 'weight':    \n",
    "#                 nn.init.normal(self.state_dict()[key], std=0.01)\n",
    "#                 print (key)\n",
    "                \n",
    "#             elif key.split('.')[-1] == 'bias':\n",
    "#                 self.state_dict()[key][...] = 0\n",
    "        \n",
    "    def forward(self,x):\n",
    "        y = self.fc1(x)\n",
    "        y1 = self.tanh1(y)\n",
    "#         y1 = scale_by_percentage(y1, q=self.q, alpha = self.alpha)\n",
    "#         y = self.fc2(y1)\n",
    "#         y2 = self.tanh2(y)\n",
    "        y = self.fc3(y1)\n",
    "        y3 = self.tanh3(y)\n",
    "#         y3 = scale_by_percentage(y3, q=self.q, alpha = self.alpha)\n",
    "        y = self.fc4(y3)\n",
    "        y4 = self.tanh4(y)\n",
    "        y4 = scale_by_percentage(y4, q=self.q, alpha = self.alpha)\n",
    "        y = self.fc5(y4)\n",
    "        y5 = self.tanh5(y)\n",
    "        y5 = scale_by_percentage(y5, q=self.q, alpha = self.alpha)\n",
    "        output = self.classifier(y5)\n",
    "        \n",
    "        return output, y1, y3, y4, y5\n",
    "\n",
    "    \n",
    "# def scale_by_percentage(x, q=5.0, alpha = 1):\n",
    "#     \"\"\"\n",
    "#     scale paramters by threshold.\n",
    "\n",
    "#     \"\"\"\n",
    "#     temp_shape = x.shape\n",
    "#     weight = x.data.cpu().numpy()\n",
    "#     flattened_weights = np.abs(weight.flatten())\n",
    "#     nonzero = flattened_weights[np.nonzero(flattened_weights)]\n",
    "#     percentile_value = np.percentile(nonzero, q)\n",
    "#     mask = np.ones(flattened_weights.shape)\n",
    "#     new_mask = np.where(flattened_weights >= percentile_value, alpha, mask)\n",
    "#     new_mask = new_mask.reshape(temp_shape)\n",
    "#     new_feature_map = np.asarray(weight * new_mask, dtype=np.float32)\n",
    "#     x.data = torch.from_numpy(new_feature_map).cuda()\n",
    "#     return x\n",
    "\n",
    "def scale_by_percentage(x, q=5.0, alpha = 1):\n",
    "    \"\"\"\n",
    "    scale paramters by threshold.\n",
    "\n",
    "    \"\"\"\n",
    "    temp_shape = x.shape\n",
    "    weight = x.data.cpu().numpy()\n",
    "    flattened_weights = np.abs(weight.flatten())\n",
    "#     flattened_weights = np.abs(weight)\n",
    "#     percentile_value = np.percentile(flattened_weights, q)\n",
    "    nonzero = flattened_weights[np.nonzero(flattened_weights)]\n",
    "    percentile_value  = np.percentile(nonzero, q)\n",
    "    amp = alpha - 1.\n",
    "    \n",
    "    tweight = x.data\n",
    "    new_mask = (tweight >= percentile_value)*amp  + 1.\n",
    "    \n",
    "#     mask = np.ones(flattened_weights.shape)\n",
    "#     new_mask = np.where(flattened_weights >= percentile_value, alpha, mask)\n",
    "\n",
    "##     new_mask = (flattened_weights >= percentile_value)*amp + 1.\n",
    "\n",
    "#     new_mask = new_mask.reshape(temp_shape)\n",
    "#     new_feature_map = np.asarray(weight * new_mask, dtype=np.float32)\n",
    "#     x.data = torch.from_numpy(new_feature_map).cuda()\n",
    "    x.data  = new_mask * tweight\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# larger model\n",
    "class Texas_layer_out_scale2_mid(nn.Module):\n",
    "    def __init__(self,num_classes=100, qfc_l = 100,qfc_h = 100, afc_l = 1, afc_h = 1):\n",
    "        super(Texas_layer_out_scale2_mid, self).__init__()\n",
    "#         self.features = nn.Sequential(\n",
    "#             nn.Linear(6169,1024),\n",
    "        self.fc1 = PruneLinear(6169,1024)\n",
    "        self.tanh1 = nn.Tanh()\n",
    "#         self.fc2 = PruneLinear(2048,1024)\n",
    "#         self.tanh2 = nn.Tanh()\n",
    "        self.fc3 = PruneLinear(1024,512)\n",
    "        self.tanh3 = nn.Tanh()\n",
    "        self.fc4 = PruneLinear(512,256)\n",
    "        self.tanh4 = nn.Tanh()\n",
    "        self.fc5 = PruneLinear(256,128)\n",
    "        self.tanh5 = nn.Tanh()\n",
    "#         )\n",
    "        self.classifier = nn.Linear(128,num_classes)\n",
    "    \n",
    "\n",
    "        self.qfc_l = qfc_l\n",
    "        self.qfc_h = qfc_h\n",
    "        \n",
    "        self.afc_l = afc_l\n",
    "        self.afc_h= afc_h\n",
    "#         for key in self.state_dict():\n",
    "#             if key.split('.')[-1] == 'weight':    \n",
    "#                 nn.init.normal(self.state_dict()[key], std=0.01)\n",
    "#                 print (key)\n",
    "                \n",
    "#             elif key.split('.')[-1] == 'bias':\n",
    "#                 self.state_dict()[key][...] = 0\n",
    "        \n",
    "    def forward(self,x):\n",
    "        y = self.fc1(x)\n",
    "        y1 = self.tanh1(y)\n",
    "#         y1 = scale_by_percentage(y1, q=self.q, alpha = self.alpha)\n",
    "#         y = self.fc2(y1)\n",
    "#         y2 = self.tanh2(y)\n",
    "        y = self.fc3(y1)\n",
    "        y3 = self.tanh3(y)\n",
    "#         y3 = scale_by_percentage(y3, q=self.q, alpha = self.alpha)\n",
    "        y = self.fc4(y3)\n",
    "        y4 = self.tanh4(y)\n",
    "        y4 = scale_by_percentage_mid(y4, q_l=self.qfc_l, q_h=self.qfc_h, alpha_l=self.afc_l, alpha_h=self.afc_h)\n",
    "        y = self.fc5(y4)\n",
    "        y5 = self.tanh5(y)\n",
    "        y5 = scale_by_percentage_mid(y5, q_l=self.qfc_l, q_h=self.qfc_h, alpha_l=self.afc_l, alpha_h=self.afc_h)\n",
    "        output = self.classifier(y5)\n",
    "        \n",
    "        return output, y1, y3, y4, y5\n",
    "\n",
    "    \n",
    "def scale_by_percentage(x, q=5.0, alpha = 1):\n",
    "    \"\"\"\n",
    "    scale paramters by threshold.\n",
    "\n",
    "    \"\"\"\n",
    "    temp_shape = x.shape\n",
    "    weight = x.data.cpu().numpy()\n",
    "    flattened_weights = np.abs(weight.flatten())\n",
    "    nonzero = flattened_weights[np.nonzero(flattened_weights)]\n",
    "    percentile_value = np.percentile(nonzero, q)\n",
    "    mask = np.ones(flattened_weights.shape)\n",
    "    new_mask = np.where(flattened_weights >= percentile_value, alpha, mask)\n",
    "    new_mask = new_mask.reshape(temp_shape)\n",
    "    new_feature_map = np.asarray(weight * new_mask, dtype=np.float32)\n",
    "    x.data = torch.from_numpy(new_feature_map).cuda()\n",
    "    return x\n",
    "\n",
    "def scale_by_percentage_mid(x, q_l = 50, q_h = 90, alpha_l = 1, alpha_h = 1):\n",
    "    \"\"\"\n",
    "    scale paramters by threshold.\n",
    "\n",
    "    \"\"\"\n",
    "#     print('q_l: ', q_l, 'q_h: ', q_h)\n",
    "    temp_shape = x.shape\n",
    "    weight = x.data.cpu().numpy()\n",
    "    \n",
    "    flattened_weights = np.abs(weight.flatten())\n",
    "    nonzero = flattened_weights[np.nonzero(flattened_weights)]\n",
    "    p_value_low = np.percentile(nonzero, q_l)\n",
    "    p_value_high = np.percentile(nonzero, q_h)\n",
    "#     p_value_low = np.percentile(flattened_weights, q_l)\n",
    "#     p_value_high = np.percentile(flattened_weights, q_h)\n",
    "#     print('p_value_low: ', p_value_low, 'p_value_high: ',p_value_high)\n",
    "    mask = np.ones(flattened_weights.shape)\n",
    "    new_mask = np.where(flattened_weights >= p_value_low, alpha_l, mask)\n",
    "#     print(new_mask)\n",
    "    new_mask = np.where(flattened_weights >= p_value_high, alpha_h, new_mask)\n",
    "#     print(new_mask)\n",
    "    new_mask = new_mask.reshape(temp_shape)\n",
    "    \n",
    "    new_feature_map = np.asarray(weight * new_mask, dtype=np.float32)\n",
    "    x.data = torch.from_numpy(new_feature_map).cuda()\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# small model\n",
    "class Texas_1layer(nn.Module):\n",
    "    def __init__(self,num_classes=100):\n",
    "        super(Texas_1layer, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "#             nn.Linear(6169,1024),\n",
    "            PruneLinear(6169,256),\n",
    "            nn.Tanh()\n",
    "#             PruneLinear(1024,512),\n",
    "#             nn.Tanh(),\n",
    "#             PruneLinear(512,256),\n",
    "#             nn.Tanh(),\n",
    "#             PruneLinear(512,128),\n",
    "#             nn.Tanh()\n",
    "        )\n",
    "#         self.classifier = nn.Linear(128,num_classes)\n",
    "        self.classifier = PruneLinear(256,num_classes)\n",
    "#         for key in self.state_dict():\n",
    "#             if key.split('.')[-1] == 'weight':    \n",
    "#                 nn.init.normal(self.state_dict()[key], std=0.01)\n",
    "#                 print (key)\n",
    "                \n",
    "#             elif key.split('.')[-1] == 'bias':\n",
    "#                 self.state_dict()[key][...] = 0\n",
    "        \n",
    "    def forward(self,x):\n",
    "        hidden_out = self.features(x)\n",
    "        \n",
    "        return self.classifier(hidden_out),hidden_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# small model\n",
    "class Texas_2layer(nn.Module):\n",
    "    def __init__(self,num_classes=100):\n",
    "        super(Texas_2layer, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "#             nn.Linear(6169,1024),\n",
    "            PruneLinear(6169,512),\n",
    "            nn.Tanh(),\n",
    "#             PruneLinear(1024,512),\n",
    "#             nn.Tanh(),\n",
    "#             PruneLinear(512,256),\n",
    "#             nn.Tanh(),\n",
    "            PruneLinear(512,128),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "#         self.classifier = nn.Linear(128,num_classes)\n",
    "        self.classifier = PruneLinear(128,num_classes)\n",
    "#         for key in self.state_dict():\n",
    "#             if key.split('.')[-1] == 'weight':    \n",
    "#                 nn.init.normal(self.state_dict()[key], std=0.01)\n",
    "#                 print (key)\n",
    "                \n",
    "#             elif key.split('.')[-1] == 'bias':\n",
    "#                 self.state_dict()[key][...] = 0\n",
    "        \n",
    "    def forward(self,x):\n",
    "        hidden_out = self.features(x)\n",
    "        \n",
    "        return self.classifier(hidden_out),hidden_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# small model\n",
    "class Texas(nn.Module):\n",
    "    def __init__(self,num_classes=100):\n",
    "        super(Texas, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "#             nn.Linear(6169,1024),\n",
    "            PruneLinear(6169,512),\n",
    "            nn.Tanh(),\n",
    "            PruneLinear(1024,512),\n",
    "            nn.Tanh(),\n",
    "            PruneLinear(512,256),\n",
    "            nn.Tanh(),\n",
    "            PruneLinear(256,128),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "#         self.classifier = nn.Linear(128,num_classes)\n",
    "        self.classifier = PruneLinear(128,num_classes)\n",
    "#         for key in self.state_dict():\n",
    "#             if key.split('.')[-1] == 'weight':    \n",
    "#                 nn.init.normal(self.state_dict()[key], std=0.01)\n",
    "#                 print (key)\n",
    "                \n",
    "#             elif key.split('.')[-1] == 'bias':\n",
    "#                 self.state_dict()[key][...] = 0\n",
    "        \n",
    "    def forward(self,x):\n",
    "        hidden_out = self.features(x)\n",
    "        \n",
    "        return self.classifier(hidden_out),hidden_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# small model\n",
    "class Texas_drop(nn.Module):\n",
    "    def __init__(self,p=0.5,num_classes = 100):\n",
    "        self.num_classes = num_classes\n",
    "        self.p = p\n",
    "        super(Texas_drop, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "#             nn.Linear(6169,1024),\n",
    "            PruneLinear(6169,1024),\n",
    "            nn.Tanh(),\n",
    "            nn.Dropout2d(p),\n",
    "            PruneLinear(1024,512),\n",
    "            nn.Tanh(),\n",
    "            nn.Dropout2d(p),\n",
    "            PruneLinear(512,256),\n",
    "            nn.Tanh(),\n",
    "            nn.Dropout2d(p),\n",
    "            PruneLinear(256,128),\n",
    "            nn.Tanh(),\n",
    "            nn.Dropout2d(p)\n",
    "        )\n",
    "#         self.classifier = nn.Linear(128,num_classes)\n",
    "        self.classifier = PruneLinear(128,num_classes)\n",
    "#         for key in self.state_dict():\n",
    "#             if key.split('.')[-1] == 'weight':    \n",
    "#                 nn.init.normal(self.state_dict()[key], std=0.01)\n",
    "#                 print (key)\n",
    "                \n",
    "#             elif key.split('.')[-1] == 'bias':\n",
    "#                 self.state_dict()[key][...] = 0\n",
    "        \n",
    "    def forward(self,x):\n",
    "        hidden_out = self.features(x)\n",
    "        \n",
    "        return self.classifier(hidden_out),hidden_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# class InferenceAttack_HZ(nn.Module):\n",
    "#     def __init__(self,num_classes):\n",
    "#         self.num_classes=num_classes\n",
    "#         super(InferenceAttack_HZ, self).__init__()\n",
    "#         self.features=nn.Sequential(\n",
    "#             nn.Linear(num_classes,512),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(512,64),\n",
    "#             nn.ReLU(),\n",
    "#             )\n",
    "        \n",
    "  \n",
    "        \n",
    "#         self.labels=nn.Sequential(\n",
    "#            nn.Linear(num_classes,64),\n",
    "#             )\n",
    "#         self.combine=nn.Sequential(\n",
    "#             nn.Linear(64*2,64),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(64,1),\n",
    "#             )\n",
    "#         for key in self.state_dict():\n",
    "#             print (key)\n",
    "#             if key.split('.')[-1] == 'weight':    \n",
    "#                 nn.init.normal(self.state_dict()[key], std=0.01)\n",
    "#                 print (key)\n",
    "                \n",
    "#             elif key.split('.')[-1] == 'bias':\n",
    "#                 self.state_dict()[key][...] = 0\n",
    "#         self.output= nn.Sigmoid()\n",
    "#     def forward(self,x1,x2,l):\n",
    "#         #print (l.size(),x.size())\n",
    "#         out_x1 = self.features(x1)\n",
    "        \n",
    "#         out_l = self.labels(l)\n",
    "        \n",
    "        \n",
    "        \n",
    "            \n",
    "#         is_member =self.combine( torch.cat((out_x1,out_l),1))\n",
    "        \n",
    "        \n",
    "#         return self.output(is_member)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# defense model\n",
    "class Defense_Model(nn.Module):\n",
    "    def __init__(self,num_classes=1):\n",
    "        super(Defense_Model, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Linear(num_classes,256),\n",
    "            \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256,128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128,64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64,1),\n",
    "            )\n",
    "        \n",
    "        self.output= nn.Sigmoid()\n",
    "    def forward(self,x):\n",
    "        is_member = self.features(x)\n",
    "        \n",
    "        return self.output(is_member), is_member"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class InferenceAttack_HZ(nn.Module):\n",
    "    def __init__(self,num_classes):\n",
    "        self.num_classes=num_classes\n",
    "        super(InferenceAttack_HZ, self).__init__()\n",
    "        self.features=nn.Sequential(\n",
    "            nn.Linear(num_classes,1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024,512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512,64),\n",
    "            nn.ReLU(),\n",
    "            )\n",
    "        \n",
    "  \n",
    "        \n",
    "        self.labels=nn.Sequential(\n",
    "           nn.Linear(num_classes,512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512,64),\n",
    "            nn.ReLU(),\n",
    "            )\n",
    "        self.combine=nn.Sequential(\n",
    "            nn.Linear(64*2,512),\n",
    "            \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512,256),\n",
    "            \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256,128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128,64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64,1),\n",
    "            )\n",
    "        for key in self.state_dict():\n",
    "            print (key)\n",
    "            if key.split('.')[-1] == 'weight':    \n",
    "                nn.init.normal(self.state_dict()[key], std=0.01)\n",
    "                print (key)\n",
    "                \n",
    "            elif key.split('.')[-1] == 'bias':\n",
    "                self.state_dict()[key][...] = 0\n",
    "        self.output= nn.Sigmoid()\n",
    "    def forward(self,x1,x2,l):\n",
    "        #print (l.size(),x.size())\n",
    "        out_x1 = self.features(x1)\n",
    "        \n",
    "        out_l = self.labels(l)\n",
    "\n",
    "            \n",
    "        is_member =self.combine( torch.cat((out_x1,out_l),1))\n",
    "        \n",
    "        return self.output(is_member), is_member\n",
    "#         return self.output(is_member)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "float(X.shape[0])\n",
    "len_train =len(X)\n",
    "# r = np.arange(len_train)\n",
    "# np.random.shuffle(r)\n",
    "# pickle.dump(r,open('./random_r_texas100','w'))\n",
    "# init_r=pickle.load(open('./random_r_texas100_prune')) #for py2\n",
    "init_r=pickle.load(open('./random_r_texas100_prune', 'rb'), encoding='latin1')# for py3\n",
    "X=X[init_r]\n",
    "Y=Y[init_r]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "train_classifier_ratio, train_attack_ratio = float(10000)/float(X.shape[0]),0.3\n",
    "train_classifier_data = X[:int(train_classifier_ratio*len_train)]\n",
    "train_attack_data = X[int(train_classifier_ratio*len_train):int((train_classifier_ratio+train_attack_ratio)*len_train)]\n",
    "test_data = X[int((train_classifier_ratio+train_attack_ratio)*len_train):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "train_classifier_data.shape\n",
    "train_attack_data.shape\n",
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# train_classifier_ratio, train_attack_ratio = float(10000)/float(X.shape[0]),0.3\n",
    "# train_classifier_ratio = 0.4\n",
    "# train_attack_ratio = 0.3\n",
    "train_classifier_data_length  = 10000\n",
    "\n",
    "train_classifier_data = X[:train_classifier_data_length]\n",
    "train_attack_data = X[10000:20000]\n",
    "test_data = X[10000:]\n",
    "# attacker_train_member = X[30000:35000]\n",
    "# attacker_train_nonmember = X[35000:40000]\n",
    "# original_train_data = X[:int((train_classifier_ratio+train_attack_ratio)*len_train)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# train_classifier_ratio, train_attack_ratio = float(10000)/float(X.shape[0]),0.3\n",
    "# print('train_classifier_ratio: ', train_classifier_ratio)\n",
    "# print('train_attack_ratio: ', train_attack_ratio)\n",
    "# train_classifier_ratio*len_train\n",
    "print('train_classifier_data: ', len(train_classifier_data))\n",
    "print('train_attack_data: ', len(train_attack_data))\n",
    "print('test_data: ', len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "train_classifier_label = Y[:train_classifier_data_length]\n",
    "train_attack_label = Y[10000:20000]\n",
    "test_label = Y[10000:]\n",
    "# attacker_train_member_label = Y[30000:35000]\n",
    "# attacker_train_nonmember_label = Y[35000:40000]\n",
    "# original_train_label = Y[:int((train_classifier_ratio+train_attack_ratio)*len_train)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print(init_r[0:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def train(train_data,labels, model, criterion, optimizer, epoch, use_cuda,num_batchs=999999):\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "    \n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    top5 = AverageMeter()\n",
    "    \n",
    "    \n",
    "    end = time.time()\n",
    "    len_t =  (len(train_data)//batch_size)-1\n",
    "    \n",
    "    for ind in range(len_t):\n",
    "        if ind > num_batchs:\n",
    "            break\n",
    "        # measure data loading time\n",
    "        inputs = train_data[ind*batch_size:(ind+1)*batch_size]\n",
    "        targets = labels[ind*batch_size:(ind+1)*batch_size]\n",
    "        data_time.update(time.time() - end)\n",
    "        if use_cuda:\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "        inputs, targets = torch.autograd.Variable(inputs), torch.autograd.Variable(targets)\n",
    "\n",
    "        # compute output\n",
    "        outputs,_,_,_,_ = model(inputs)\n",
    "        \n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        prec1, prec5 = accuracy(outputs.data, targets.data, topk=(1, 5))\n",
    "        losses.update(loss.data, inputs.size()[0])\n",
    "        top1.update(prec1, inputs.size()[0])\n",
    "        top5.update(prec5, inputs.size()[0])\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        # plot progress\n",
    "        if ind%10==0:\n",
    "            print  ('({batch}/{size}) Data: {data:.3f}s | Batch: {bt:.3f}s | | Loss: {loss:.4f} | top1: {top1: .4f} | top5: {top5: .4f}'.format(\n",
    "                    batch=ind + 1,\n",
    "                    size=len_t,\n",
    "                    data=data_time.avg,\n",
    "                    bt=batch_time.avg,\n",
    "                    loss=losses.avg,\n",
    "                    top1=top1.avg,\n",
    "                    top5=top5.avg,\n",
    "                    ))\n",
    "    return (losses.avg, top1.avg)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def test(test_data,labels, model, criterion, epoch, use_cuda):\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    top5 = AverageMeter()\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "    end = time.time()\n",
    "    len_t =  (len(test_data)//batch_size)\n",
    "    \n",
    "    for ind in range(len_t):\n",
    "        # measure data loading time\n",
    "        inputs = test_data[ind*batch_size:(ind+1)*batch_size]\n",
    "        targets = labels[ind*batch_size:(ind+1)*batch_size]\n",
    "        \n",
    "        data_time.update(time.time() - end)\n",
    "        if use_cuda:\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "        inputs, targets = torch.autograd.Variable(inputs, volatile=True), torch.autograd.Variable(targets)\n",
    "\n",
    "        # compute output\n",
    "        outputs,_,_,_,_ = model(inputs)\n",
    "        \n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        prec1, prec5 = accuracy(outputs.data, targets.data, topk=(1, 5))\n",
    "        losses.update(loss.data, inputs.size()[0])\n",
    "        top1.update(prec1, inputs.size()[0])\n",
    "        top5.update(prec5, inputs.size()[0])\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        # plot progress\n",
    "        if ind % 100==0:\n",
    "            \n",
    "            print ('({batch}/{size}) Data: {data:.3f}s | Batch: {bt:.3f}s | Loss: {loss:.4f} | top1: {top1: .4f} | top5: {top5: .4f}'.format(\n",
    "                        batch=ind + 1,\n",
    "                        size=len(test_data),\n",
    "                        data=data_time.avg,\n",
    "                        bt=batch_time.avg,\n",
    "                        loss=losses.avg,\n",
    "                        top1=top1.avg,\n",
    "                        top5=top5.avg,\n",
    "                        ))\n",
    "    return (losses.avg, top1.avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def train_mod(train_data,labels, model, criterion, optimizer, epoch, use_cuda,num_batchs=999999, alpha = 1.0):\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "    softmax = nn.Softmax()\n",
    "\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    top5 = AverageMeter()\n",
    "    \n",
    "    \n",
    "    end = time.time()\n",
    "    len_t =  (len(train_data)//batch_size)-1\n",
    "    \n",
    "    for ind in range(len_t):\n",
    "        if ind > num_batchs:\n",
    "            break\n",
    "        # measure data loading time\n",
    "        inputs = train_data[ind*batch_size:(ind+1)*batch_size]\n",
    "        targets = labels[ind*batch_size:(ind+1)*batch_size]\n",
    "        data_time.update(time.time() - end)\n",
    "        if use_cuda:\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "        inputs, targets = torch.autograd.Variable(inputs), torch.autograd.Variable(targets)\n",
    "\n",
    "        # compute output\n",
    "        outputs,_ = model(inputs)\n",
    "        \n",
    "        soft_outputs = softmax(outputs)\n",
    "        max_outputs = torch.max(soft_outputs,1).values\n",
    "        loss = criterion(outputs, targets) + alpha*(torch.mean(max_outputs - 0.85))\n",
    "        \n",
    "#         loss = criterion(outputs, targets)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        prec1, prec5 = accuracy(outputs.data, targets.data, topk=(1, 5))\n",
    "        losses.update(loss.data, inputs.size()[0])\n",
    "        top1.update(prec1, inputs.size()[0])\n",
    "        top5.update(prec5, inputs.size()[0])\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        # plot progress\n",
    "        if ind%100==0:\n",
    "            print  ('({batch}/{size}) Data: {data:.3f}s | Batch: {bt:.3f}s | | Loss: {loss:.4f} | top1: {top1: .4f} | top5: {top5: .4f}'.format(\n",
    "                    batch=ind + 1,\n",
    "                    size=len_t,\n",
    "                    data=data_time.avg,\n",
    "                    bt=batch_time.avg,\n",
    "                    loss=losses.avg,\n",
    "                    top1=top1.avg,\n",
    "                    top5=top5.avg,\n",
    "                    ))\n",
    "    return (losses.avg, top1.avg)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def test_mod(test_data,labels, model, criterion, epoch, use_cuda, alpha = 1.0):\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    top5 = AverageMeter()\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "    end = time.time()\n",
    "    len_t =  (len(test_data)//batch_size)\n",
    "    softmax = nn.Softmax()\n",
    "    \n",
    "    for ind in range(len_t):\n",
    "        # measure data loading time\n",
    "        inputs = test_data[ind*batch_size:(ind+1)*batch_size]\n",
    "        targets = labels[ind*batch_size:(ind+1)*batch_size]\n",
    "        \n",
    "        data_time.update(time.time() - end)\n",
    "        if use_cuda:\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "        inputs, targets = torch.autograd.Variable(inputs, volatile=True), torch.autograd.Variable(targets)\n",
    "\n",
    "        # compute output\n",
    "        outputs,_ = model(inputs)\n",
    "        \n",
    "        soft_outputs = softmax(outputs)\n",
    "        max_outputs = torch.max(soft_outputs,1).values\n",
    "        loss = criterion(outputs, targets) + alpha*(torch.mean(max_outputs - 0.85))\n",
    "#         loss = criterion(outputs, targets) + alpha*(torch.mean(torch.abs(0.85 - max_outputs)))\n",
    "\n",
    "#         loss = criterion(outputs, targets)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        prec1, prec5 = accuracy(outputs.data, targets.data, topk=(1, 5))\n",
    "        losses.update(loss.data, inputs.size()[0])\n",
    "        top1.update(prec1, inputs.size()[0])\n",
    "        top5.update(prec5, inputs.size()[0])\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        # plot progress\n",
    "#         if ind % 100==0:\n",
    "            \n",
    "#             print ('({batch}/{size}) Data: {data:.3f}s | Batch: {bt:.3f}s | Loss: {loss:.4f} | top1: {top1: .4f} | top5: {top5: .4f}'.format(\n",
    "#                         batch=ind + 1,\n",
    "#                         size=len(test_data),\n",
    "#                         data=data_time.avg,\n",
    "#                         bt=batch_time.avg,\n",
    "#                         loss=losses.avg,\n",
    "#                         top1=top1.avg,\n",
    "#                         top5=top5.avg,\n",
    "#                         ))\n",
    "    return (losses.avg, top1.avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def train_mod1(train_data,labels, model, criterion, optimizer, epoch, use_cuda,num_batchs=999999, alpha = 1.0):\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "    softmax = nn.Softmax()\n",
    "\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    top5 = AverageMeter()\n",
    "    \n",
    "    print('alpha: ', alpha)\n",
    "    end = time.time()\n",
    "    len_t =  (len(train_data)//batch_size)-1\n",
    "    \n",
    "    for ind in range(len_t):\n",
    "        if ind > num_batchs:\n",
    "            break\n",
    "        # measure data loading time\n",
    "        inputs = train_data[ind*batch_size:(ind+1)*batch_size]\n",
    "        targets = labels[ind*batch_size:(ind+1)*batch_size]\n",
    "        data_time.update(time.time() - end)\n",
    "        if use_cuda:\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "        inputs, targets = torch.autograd.Variable(inputs), torch.autograd.Variable(targets)\n",
    "\n",
    "        # compute output\n",
    "        outputs,_ = model(inputs)\n",
    "        \n",
    "        soft_outputs = softmax(outputs)\n",
    "        max_outputs = torch.max(soft_outputs,1).values\n",
    "        loss = criterion(outputs, targets) + alpha*(torch.mean(torch.abs(0.85 - max_outputs)))\n",
    "        \n",
    "#         loss = criterion(outputs, targets)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        prec1, prec5 = accuracy(outputs.data, targets.data, topk=(1, 5))\n",
    "        losses.update(loss.data, inputs.size()[0])\n",
    "        top1.update(prec1, inputs.size()[0])\n",
    "        top5.update(prec5, inputs.size()[0])\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        # plot progress\n",
    "        if ind%100==0:\n",
    "            print  ('({batch}/{size}) Data: {data:.3f}s | Batch: {bt:.3f}s | | Loss: {loss:.4f} | top1: {top1: .4f} | top5: {top5: .4f}'.format(\n",
    "                    batch=ind + 1,\n",
    "                    size=len_t,\n",
    "                    data=data_time.avg,\n",
    "                    bt=batch_time.avg,\n",
    "                    loss=losses.avg,\n",
    "                    top1=top1.avg,\n",
    "                    top5=top5.avg,\n",
    "                    ))\n",
    "    return (losses.avg, top1.avg)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def train_mod2(train_data,labels,untrain_data, untrain_labels, model, criterion, optimizer, epoch, use_cuda,num_batchs=999999, alpha = 1.0):\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "    softmax = nn.Softmax()\n",
    "\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    losses_d = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    top5 = AverageMeter()\n",
    "    \n",
    "    print('alpha: ', alpha)\n",
    "    end = time.time()\n",
    "    len_t =  (len(train_data)//batch_size)-1\n",
    "    \n",
    "    for ind in range(len_t):\n",
    "        if ind > num_batchs:\n",
    "            break\n",
    "        # measure data loading time\n",
    "        inputs = train_data[ind*batch_size:(ind+1)*batch_size]\n",
    "        targets = labels[ind*batch_size:(ind+1)*batch_size]\n",
    "        r= np.arange(untrain_data.shape[0])\n",
    "        np.random.shuffle(r)\n",
    "        untrain_inputs = untrain_data[r[:batch_size]]\n",
    "        untrain_targets = untrain_labels[r[:batch_size]]\n",
    "\n",
    "        data_time.update(time.time() - end)\n",
    "        if use_cuda:\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "            untrain_inputs, untrain_targets = untrain_inputs.cuda(), untrain_targets.cuda()\n",
    "        inputs, targets = torch.autograd.Variable(inputs), torch.autograd.Variable(targets)\n",
    "        untrain_inputs, untrain_targets = torch.autograd.Variable(untrain_inputs), torch.autograd.Variable(untrain_targets)\n",
    "\n",
    "        # compute output\n",
    "        outputs,_ = model(inputs)\n",
    "        untrain_outputs,_ = model(untrain_inputs)\n",
    "\n",
    "        soft_outputs = softmax(outputs)\n",
    "        soft_untrain_outputs = softmax(untrain_outputs)\n",
    "\n",
    "    #         max_outputs = torch.max(soft_outputs,1).values\n",
    "        sort_soft_outputs,_ = torch.sort(soft_outputs)\n",
    "        sort_soft_untrain_outputs,_ = torch.sort(soft_untrain_outputs)\n",
    "        loss_d = alpha*(torch.mean(torch.sum(torch.abs(sort_soft_outputs - sort_soft_untrain_outputs),1)))\n",
    "        loss = criterion(outputs, targets) + loss_d\n",
    "        \n",
    "#         loss = criterion(outputs, targets)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        prec1, prec5 = accuracy(outputs.data, targets.data, topk=(1, 5))\n",
    "        losses.update(loss.data, inputs.size()[0])\n",
    "        losses_d.update(loss_d.data, untrain_inputs.size()[0])\n",
    "        top1.update(prec1, inputs.size()[0])\n",
    "        top5.update(prec5, inputs.size()[0])\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        # plot progress\n",
    "        if ind%100==0:\n",
    "            print  ('({batch}/{size}) Data: {data:.3f}s | Batch: {bt:.3f}s | | Loss: {loss:.4f} |  Loss_d: {loss_d:.4f} | top1: {top1: .4f} | top5: {top5: .4f}'.format(\n",
    "                    batch=ind + 1,\n",
    "                    size=len_t,\n",
    "                    data=data_time.avg,\n",
    "                    bt=batch_time.avg,\n",
    "                    loss=losses.avg,\n",
    "                    loss_d = losses_d.avg,\n",
    "                    top1=top1.avg,\n",
    "                    top5=top5.avg,\n",
    "                    ))\n",
    "    return (losses.avg, losses_d.avg, top1.avg)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def train_mod3(train_data,labels,untrain_data, untrain_labels, model, criterion, optimizer, epoch, use_cuda,num_batchs=999999, alpha = 1.0, beta = 1.0):\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "    softmax = nn.Softmax()\n",
    "\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    losses_d = AverageMeter()\n",
    "    losses_a = AverageMeter()\n",
    "    max_train_outputs = AverageMeter()\n",
    "    max_untrain_outputs = AverageMeter()\n",
    "    min_untrain_outputs = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    top5 = AverageMeter()\n",
    "    \n",
    "    print('alpha: ', alpha, ' beta: ', beta)\n",
    "    end = time.time()\n",
    "    len_t =  (len(train_data)//batch_size)-1\n",
    "    \n",
    "    for ind in range(len_t):\n",
    "        if ind > num_batchs:\n",
    "            break\n",
    "        # measure data loading time\n",
    "        inputs = train_data[ind*batch_size:(ind+1)*batch_size]\n",
    "        targets = labels[ind*batch_size:(ind+1)*batch_size]\n",
    "        r= np.arange(untrain_data.shape[0])\n",
    "        np.random.shuffle(r)\n",
    "        untrain_inputs = untrain_data[r[:batch_size]]\n",
    "        untrain_targets = untrain_labels[r[:batch_size]]\n",
    "\n",
    "        data_time.update(time.time() - end)\n",
    "        if use_cuda:\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "            untrain_inputs, untrain_targets = untrain_inputs.cuda(), untrain_targets.cuda()\n",
    "        inputs, targets = torch.autograd.Variable(inputs), torch.autograd.Variable(targets)\n",
    "        untrain_inputs, untrain_targets = torch.autograd.Variable(untrain_inputs), torch.autograd.Variable(untrain_targets)\n",
    "\n",
    "        # compute output\n",
    "        outputs,_ = model(inputs)\n",
    "        untrain_outputs,_ = model(untrain_inputs)\n",
    "\n",
    "        soft_outputs = softmax(outputs)\n",
    "        soft_untrain_outputs = softmax(untrain_outputs)\n",
    "\n",
    "        sort_soft_outputs,_ = torch.sort(soft_outputs)\n",
    "        sort_soft_untrain_outputs,_ = torch.sort(soft_untrain_outputs)\n",
    "        loss_d = alpha*(torch.mean(torch.sum(torch.abs(sort_soft_outputs - sort_soft_untrain_outputs),1)))\n",
    "#         print('loss_d: ', loss_d)\n",
    "        max_soft_outputs = torch.max(soft_outputs,1).values\n",
    "        max_soft_untrain_outputs = torch.mean(torch.max(sort_soft_untrain_outputs,1).values)\n",
    "        min_soft_untrain_outputs = torch.min(torch.max(sort_soft_untrain_outputs,1).values)\n",
    "#         print('max_soft_outputs: ', max_soft_outputs)\n",
    "#         print('max_soft_untrain_outputs: ', max_soft_untrain_outputs)\n",
    "#         print('min_soft_untrain_outputs: ', min_soft_untrain_outputs)\n",
    "#         max_untrain_outputs = max_untrain_outputs + max_soft_untrain_outputs\n",
    "        loss_a = beta*torch.mean(torch.abs(max_soft_outputs - 0.01))\n",
    "#         print('loss_a: ', loss_a)\n",
    "        loss = criterion(outputs, targets) + loss_d + loss_a\n",
    "#         print('loss: ', loss)\n",
    "#         print('inputs.size()[0]: ', inputs.size()[0])\n",
    "#         loss = criterion(outputs, targets)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        prec1, prec5 = accuracy(outputs.data, targets.data, topk=(1, 5))\n",
    "        losses.update(loss.data, inputs.size()[0])\n",
    "        losses_d.update(loss_d.data, untrain_inputs.size()[0])\n",
    "        losses_a.update(loss_a.data, untrain_inputs.size()[0])\n",
    "        max_train_outputs.update(torch.mean(max_soft_outputs), inputs.size()[0])\n",
    "#         max_untrain_outputs.update(max_soft_untrain_outputs, 1)\n",
    "        max_untrain_outputs.update(max_soft_untrain_outputs, inputs.size()[0])\n",
    "        min_untrain_outputs.update(min_soft_untrain_outputs, inputs.size()[0])\n",
    "        top1.update(prec1, inputs.size()[0])\n",
    "        top5.update(prec5, inputs.size()[0])\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "        \n",
    "        # plot progress\n",
    "        if ind%100==0:\n",
    "            print  ('({batch}/{size})| Loss: {loss:.4f}| Loss_d: {loss_d:.4f}| Loss_a:{loss_a:.4f}|max train:{max_train:.4f}|max untrain:{max_untrain:.4f}|min: {min_untrain:.4f}|top1:{top1: .4f}|top5:{top5: .4f}'.format(\n",
    "                    batch=ind + 1,\n",
    "                    size=len_t,\n",
    "#                     data=data_time.avg,\n",
    "#                     bt=batch_time.avg,\n",
    "                    loss=losses.avg,\n",
    "                    loss_d = losses_d.avg,\n",
    "                    loss_a = losses_a.avg,\n",
    "                    max_train = max_train_outputs.avg,\n",
    "                    max_untrain = max_untrain_outputs.avg,    #torch.mean(max_untrain_outputs),\n",
    "                    min_untrain = min_untrain_outputs.avg,\n",
    "                    top1=top1.avg,\n",
    "                    top5=top5.avg,\n",
    "                    ))\n",
    "#             print  ('({batch}/{size}) Data: {data:.3f}s | Batch: {bt:.3f}s | | Loss: {loss:.4f} |  Loss_d: {loss_d:.4f} |  Loss_a: {loss_a:.4f} | top1: {top1: .4f} | top5: {top5: .4f}'.format(\n",
    "#                     batch=ind + 1,\n",
    "#                     size=len_t,\n",
    "#                     data=data_time.avg,\n",
    "#                     bt=batch_time.avg,\n",
    "#                     loss=losses.avg,\n",
    "#                     loss_d = losses_d.avg,\n",
    "#                     loss_a = losses_a.avg,\n",
    "\n",
    "#                     top1=top1.avg,\n",
    "#                     top5=top5.avg,\n",
    "#                     ))\n",
    "    return (losses.avg, losses_d.avg, losses_a.avg, top1.avg)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def train_mod4(train_data,labels,untrain_data, untrain_labels, model, criterion, optimizer, epoch, use_cuda,num_batchs=999999, alpha = 1.0, beta = 1.0):\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "    softmax = nn.Softmax()\n",
    "\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    losses_d = AverageMeter()\n",
    "    losses_a = AverageMeter()\n",
    "    max_train_outputs = AverageMeter()\n",
    "    max_untrain_outputs = AverageMeter()\n",
    "    min_untrain_outputs = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    top5 = AverageMeter()\n",
    "    \n",
    "    print('alpha: ', alpha, ' beta: ', beta)\n",
    "    end = time.time()\n",
    "    len_t =  (len(train_data)//batch_size)-1\n",
    "    \n",
    "    for ind in range(len_t):\n",
    "        if ind > num_batchs:\n",
    "            break\n",
    "        # measure data loading time\n",
    "        inputs = train_data[ind*batch_size:(ind+1)*batch_size]\n",
    "        targets = labels[ind*batch_size:(ind+1)*batch_size]\n",
    "        r= np.arange(untrain_data.shape[0])\n",
    "        np.random.shuffle(r)\n",
    "        untrain_inputs = untrain_data[r[:batch_size]]\n",
    "        untrain_targets = untrain_labels[r[:batch_size]]\n",
    "\n",
    "        data_time.update(time.time() - end)\n",
    "        if use_cuda:\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "            untrain_inputs, untrain_targets = untrain_inputs.cuda(), untrain_targets.cuda()\n",
    "        inputs, targets = torch.autograd.Variable(inputs), torch.autograd.Variable(targets)\n",
    "        untrain_inputs, untrain_targets = torch.autograd.Variable(untrain_inputs), torch.autograd.Variable(untrain_targets)\n",
    "\n",
    "        # compute output\n",
    "        outputs,_ = model(inputs)\n",
    "        untrain_outputs,_ = model(untrain_inputs)\n",
    "\n",
    "        soft_outputs = softmax(outputs)\n",
    "        soft_untrain_outputs = softmax(untrain_outputs)\n",
    "\n",
    "        sort_soft_outputs,_ = torch.sort(soft_outputs)\n",
    "        sort_soft_untrain_outputs,_ = torch.sort(soft_untrain_outputs)\n",
    "        loss_d = alpha*(torch.mean(torch.sum(torch.abs(sort_soft_outputs - sort_soft_untrain_outputs),1)))\n",
    "#         print('loss_d: ', loss_d)\n",
    "        max_soft_outputs = torch.max(soft_outputs,1).values\n",
    "        max_soft_untrain_outputs = torch.mean(torch.max(sort_soft_untrain_outputs,1).values)\n",
    "        min_soft_untrain_outputs = torch.min(torch.max(sort_soft_untrain_outputs,1).values)\n",
    "#         print('max_soft_outputs: ', max_soft_outputs)\n",
    "#         print('max_soft_untrain_outputs: ', max_soft_untrain_outputs)\n",
    "#         print('min_soft_untrain_outputs: ', min_soft_untrain_outputs)\n",
    "#         max_untrain_outputs = max_untrain_outputs + max_soft_untrain_outputs\n",
    "        loss_a = beta*torch.mean(torch.abs(max_soft_outputs - min_soft_untrain_outputs))\n",
    "#         print('loss_a: ', loss_a)\n",
    "        loss = criterion(outputs, targets) + loss_d + loss_a\n",
    "#         print('loss: ', loss)\n",
    "#         print('inputs.size()[0]: ', inputs.size()[0])\n",
    "#         loss = criterion(outputs, targets)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        prec1, prec5 = accuracy(outputs.data, targets.data, topk=(1, 5))\n",
    "        losses.update(loss.data, inputs.size()[0])\n",
    "        losses_d.update(loss_d.data, untrain_inputs.size()[0])\n",
    "        losses_a.update(loss_a.data, untrain_inputs.size()[0])\n",
    "        max_train_outputs.update(torch.mean(max_soft_outputs), inputs.size()[0])\n",
    "#         max_untrain_outputs.update(max_soft_untrain_outputs, 1)\n",
    "        max_untrain_outputs.update(max_soft_untrain_outputs, inputs.size()[0])\n",
    "        min_untrain_outputs.update(min_soft_untrain_outputs, inputs.size()[0])\n",
    "        top1.update(prec1, inputs.size()[0])\n",
    "        top5.update(prec5, inputs.size()[0])\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "        \n",
    "        # plot progress\n",
    "        if ind%100==0:\n",
    "            print  ('({batch}/{size})| Loss: {loss:.4f}| Loss_d: {loss_d:.4f}| Loss_a:{loss_a:.4f}|max train:{max_train:.4f}|max untrain:{max_untrain:.4f}|min: {min_untrain:.4f}|top1:{top1: .4f}|top5:{top5: .4f}'.format(\n",
    "                    batch=ind + 1,\n",
    "                    size=len_t,\n",
    "#                     data=data_time.avg,\n",
    "#                     bt=batch_time.avg,\n",
    "                    loss=losses.avg,\n",
    "                    loss_d = losses_d.avg,\n",
    "                    loss_a = losses_a.avg,\n",
    "                    max_train = max_train_outputs.avg,\n",
    "                    max_untrain = max_untrain_outputs.avg,    #torch.mean(max_untrain_outputs),\n",
    "                    min_untrain = min_untrain_outputs.avg,\n",
    "                    top1=top1.avg,\n",
    "                    top5=top5.avg,\n",
    "                    ))\n",
    "#             print  ('({batch}/{size}) Data: {data:.3f}s | Batch: {bt:.3f}s | | Loss: {loss:.4f} |  Loss_d: {loss_d:.4f} |  Loss_a: {loss_a:.4f} | top1: {top1: .4f} | top5: {top5: .4f}'.format(\n",
    "#                     batch=ind + 1,\n",
    "#                     size=len_t,\n",
    "#                     data=data_time.avg,\n",
    "#                     bt=batch_time.avg,\n",
    "#                     loss=losses.avg,\n",
    "#                     loss_d = losses_d.avg,\n",
    "#                     loss_a = losses_a.avg,\n",
    "\n",
    "#                     top1=top1.avg,\n",
    "#                     top5=top5.avg,\n",
    "#                     ))\n",
    "    return (losses.avg, losses_d.avg, losses_a.avg, top1.avg)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def train_mod5(train_data,labels,untrain_data, untrain_labels, model, criterion, optimizer, epoch, use_cuda,num_batchs=999999, alpha = 1.0, beta1 = 1.0, beta2 = 1.0):\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "    softmax = nn.Softmax()\n",
    "\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    losses_d = AverageMeter()\n",
    "    losses_min = AverageMeter()\n",
    "    losses_max = AverageMeter()\n",
    "    max_train_outputs = AverageMeter()\n",
    "    max_untrain_outputs = AverageMeter()\n",
    "    min_untrain_outputs = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    top5 = AverageMeter()\n",
    "    \n",
    "    print('alpha: ', alpha, ' beta: ', beta)\n",
    "    end = time.time()\n",
    "    len_t =  (len(train_data)//batch_size)-1\n",
    "    \n",
    "    for ind in range(len_t):\n",
    "        if ind > num_batchs:\n",
    "            break\n",
    "        # measure data loading time\n",
    "        inputs = train_data[ind*batch_size:(ind+1)*batch_size]\n",
    "        targets = labels[ind*batch_size:(ind+1)*batch_size]\n",
    "        r= np.arange(untrain_data.shape[0])\n",
    "        np.random.shuffle(r)\n",
    "        untrain_inputs = untrain_data[r[:batch_size]]\n",
    "        untrain_targets = untrain_labels[r[:batch_size]]\n",
    "\n",
    "        data_time.update(time.time() - end)\n",
    "        if use_cuda:\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "            untrain_inputs, untrain_targets = untrain_inputs.cuda(), untrain_targets.cuda()\n",
    "        inputs, targets = torch.autograd.Variable(inputs), torch.autograd.Variable(targets)\n",
    "        untrain_inputs, untrain_targets = torch.autograd.Variable(untrain_inputs), torch.autograd.Variable(untrain_targets)\n",
    "\n",
    "        # compute output\n",
    "        outputs,_ = model(inputs)\n",
    "        untrain_outputs,_ = model(untrain_inputs)\n",
    "\n",
    "        soft_outputs = softmax(outputs)\n",
    "        soft_untrain_outputs = softmax(untrain_outputs)\n",
    "\n",
    "        sort_soft_outputs,_ = torch.sort(soft_outputs)\n",
    "        sort_soft_untrain_outputs,_ = torch.sort(soft_untrain_outputs)\n",
    "        loss_d = alpha*(torch.mean(torch.sum(torch.abs(sort_soft_outputs - sort_soft_untrain_outputs),1)))\n",
    "#         print('loss_d: ', loss_d)\n",
    "        max_soft_outputs = torch.max(soft_outputs,1).values\n",
    "        max_soft_untrain_outputs = torch.mean(torch.max(sort_soft_untrain_outputs,1).values)\n",
    "        min_soft_untrain_outputs = torch.min(torch.max(sort_soft_untrain_outputs,1).values)\n",
    "#         print('max_soft_outputs: ', max_soft_outputs)\n",
    "#         print('max_soft_untrain_outputs: ', max_soft_untrain_outputs)\n",
    "#         print('min_soft_untrain_outputs: ', min_soft_untrain_outputs)\n",
    "#         max_untrain_outputs = max_untrain_outputs + max_soft_untrain_outputs\n",
    "        loss_min = beta1*torch.mean((max_soft_outputs - min_soft_untrain_outputs))\n",
    "        loss_max = beta2*torch.mean((max_soft_outputs - max_soft_untrain_outputs))\n",
    "#         print('loss_a: ', loss_a)\n",
    "        loss = criterion(outputs, targets) + loss_d + loss_min + loss_max\n",
    "#         print('loss: ', loss)\n",
    "#         print('inputs.size()[0]: ', inputs.size()[0])\n",
    "#         loss = criterion(outputs, targets)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        prec1, prec5 = accuracy(outputs.data, targets.data, topk=(1, 5))\n",
    "        losses.update(loss.data, inputs.size()[0])\n",
    "        losses_d.update(loss_d.data, untrain_inputs.size()[0])\n",
    "        losses_min.update(loss_min.data, untrain_inputs.size()[0])\n",
    "        losses_max.update(loss_max.data, untrain_inputs.size()[0])\n",
    "        max_train_outputs.update(torch.mean(max_soft_outputs), inputs.size()[0])\n",
    "#         max_untrain_outputs.update(max_soft_untrain_outputs, 1)\n",
    "        max_untrain_outputs.update(max_soft_untrain_outputs, inputs.size()[0])\n",
    "        min_untrain_outputs.update(min_soft_untrain_outputs, inputs.size()[0])\n",
    "        top1.update(prec1, inputs.size()[0])\n",
    "        top5.update(prec5, inputs.size()[0])\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "        \n",
    "        # plot progress\n",
    "        if ind%100==0:\n",
    "            print  ('({batch}/{size})| Loss: {loss:.4f}|Loss_d: {loss_d:.4f}|L_max:{loss_max:.4f}| L_min:{loss_min:.4f}|train:{max_train:.4f}|max:{max_untrain:.4f}|min: {min_untrain:.4f}|top1:{top1: .4f}|top5:{top5: .4f}'.format(\n",
    "                    batch=ind + 1,\n",
    "                    size=len_t,\n",
    "#                     data=data_time.avg,\n",
    "#                     bt=batch_time.avg,\n",
    "                    loss=losses.avg,\n",
    "                    loss_d = losses_d.avg,\n",
    "                    loss_max = losses_max.avg,\n",
    "                    loss_min = losses_min.avg,\n",
    "                    max_train = max_train_outputs.avg,\n",
    "                    max_untrain = max_untrain_outputs.avg,    #torch.mean(max_untrain_outputs),\n",
    "                    min_untrain = min_untrain_outputs.avg,\n",
    "                    top1=top1.avg,\n",
    "                    top5=top5.avg,\n",
    "                    ))\n",
    "#             print  ('({batch}/{size}) Data: {data:.3f}s | Batch: {bt:.3f}s | | Loss: {loss:.4f} |  Loss_d: {loss_d:.4f} |  Loss_a: {loss_a:.4f} | top1: {top1: .4f} | top5: {top5: .4f}'.format(\n",
    "#                     batch=ind + 1,\n",
    "#                     size=len_t,\n",
    "#                     data=data_time.avg,\n",
    "#                     bt=batch_time.avg,\n",
    "#                     loss=losses.avg,\n",
    "#                     loss_d = losses_d.avg,\n",
    "#                     loss_a = losses_a.avg,\n",
    "\n",
    "#                     top1=top1.avg,\n",
    "#                     top5=top5.avg,\n",
    "#                     ))\n",
    "    return (losses.avg, losses_d.avg, losses_max.avg,losses_min.avg, top1.avg)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def train_mod7(train_data,labels,untrain_data, untrain_labels, model, criterion, optimizer, epoch, use_cuda,num_batchs=999999, alpha = 1.0, beta = 1.0):\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "    softmax = nn.Softmax()\n",
    "\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    losses_d = AverageMeter()\n",
    "    losses_a = AverageMeter()\n",
    "    losses_ce = AverageMeter()\n",
    "    max_train_outputs = AverageMeter()\n",
    "    max_untrain_outputs = AverageMeter()\n",
    "    min_untrain_outputs = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    top5 = AverageMeter()\n",
    "    \n",
    "    print('alpha: ', alpha, ' beta: ', beta)\n",
    "    end = time.time()\n",
    "    len_t =  (len(train_data)//batch_size)-1\n",
    "    \n",
    "    for ind in range(len_t):\n",
    "        if ind > num_batchs:\n",
    "            break\n",
    "        # measure data loading time\n",
    "        inputs = train_data[ind*batch_size:(ind+1)*batch_size]\n",
    "        targets = labels[ind*batch_size:(ind+1)*batch_size]\n",
    "        r= np.arange(untrain_data.shape[0])\n",
    "        np.random.shuffle(r)\n",
    "        untrain_inputs = untrain_data[r[:batch_size]]\n",
    "        untrain_targets = untrain_labels[r[:batch_size]]\n",
    "\n",
    "        data_time.update(time.time() - end)\n",
    "        if use_cuda:\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "            untrain_inputs, untrain_targets = untrain_inputs.cuda(), untrain_targets.cuda()\n",
    "        inputs, targets = torch.autograd.Variable(inputs), torch.autograd.Variable(targets)\n",
    "        untrain_inputs, untrain_targets = torch.autograd.Variable(untrain_inputs), torch.autograd.Variable(untrain_targets)\n",
    "\n",
    "        # compute output\n",
    "        outputs,_ = model(inputs)\n",
    "        untrain_outputs,_ = model(untrain_inputs)\n",
    "\n",
    "        soft_outputs = softmax(outputs)\n",
    "        soft_untrain_outputs = softmax(untrain_outputs)\n",
    "\n",
    "        sort_outputs,_ = torch.sort(outputs)\n",
    "        sort_untrain_outputs,_ = torch.sort(untrain_outputs)\n",
    "        \n",
    "        sort_soft_outputs,_ = torch.sort(soft_outputs)\n",
    "        sort_soft_untrain_outputs,_ = torch.sort(soft_untrain_outputs)\n",
    "        \n",
    "        mean_sort_soft_untrain_outputs = torch.mean(sort_soft_untrain_outputs, 0)\n",
    "        loss_ce = -torch.mean(torch.sum(mean_sort_soft_untrain_outputs*torch.log(sort_soft_outputs),1))\n",
    "        \n",
    "        loss_d = alpha*(torch.mean(torch.sum(torch.abs(sort_outputs - sort_untrain_outputs),1)))\n",
    "\n",
    "#         print('loss_d: ', loss_d)\n",
    "        max_soft_outputs = torch.max(sort_outputs,1).values\n",
    "        max_soft_untrain_outputs = torch.mean(torch.max(sort_untrain_outputs,1).values)\n",
    "        min_soft_untrain_outputs = torch.min(torch.max(sort_untrain_outputs,1).values)\n",
    "#         print('max_soft_outputs: ', max_soft_outputs)\n",
    "#         print('max_soft_untrain_outputs: ', max_soft_untrain_outputs)\n",
    "#         print('min_soft_untrain_outputs: ', min_soft_untrain_outputs)\n",
    "#         max_untrain_outputs = max_untrain_outputs + max_soft_untrain_outputs\n",
    "        loss_a = beta*torch.mean(torch.abs(max_soft_outputs - min_soft_untrain_outputs))\n",
    "#         print('loss_a: ', loss_a)\n",
    "#         loss = criterion(outputs, targets) + loss_d + loss_a\n",
    "        loss = criterion(outputs, targets) + alpha*loss_ce\n",
    "#         print('loss: ', loss)\n",
    "#         print('inputs.size()[0]: ', inputs.size()[0])\n",
    "#         loss = criterion(outputs, targets)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        prec1, prec5 = accuracy(outputs.data, targets.data, topk=(1, 5))\n",
    "        losses.update(loss.data, inputs.size()[0])\n",
    "        losses_d.update(loss_d.data, untrain_inputs.size()[0])\n",
    "        losses_a.update(loss_a.data, untrain_inputs.size()[0])\n",
    "        losses_ce.update(loss_ce.data, untrain_inputs.size()[0])\n",
    "        max_train_outputs.update(torch.mean(max_soft_outputs), inputs.size()[0])\n",
    "#         max_untrain_outputs.update(max_soft_untrain_outputs, 1)\n",
    "        max_untrain_outputs.update(max_soft_untrain_outputs, inputs.size()[0])\n",
    "        min_untrain_outputs.update(min_soft_untrain_outputs, inputs.size()[0])\n",
    "        top1.update(prec1, inputs.size()[0])\n",
    "        top5.update(prec5, inputs.size()[0])\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "        \n",
    "        # plot progress\n",
    "        if ind%100==0:\n",
    "            print  ('({batch}/{size})| Loss: {loss:.4f} Loss_ce: {loss_ce:.4f}|| Loss_d: {loss_d:.4f}|max train:{max_train:.4f}|max untrain:{max_untrain:.4f}|min: {min_untrain:.4f}|top1:{top1: .4f}|top5:{top5: .4f}'.format(\n",
    "                    batch=ind + 1,\n",
    "                    size=len_t,\n",
    "#                     data=data_time.avg,\n",
    "#                     bt=batch_time.avg,\n",
    "                    loss=losses.avg,\n",
    "                    loss_ce = losses_ce.avg,\n",
    "                    loss_d = losses_d.avg,\n",
    "#                     loss_a = losses_a.avg,\n",
    "                    max_train = max_train_outputs.avg,\n",
    "                    max_untrain = max_untrain_outputs.avg,    #torch.mean(max_untrain_outputs),\n",
    "                    min_untrain = min_untrain_outputs.avg,\n",
    "                    top1=top1.avg,\n",
    "                    top5=top5.avg,\n",
    "                    ))\n",
    "#             print  ('({batch}/{size}) Data: {data:.3f}s | Batch: {bt:.3f}s | | Loss: {loss:.4f} |  Loss_d: {loss_d:.4f} |  Loss_a: {loss_a:.4f} | top1: {top1: .4f} | top5: {top5: .4f}'.format(\n",
    "#                     batch=ind + 1,\n",
    "#                     size=len_t,\n",
    "#                     data=data_time.avg,\n",
    "#                     bt=batch_time.avg,\n",
    "#                     loss=losses.avg,\n",
    "#                     loss_d = losses_d.avg,\n",
    "#                     loss_a = losses_a.avg,\n",
    "\n",
    "#                     top1=top1.avg,\n",
    "#                     top5=top5.avg,\n",
    "#                     ))\n",
    "    return (losses.avg, losses_d.avg, losses_ce.avg, top1.avg)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def train_privatly(train_data,labels, model,inference_model, criterion, optimizer, epoch, use_cuda,num_batchs=10000,skip_batch=0,alpha=0.5):\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "    inference_model.eval()\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    top5 = AverageMeter()\n",
    "    end = time.time()\n",
    "    \n",
    "    \n",
    "    len_t =  (len(train_data)//batch_size)-1\n",
    "    \n",
    "    for ind in range(skip_batch,len_t):\n",
    "        \n",
    "        if ind >= skip_batch+num_batchs:\n",
    "            break\n",
    "        \n",
    "        # measure data loading time\n",
    "        \n",
    "        #print (ind)\n",
    "        \n",
    "        inputs = train_data[ind*batch_size:(ind+1)*batch_size]\n",
    "        \n",
    "        \n",
    "        targets = labels[ind*batch_size:(ind+1)*batch_size]\n",
    "        data_time.update(time.time() - end)\n",
    "        if use_cuda:\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "        inputs, targets = torch.autograd.Variable(inputs), torch.autograd.Variable(targets)\n",
    "\n",
    "        # compute output\n",
    "        outputs,h_layer = model(inputs)\n",
    "        \n",
    "        \n",
    "        one_hot_tr = torch.from_numpy((np.zeros((outputs.size()[0],outputs.size(1))))).cuda().type(torch.cuda.FloatTensor)\n",
    "        target_one_hot_tr = one_hot_tr.scatter_(1, targets.type(torch.cuda.LongTensor).view([-1,1]).data,1)\n",
    "        \n",
    "        infer_input_one_hot = torch.autograd.Variable(target_one_hot_tr)\n",
    "        \n",
    "        \n",
    "        \n",
    "        inference_output = inference_model ( outputs,h_layer,infer_input_one_hot)\n",
    "        #print (inference_output.mean())\n",
    "        \n",
    "        relu = nn.ReLU()\n",
    "        loss = criterion(outputs, targets) + ((alpha)*(torch.mean((inference_output)) - 0.5))\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        prec1, prec5 = accuracy(outputs.data, targets.data, topk=(1, 5))\n",
    "        losses.update(loss.data, inputs.size()[0])\n",
    "        top1.update(prec1, inputs.size()[0])\n",
    "        top5.update(prec5, inputs.size()[0])\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        # plot progress\n",
    "        if ind%100==0:\n",
    "            print  (alpha, '({batch}/{size}) Data: {data:.3f}s | Batch: {bt:.3f}s | | Loss: {loss:.4f} | top1: {top1: .4f} | top5: {top5: .4f}'.format(\n",
    "                    batch=ind + 1,\n",
    "                    size=len_t,\n",
    "                    data=data_time.avg,\n",
    "                    bt=batch_time.avg,\n",
    "                    loss=losses.avg,\n",
    "                    top1=top1.avg,\n",
    "                    top5=top5.avg,\n",
    "                    ))\n",
    "    return (losses.avg, top1.avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def outputres(test_data,labels, model, criterion, epoch, use_cuda):\n",
    "    \n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "    end = time.time()\n",
    "    len_t =  (len(test_data)//batch_size)-1\n",
    "    alloutputs = np.zeros((batch_size*(len_t),100))\n",
    "    for ind in range(len_t):\n",
    "        # measure data loading time\n",
    "        inputs = test_data[ind*batch_size:(ind+1)*batch_size]\n",
    "        targets = labels[ind*batch_size:(ind+1)*batch_size]\n",
    "        \n",
    "        \n",
    "        if use_cuda:\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "        inputs, targets = torch.autograd.Variable(inputs, volatile=True), torch.autograd.Variable(targets)\n",
    "\n",
    "        # compute output\n",
    "        outputs,_ = model(inputs)\n",
    "        \n",
    "        alloutputs[ind*batch_size:(ind+1)*batch_size,:]=F.softmax(outputs,dim=1).data.cpu().numpy()\n",
    "    return alloutputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def save_checkpoint(state, is_best, checkpoint='./checkpoints_texas_10class_little_model_defense/', filename='checkpoint.pth.tar'):\n",
    "    if not os.path.isdir(checkpoint):\n",
    "        mkdir_p(checkpoint)\n",
    "    filepath = os.path.join(checkpoint, filename)\n",
    "    torch.save(state, filepath)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filepath, os.path.join(checkpoint, 'model_best.pth.tar'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "best_acc = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "epochs=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def train_attack(train_data,labels,attack_data,attack_label, model,attack_model, criterion,attack_criterion, optimizer,attack_optimizer, epoch, use_cuda,num_batchs=100000,skip_batch=0):\n",
    "    # switch to train mode\n",
    "    model.eval()\n",
    "    attack_model.train()\n",
    "    \n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    top5 = AverageMeter()\n",
    "    \n",
    "    \n",
    "    end = time.time()\n",
    "    len_t =  min((len(attack_data)//batch_size) ,(len(train_data)//batch_size))+1\n",
    "    \n",
    "    #print (skip_batch, len_t)\n",
    "    \n",
    "    for ind in range(skip_batch, len_t):\n",
    "        \n",
    "        if ind >= skip_batch+num_batchs:\n",
    "            break\n",
    "        # measure data loading time\n",
    "        inputs = train_data[ind*batch_size:(ind+1)*batch_size]\n",
    "        targets = labels[ind*batch_size:(ind+1)*batch_size]\n",
    "        \n",
    "        inputs_attack = attack_data[ind*batch_size:(ind+1)*batch_size]\n",
    "        targets_attack = attack_label[ind*batch_size:(ind+1)*batch_size]\n",
    "        #print ( len(targets_attack), len(targets))\n",
    "        \n",
    "        data_time.update(time.time() - end)\n",
    "        if use_cuda:\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "            inputs_attack , targets_attack = inputs_attack.cuda(), targets_attack.cuda()\n",
    "            \n",
    "        inputs, targets = torch.autograd.Variable(inputs), torch.autograd.Variable(targets)\n",
    "        inputs_attack , targets_attack = torch.autograd.Variable(inputs_attack), torch.autograd.Variable(targets_attack)\n",
    "        # compute output\n",
    "        outputs, h_layer = model(inputs)\n",
    "        outputs_non, h_layer_non = model(inputs_attack)\n",
    "        \n",
    "        classifier_input = torch.cat((inputs,inputs_attack))\n",
    "        comb_inputs_h = torch.cat((h_layer,h_layer_non))\n",
    "        comb_inputs = torch.cat((outputs,outputs_non))\n",
    "        \n",
    "        if use_cuda:\n",
    "            comb_targets= torch.cat((targets,targets_attack)).view([-1,1]).type(torch.cuda.FloatTensor)\n",
    "        else:\n",
    "            comb_targets= torch.cat((targets,targets_attack)).view([-1,1]).type(torch.FloatTensor)\n",
    "            \n",
    "        #print (comb_inputs.size(),comb_targets.size())\n",
    "        attack_input = comb_inputs #torch.cat((comb_inputs,comb_targets),1)\n",
    "        \n",
    "        \n",
    "        one_hot_tr = torch.from_numpy((np.zeros((attack_input.size()[0],outputs.size(1))))).cuda().type(torch.cuda.FloatTensor)\n",
    "        target_one_hot_tr = one_hot_tr.scatter_(1, torch.cat((targets,targets_attack)).type(torch.cuda.LongTensor).view([-1,1]).data,1)\n",
    "        \n",
    "        infer_input_one_hot = torch.autograd.Variable(target_one_hot_tr)\n",
    "         \n",
    "        \n",
    "        \n",
    "#         sf= nn.Softmax(dim=0)\n",
    "        \n",
    "#         att_inp=torch.stack([attack_input, infer_input_one_hot],1)\n",
    "        \n",
    "        \n",
    "#         att_inp = att_inp.view([attack_input.size()[0],1,2,attack_input.size(1)])\n",
    "        \n",
    "        #attack_output = attack_model(att_inp).view([-1])\n",
    "        attack_output = attack_model(attack_input,comb_inputs_h,infer_input_one_hot).view([-1])\n",
    "        #attack_output = attack_model(attack_input).view([-1])\n",
    "        att_labels = np.zeros((inputs.size()[0]+inputs_attack.size()[0]))\n",
    "        att_labels [:inputs.size()[0]] =1.0\n",
    "        att_labels [inputs.size()[0]:] =0.0\n",
    "        is_member_labels = torch.from_numpy(att_labels).type(torch.FloatTensor)\n",
    "        \n",
    "        if use_cuda:\n",
    "            is_member_labels = is_member_labels.cuda()\n",
    "        \n",
    "        v_is_member_labels = torch.autograd.Variable(is_member_labels)\n",
    "        \n",
    "        \n",
    "#         classifier_targets = comb_targets.clone().view([-1]).type(torch.cuda.LongTensor)\n",
    "        \n",
    "        loss_attack = attack_criterion(attack_output, v_is_member_labels)\n",
    "        \n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        #prec1,p5 = accuracy(attack_output.data, v_is_member_labels.data, topk=(1,2))\n",
    "        \n",
    "        prec1=np.mean(np.equal((attack_output.data.cpu().numpy() >0.5),(v_is_member_labels.data.cpu().numpy()> 0.5)))\n",
    "        losses.update(loss_attack.data, attack_input.size()[0])\n",
    "        top1.update(prec1, attack_input.size()[0])\n",
    "        \n",
    "        #print ( attack_output.data.cpu().numpy(),v_is_member_labels.data.cpu().numpy() ,attack_input.data.cpu().numpy())\n",
    "        #raise\n",
    "        \n",
    "        \n",
    "        \n",
    "        # compute gradient and do SGD step\n",
    "        attack_optimizer.zero_grad()\n",
    "        loss_attack.backward()\n",
    "        attack_optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        # plot progress\n",
    "        if ind%100==0:\n",
    "            print  ('({batch}/{size}) Data: {data:.3f}s | Batch: {bt:.3f}s | | Loss: {loss:.4f} | top1: {top1: .4f} '.format(\n",
    "                    batch=ind + 1,\n",
    "                    size=len_t,\n",
    "                    data=data_time.avg,\n",
    "                    bt=batch_time.avg,\n",
    "                    loss=losses.avg,\n",
    "                    top1=top1.avg,\n",
    "                    ))\n",
    "    return (losses.avg, top1.avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def test_attack(train_data,labels,attack_data,attack_label, model,attack_model, criterion,attack_criterion, optimizer,attack_optimizer, epoch, use_cuda):\n",
    "    model.eval()\n",
    "    attack_model.eval()\n",
    "    \n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    top5 = AverageMeter()\n",
    "    \n",
    "    sum_correct = 0.0\n",
    "    \n",
    "    end = time.time()\n",
    "    len_t =  min((len(attack_data)//batch_size) ,(len(train_data)//batch_size))+1\n",
    "    \n",
    "    for ind in range(len_t):\n",
    "        # measure data loading time\n",
    "        inputs = train_data[ind*batch_size:(ind+1)*batch_size]\n",
    "        targets = labels[ind*batch_size:(ind+1)*batch_size]\n",
    "        \n",
    "        inputs_attack = attack_data[ind*batch_size:(ind+1)*batch_size]\n",
    "        targets_attack = attack_label[ind*batch_size:(ind+1)*batch_size]\n",
    "        #print ( len(targets_attack), len(targets))\n",
    "        \n",
    "        data_time.update(time.time() - end)\n",
    "        if use_cuda:\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "            inputs_attack , targets_attack = inputs_attack.cuda(), targets_attack.cuda()\n",
    "        inputs, targets = torch.autograd.Variable(inputs), torch.autograd.Variable(targets)\n",
    "        inputs_attack , targets_attack = torch.autograd.Variable(inputs_attack), torch.autograd.Variable(targets_attack)\n",
    "\n",
    "        # compute output\n",
    "        outputs,h_layer = model(inputs)\n",
    "        outputs_non,h_layer_non = model(inputs_attack)\n",
    "        \n",
    "        comb_inputs_h = torch.cat((h_layer,h_layer_non))\n",
    "        comb_inputs = torch.cat((outputs,outputs_non))\n",
    "        \n",
    "        if use_cuda:\n",
    "            comb_targets= torch.cat((targets,targets_attack)).view([-1,1]).type(torch.cuda.FloatTensor)\n",
    "        else:\n",
    "            comb_targets= torch.cat((targets,targets_attack)).view([-1,1]).type(torch.FloatTensor)\n",
    "            \n",
    "        #print (comb_inputs.size(),comb_targets.size())\n",
    "        attack_input = comb_inputs #torch.cat((comb_inputs,comb_targets),1)\n",
    "        \n",
    "        \n",
    "        one_hot_tr = torch.from_numpy((np.zeros((attack_input.size()[0],outputs.size(1))))).cuda().type(torch.cuda.FloatTensor)\n",
    "        target_one_hot_tr = one_hot_tr.scatter_(1, torch.cat((targets,targets_attack)).type(torch.cuda.LongTensor).view([-1,1]).data,1)\n",
    "        \n",
    "        infer_input_one_hot = torch.autograd.Variable(target_one_hot_tr)\n",
    "         \n",
    "        \n",
    "        \n",
    "        #attack_output = attack_model(att_inp).view([-1])\n",
    "        attack_output = attack_model(attack_input,comb_inputs_h,infer_input_one_hot).view([-1])\n",
    "        #attack_output = attack_model(attack_input).view([-1])\n",
    "        att_labels = np.zeros((inputs.size()[0]+inputs_attack.size()[0]))\n",
    "        att_labels [:inputs.size()[0]] =1.0\n",
    "        att_labels [inputs.size()[0]:] =0.0\n",
    "        is_member_labels = torch.from_numpy(att_labels).type(torch.FloatTensor)\n",
    "        if use_cuda:\n",
    "            is_member_labels = is_member_labels.cuda()\n",
    "        \n",
    "        v_is_member_labels = torch.autograd.Variable(is_member_labels)\n",
    "        \n",
    "        \n",
    "        \n",
    "        loss = attack_criterion(attack_output, v_is_member_labels)\n",
    "        \n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        #prec1,p5 = accuracy(attack_output.data, v_is_member_labels.data, topk=(1,2))\n",
    "        \n",
    "        prec1=np.mean(np.equal((attack_output.data.cpu().numpy() >0.5),(v_is_member_labels.data.cpu().numpy()> 0.5)))\n",
    "        losses.update(loss.data, attack_input.size()[0])\n",
    "        top1.update(prec1, attack_input.size()[0])\n",
    "        \n",
    "        correct = np.sum(np.equal((attack_output.data.cpu().numpy() >0.5),(v_is_member_labels.data.cpu().numpy()> 0.5)))\n",
    "        sum_correct += correct\n",
    "        #raise\n",
    "        \n",
    "        # compute gradient and do SGD step\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        # plot progress\n",
    "        if ind%100==0:\n",
    "            print  ('({batch}/{size}) Data: {data:.3f}s | Batch: {bt:.3f}s | | Loss: {loss:.4f} | top1: {top1: .4f} '.format(\n",
    "                    batch=ind + 1,\n",
    "                    size=len_t,\n",
    "                    data=data_time.avg,\n",
    "                    bt=batch_time.avg,\n",
    "                    loss=losses.avg,\n",
    "                    top1=top1.avg,\n",
    "                    ))\n",
    "            \n",
    "#         break\n",
    "#     return (losses.avg, top1.avg)  #,prec1,attack_output,  v_is_member_labels)\n",
    "        \n",
    "    return (losses.avg, top1.avg, sum_correct)\n",
    "\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def train_attack_softmax(train_data,labels,attack_data,attack_label, model,attack_model, criterion,attack_criterion, optimizer,attack_optimizer, epoch, use_cuda,num_batchs=100000,skip_batch=0):\n",
    "    # switch to train mode\n",
    "    model.eval()\n",
    "    attack_model.train()\n",
    "    \n",
    "    softmax = nn.Softmax()\n",
    "    \n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    top5 = AverageMeter()\n",
    "    \n",
    "    \n",
    "    end = time.time()\n",
    "    len_t =  min((len(attack_data)//batch_size) ,(len(train_data)//batch_size))+1\n",
    "    \n",
    "    #print (skip_batch, len_t)\n",
    "    \n",
    "    for ind in range(skip_batch, len_t):\n",
    "        \n",
    "        if ind >= skip_batch+num_batchs:\n",
    "            break\n",
    "        # measure data loading time\n",
    "        inputs = train_data[ind*batch_size:(ind+1)*batch_size]\n",
    "        targets = labels[ind*batch_size:(ind+1)*batch_size]\n",
    "        \n",
    "        inputs_attack = attack_data[ind*batch_size:(ind+1)*batch_size]\n",
    "        targets_attack = attack_label[ind*batch_size:(ind+1)*batch_size]\n",
    "        #print ( len(targets_attack), len(targets))\n",
    "        \n",
    "        data_time.update(time.time() - end)\n",
    "        if use_cuda:\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "            inputs_attack , targets_attack = inputs_attack.cuda(), targets_attack.cuda()\n",
    "            \n",
    "        inputs, targets = torch.autograd.Variable(inputs), torch.autograd.Variable(targets)\n",
    "        inputs_attack , targets_attack = torch.autograd.Variable(inputs_attack), torch.autograd.Variable(targets_attack)\n",
    "        # compute output\n",
    "        outputs,_,_,_, h_layer = model(inputs)\n",
    "        outputs_non,_,_,_, h_layer_non = model(inputs_attack)\n",
    "        \n",
    "        classifier_input = torch.cat((inputs,inputs_attack))\n",
    "        comb_inputs_h = torch.cat((h_layer,h_layer_non))\n",
    "        comb_inputs = torch.cat((outputs,outputs_non))\n",
    "        \n",
    "        if use_cuda:\n",
    "            comb_targets= torch.cat((targets,targets_attack)).view([-1,1]).type(torch.cuda.FloatTensor)\n",
    "        else:\n",
    "            comb_targets= torch.cat((targets,targets_attack)).view([-1,1]).type(torch.FloatTensor)\n",
    "            \n",
    "        #print (comb_inputs.size(),comb_targets.size())\n",
    "        attack_input = softmax(comb_inputs) #torch.cat((comb_inputs,comb_targets),1)\n",
    "        \n",
    "        \n",
    "        one_hot_tr = torch.from_numpy((np.zeros((attack_input.size()[0],outputs.size(1))))).cuda().type(torch.cuda.FloatTensor)\n",
    "        target_one_hot_tr = one_hot_tr.scatter_(1, torch.cat((targets,targets_attack)).type(torch.cuda.LongTensor).view([-1,1]).data,1)\n",
    "        \n",
    "        infer_input_one_hot = torch.autograd.Variable(target_one_hot_tr)\n",
    "         \n",
    "        \n",
    "        \n",
    "#         sf= nn.Softmax(dim=0)\n",
    "        \n",
    "#         att_inp=torch.stack([attack_input, infer_input_one_hot],1)\n",
    "        \n",
    "        \n",
    "#         att_inp = att_inp.view([attack_input.size()[0],1,2,attack_input.size(1)])\n",
    "        \n",
    "        #attack_output = attack_model(att_inp).view([-1])\n",
    "#         attack_output = attack_model(attack_input,comb_inputs_h,infer_input_one_hot).view([-1])\n",
    "#         print(attack_input.shape, comb_inputs_h.shape, infer_input_one_hot.shape)\n",
    "        attack_output, _ = attack_model(attack_input,comb_inputs_h,infer_input_one_hot)\n",
    "        attack_output = attack_output.view([-1])\n",
    "        #attack_output = attack_model(attack_input).view([-1])\n",
    "        att_labels = np.zeros((inputs.size()[0]+inputs_attack.size()[0]))\n",
    "        att_labels [:inputs.size()[0]] =1.0\n",
    "        att_labels [inputs.size()[0]:] =0.0\n",
    "        is_member_labels = torch.from_numpy(att_labels).type(torch.FloatTensor)\n",
    "        \n",
    "        if use_cuda:\n",
    "            is_member_labels = is_member_labels.cuda()\n",
    "        \n",
    "        v_is_member_labels = torch.autograd.Variable(is_member_labels)\n",
    "        \n",
    "        \n",
    "#         classifier_targets = comb_targets.clone().view([-1]).type(torch.cuda.LongTensor)\n",
    "        \n",
    "        loss_attack = attack_criterion(attack_output, v_is_member_labels)\n",
    "        \n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        #prec1,p5 = accuracy(attack_output.data, v_is_member_labels.data, topk=(1,2))\n",
    "        \n",
    "        prec1=np.mean(np.equal((attack_output.data.cpu().numpy() >0.5),(v_is_member_labels.data.cpu().numpy()> 0.5)))\n",
    "        losses.update(loss_attack.data, attack_input.size()[0])\n",
    "        top1.update(prec1, attack_input.size()[0])\n",
    "        \n",
    "        #print ( attack_output.data.cpu().numpy(),v_is_member_labels.data.cpu().numpy() ,attack_input.data.cpu().numpy())\n",
    "        #raise\n",
    "        \n",
    "        \n",
    "        \n",
    "        # compute gradient and do SGD step\n",
    "        attack_optimizer.zero_grad()\n",
    "        loss_attack.backward()\n",
    "        attack_optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        # plot progress\n",
    "        if ind%100==0:\n",
    "            print  ('({batch}/{size}) Data: {data:.3f}s | Batch: {bt:.3f}s | | Loss: {loss:.4f} | top1: {top1: .4f} '.format(\n",
    "                    batch=ind + 1,\n",
    "                    size=len_t,\n",
    "                    data=data_time.avg,\n",
    "                    bt=batch_time.avg,\n",
    "                    loss=losses.avg,\n",
    "                    top1=top1.avg,\n",
    "                    ))\n",
    "    return (losses.avg, top1.avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def test_attack_softmax(train_data,labels,attack_data,attack_label, model,attack_model, criterion,attack_criterion, optimizer,attack_optimizer, epoch, use_cuda):\n",
    "    model.eval()\n",
    "    attack_model.eval()\n",
    "    \n",
    "    softmax = nn.Softmax()\n",
    "\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    top5 = AverageMeter()\n",
    "    \n",
    "    sum_correct = 0.0\n",
    "    \n",
    "    end = time.time()\n",
    "    len_t =  min((len(attack_data)//batch_size) ,(len(train_data)//batch_size))+1\n",
    "    \n",
    "    for ind in range(len_t):\n",
    "        # measure data loading time\n",
    "        inputs = train_data[ind*batch_size:(ind+1)*batch_size]\n",
    "        targets = labels[ind*batch_size:(ind+1)*batch_size]\n",
    "        \n",
    "        inputs_attack = attack_data[ind*batch_size:(ind+1)*batch_size]\n",
    "        targets_attack = attack_label[ind*batch_size:(ind+1)*batch_size]\n",
    "        #print ( len(targets_attack), len(targets))\n",
    "        \n",
    "        data_time.update(time.time() - end)\n",
    "        if use_cuda:\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "            inputs_attack , targets_attack = inputs_attack.cuda(), targets_attack.cuda()\n",
    "        inputs, targets = torch.autograd.Variable(inputs), torch.autograd.Variable(targets)\n",
    "        inputs_attack , targets_attack = torch.autograd.Variable(inputs_attack), torch.autograd.Variable(targets_attack)\n",
    "\n",
    "        # compute output\n",
    "        outputs,_,_,_,h_layer = model(inputs)\n",
    "        outputs_non,_,_,_,h_layer_non = model(inputs_attack)\n",
    "        \n",
    "        comb_inputs_h = torch.cat((h_layer,h_layer_non))\n",
    "        comb_inputs = torch.cat((outputs,outputs_non))\n",
    "        \n",
    "        if use_cuda:\n",
    "            comb_targets= torch.cat((targets,targets_attack)).view([-1,1]).type(torch.cuda.FloatTensor)\n",
    "        else:\n",
    "            comb_targets= torch.cat((targets,targets_attack)).view([-1,1]).type(torch.FloatTensor)\n",
    "            \n",
    "        #print (comb_inputs.size(),comb_targets.size())\n",
    "        attack_input = softmax(comb_inputs) #torch.cat((comb_inputs,comb_targets),1)\n",
    "        \n",
    "        \n",
    "        one_hot_tr = torch.from_numpy((np.zeros((attack_input.size()[0],outputs.size(1))))).cuda().type(torch.cuda.FloatTensor)\n",
    "        target_one_hot_tr = one_hot_tr.scatter_(1, torch.cat((targets,targets_attack)).type(torch.cuda.LongTensor).view([-1,1]).data,1)\n",
    "        \n",
    "        infer_input_one_hot = torch.autograd.Variable(target_one_hot_tr)\n",
    "         \n",
    "        \n",
    "        \n",
    "        #attack_output = attack_model(att_inp).view([-1])\n",
    "        attack_output, _ = attack_model(attack_input,comb_inputs_h,infer_input_one_hot)\n",
    "        attack_output = attack_output.view([-1])\n",
    "        #attack_output = attack_model(attack_input).view([-1])\n",
    "        att_labels = np.zeros((inputs.size()[0]+inputs_attack.size()[0]))\n",
    "        att_labels [:inputs.size()[0]] =1.0\n",
    "        att_labels [inputs.size()[0]:] =0.0\n",
    "        is_member_labels = torch.from_numpy(att_labels).type(torch.FloatTensor)\n",
    "        if use_cuda:\n",
    "            is_member_labels = is_member_labels.cuda()\n",
    "        \n",
    "        v_is_member_labels = torch.autograd.Variable(is_member_labels)\n",
    "        \n",
    "        \n",
    "        \n",
    "        loss = attack_criterion(attack_output, v_is_member_labels)\n",
    "        \n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        #prec1,p5 = accuracy(attack_output.data, v_is_member_labels.data, topk=(1,2))\n",
    "        \n",
    "        prec1=np.mean(np.equal((attack_output.data.cpu().numpy() >0.5),(v_is_member_labels.data.cpu().numpy()> 0.5)))\n",
    "        losses.update(loss.data, attack_input.size()[0])\n",
    "        top1.update(prec1, attack_input.size()[0])\n",
    "        \n",
    "        correct = np.sum(np.equal((attack_output.data.cpu().numpy() >0.5),(v_is_member_labels.data.cpu().numpy()> 0.5)))\n",
    "        sum_correct += correct\n",
    "        #raise\n",
    "        \n",
    "        # compute gradient and do SGD step\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        # plot progress\n",
    "        if ind%100==0:\n",
    "            print  ('({batch}/{size}) Data: {data:.3f}s | Batch: {bt:.3f}s | | Loss: {loss:.4f} | top1: {top1: .4f} '.format(\n",
    "                    batch=ind + 1,\n",
    "                    size=len_t,\n",
    "                    data=data_time.avg,\n",
    "                    bt=batch_time.avg,\n",
    "                    loss=losses.avg,\n",
    "                    top1=top1.avg,\n",
    "                    ))\n",
    "            \n",
    "#         break\n",
    "#     return (losses.avg, top1.avg)  #,prec1,attack_output,  v_is_member_labels)\n",
    "        \n",
    "    return (losses.avg, top1.avg, sum_correct)\n",
    "\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def test_attack_softmax_modify(train_data,labels, train_logits,attack_data,attack_label,test_logits, model,attack_model, criterion,attack_criterion, optimizer,attack_optimizer, epoch, use_cuda):\n",
    "    model.eval()\n",
    "    attack_model.eval()\n",
    "    \n",
    "    softmax = nn.Softmax()\n",
    "\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    top5 = AverageMeter()\n",
    "    \n",
    "    sum_correct = 0.0\n",
    "    \n",
    "    end = time.time()\n",
    "    len_t =  min((len(attack_data)//batch_size) ,(len(train_data)//batch_size))+1\n",
    "    \n",
    "    for ind in range(len_t):\n",
    "        # measure data loading time\n",
    "        inputs = train_data[ind*batch_size:(ind+1)*batch_size]\n",
    "        targets = labels[ind*batch_size:(ind+1)*batch_size]\n",
    "        train_attack_logits = train_logits[ind*batch_size:(ind+1)*batch_size]\n",
    "        \n",
    "        inputs_attack = attack_data[ind*batch_size:(ind+1)*batch_size]\n",
    "        targets_attack = attack_label[ind*batch_size:(ind+1)*batch_size]\n",
    "        test_attack_logits = test_logits[ind*batch_size:(ind+1)*batch_size]\n",
    "        #print ( len(targets_attack), len(targets))\n",
    "        \n",
    "        data_time.update(time.time() - end)\n",
    "        if use_cuda:\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "            inputs_attack , targets_attack = inputs_attack.cuda(), targets_attack.cuda()\n",
    "            train_attack_logits, test_attack_logits = train_attack_logits.cuda(), test_attack_logits.cuda()\n",
    "        inputs, targets = torch.autograd.Variable(inputs), torch.autograd.Variable(targets)\n",
    "        inputs_attack , targets_attack = torch.autograd.Variable(inputs_attack), torch.autograd.Variable(targets_attack)\n",
    "        train_attack_logits , test_attack_logits = torch.autograd.Variable(train_attack_logits), torch.autograd.Variable(test_attack_logits)\n",
    "        \n",
    "        # compute output\n",
    "        outputs,h_layer = model(inputs)\n",
    "        outputs_non,h_layer_non = model(inputs_attack)\n",
    "        \n",
    "        comb_inputs_h = torch.cat((h_layer,h_layer_non))\n",
    "        \n",
    "        comb_inputs = torch.cat((train_attack_logits,test_attack_logits))\n",
    "        \n",
    "        if use_cuda:\n",
    "            comb_targets= torch.cat((targets,targets_attack)).view([-1,1]).type(torch.cuda.FloatTensor)\n",
    "        else:\n",
    "            comb_targets= torch.cat((targets,targets_attack)).view([-1,1]).type(torch.FloatTensor)\n",
    "            \n",
    "        #print (comb_inputs.size(),comb_targets.size())\n",
    "        attack_input = softmax(comb_inputs) #torch.cat((comb_inputs,comb_targets),1)\n",
    "        \n",
    "        \n",
    "        one_hot_tr = torch.from_numpy((np.zeros((attack_input.size()[0],outputs.size(1))))).cuda().type(torch.cuda.FloatTensor)\n",
    "        target_one_hot_tr = one_hot_tr.scatter_(1, torch.cat((targets,targets_attack)).type(torch.cuda.LongTensor).view([-1,1]).data,1)\n",
    "        \n",
    "        infer_input_one_hot = torch.autograd.Variable(target_one_hot_tr)\n",
    "         \n",
    "        \n",
    "        #attack_output = attack_model(att_inp).view([-1])\n",
    "#         attack_output = attack_model(attack_input,comb_inputs_h,infer_input_one_hot).view([-1])\n",
    "        attack_output, _ = attack_model(attack_input,comb_inputs_h,infer_input_one_hot)\n",
    "        attack_output = attack_output.view([-1])\n",
    "        #attack_output = attack_model(attack_input).view([-1])\n",
    "        att_labels = np.zeros((train_attack_logits.size()[0]+test_attack_logits.size()[0]))\n",
    "        att_labels [:train_attack_logits.size()[0]] =1.0\n",
    "        att_labels [train_attack_logits.size()[0]:] =0.0\n",
    "        is_member_labels = torch.from_numpy(att_labels).type(torch.FloatTensor)\n",
    "        if use_cuda:\n",
    "            is_member_labels = is_member_labels.cuda()\n",
    "        \n",
    "        v_is_member_labels = torch.autograd.Variable(is_member_labels)\n",
    "        \n",
    "    \n",
    "        loss = attack_criterion(attack_output, v_is_member_labels)\n",
    "        \n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        #prec1,p5 = accuracy(attack_output.data, v_is_member_labels.data, topk=(1,2))\n",
    "        \n",
    "        prec1=np.mean(np.equal((attack_output.data.cpu().numpy() >0.5),(v_is_member_labels.data.cpu().numpy()> 0.5)))\n",
    "        losses.update(loss.data, attack_input.size()[0])\n",
    "        top1.update(prec1, attack_input.size()[0])\n",
    "        \n",
    "        correct = np.sum(np.equal((attack_output.data.cpu().numpy() >0.5),(v_is_member_labels.data.cpu().numpy()> 0.5)))\n",
    "        sum_correct += correct\n",
    "        #raise\n",
    "        \n",
    "        # compute gradient and do SGD step\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        # plot progress\n",
    "        if ind%100==0:\n",
    "            print  ('({batch}/{size}) Data: {data:.3f}s | Batch: {bt:.3f}s | | Loss: {loss:.4f} | top1: {top1: .4f} '.format(\n",
    "                    batch=ind + 1,\n",
    "                    size=len_t,\n",
    "                    data=data_time.avg,\n",
    "                    bt=batch_time.avg,\n",
    "                    loss=losses.avg,\n",
    "                    top1=top1.avg,\n",
    "                    ))\n",
    "            \n",
    "#         break\n",
    "#     return (losses.avg, top1.avg)  #,prec1,attack_output,  v_is_member_labels)\n",
    "        \n",
    "    return (losses.avg, top1.avg, sum_correct)\n",
    "\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def attack_test_trainset(train_data,labels, model,attack_model, criterion,attack_criterion, optimizer,attack_optimizer, epoch, use_cuda):\n",
    "    model.eval()\n",
    "    attack_model.eval()\n",
    "    \n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    top5 = AverageMeter()\n",
    "    \n",
    "    sum_correct = 0.0\n",
    "    \n",
    "    end = time.time()\n",
    "#     len_t =  min((len(attack_data)//batch_size) ,(len(train_data)//batch_size))-1\n",
    "    len_t = len(train_data)//batch_size + 1\n",
    "    \n",
    "    for ind in range(len_t):\n",
    "        # measure data loading time\n",
    "        inputs = train_data[ind*batch_size:(ind+1)*batch_size]\n",
    "        targets = labels[ind*batch_size:(ind+1)*batch_size]\n",
    "        \n",
    "#         inputs_attack = attack_data[ind*batch_size:(ind+1)*batch_size]\n",
    "#         targets_attack = attack_label[ind*batch_size:(ind+1)*batch_size]\n",
    "#         #print ( len(targets_attack), len(targets))\n",
    "        \n",
    "        data_time.update(time.time() - end)\n",
    "        if use_cuda:\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "#             inputs_attack , targets_attack = inputs_attack.cuda(), targets_attack.cuda()\n",
    "        inputs, targets = torch.autograd.Variable(inputs), torch.autograd.Variable(targets)\n",
    "#         inputs_attack , targets_attack = torch.autograd.Variable(inputs_attack), torch.autograd.Variable(targets_attack)\n",
    "\n",
    "        # compute output\n",
    "        outputs,h_layer = model(inputs)\n",
    "#         outputs_non,h_layer_non = model(inputs_attack)\n",
    "        \n",
    "        comb_inputs_h = h_layer  #torch.cat((h_layer,h_layer_non))\n",
    "        comb_inputs = outputs  #torch.cat((outputs,outputs_non))\n",
    "        \n",
    "        if use_cuda:\n",
    "#             comb_targets= torch.cat((targets,targets_attack)).view([-1,1]).type(torch.cuda.FloatTensor)\n",
    "            comb_targets= targets.view([-1,1]).type(torch.cuda.FloatTensor)\n",
    "        else:\n",
    "#             comb_targets= torch.cat((targets,targets_attack)).view([-1,1]).type(torch.FloatTensor)\n",
    "            comb_targets= targets.view([-1,1]).type(torch.FloatTensor)\n",
    "            \n",
    "        #print (comb_inputs.size(),comb_targets.size())\n",
    "        attack_input = comb_inputs #torch.cat((comb_inputs,comb_targets),1)\n",
    "        \n",
    "        \n",
    "        one_hot_tr = torch.from_numpy((np.zeros((attack_input.size()[0],outputs.size(1))))).cuda().type(torch.cuda.FloatTensor)\n",
    "#         target_one_hot_tr = one_hot_tr.scatter_(1, torch.cat((targets,targets_attack)).type(torch.cuda.LongTensor).view([-1,1]).data,1)\n",
    "        target_one_hot_tr = one_hot_tr.scatter_(1, targets.type(torch.cuda.LongTensor).view([-1,1]).data,1)\n",
    "        \n",
    "        infer_input_one_hot = torch.autograd.Variable(target_one_hot_tr)\n",
    "         \n",
    "        \n",
    "        \n",
    "        #attack_output = attack_model(att_inp).view([-1])\n",
    "        attack_output = attack_model(attack_input,comb_inputs_h,infer_input_one_hot).view([-1])\n",
    "        #attack_output = attack_model(attack_input).view([-1])\n",
    "        att_labels = np.zeros((inputs.size()[0])) #+inputs_attack.size()[0]))\n",
    "        att_labels [:inputs.size()[0]] =1.0\n",
    "#         att_labels [inputs.size()[0]:] =0.0\n",
    "        is_member_labels = torch.from_numpy(att_labels).type(torch.FloatTensor)\n",
    "        if use_cuda:\n",
    "            is_member_labels = is_member_labels.cuda()\n",
    "        \n",
    "        v_is_member_labels = torch.autograd.Variable(is_member_labels)\n",
    "        \n",
    "        loss = attack_criterion(attack_output, v_is_member_labels)\n",
    "        \n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        #prec1,p5 = accuracy(attack_output.data, v_is_member_labels.data, topk=(1,2))\n",
    "        \n",
    "        prec1=np.mean(np.equal((attack_output.data.cpu().numpy() >0.5),(v_is_member_labels.data.cpu().numpy()> 0.5)))\n",
    "        losses.update(loss.data, attack_input.size()[0])\n",
    "        top1.update(prec1, attack_input.size()[0])\n",
    "        \n",
    "        correct = np.sum(np.equal((attack_output.data.cpu().numpy() >0.5),(v_is_member_labels.data.cpu().numpy()> 0.5)))\n",
    "        sum_correct += correct\n",
    "#         print('prec1: ', prec1)\n",
    "        #raise\n",
    "        \n",
    "        # compute gradient and do SGD step\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        # plot progress\n",
    "        if ind%100==0:\n",
    "            print  ('({batch}/{size}) Data: {data:.3f}s | Batch: {bt:.3f}s | | Loss: {loss:.4f} | top1: {top1: .4f} '.format(\n",
    "                    batch=ind + 1,\n",
    "                    size=len_t,\n",
    "                    data=data_time.avg,\n",
    "                    bt=batch_time.avg,\n",
    "                    loss=losses.avg,\n",
    "                    top1=top1.avg,\n",
    "                    ))\n",
    "#         break\n",
    "            \n",
    "    return (losses.avg, top1.avg, sum_correct)\n",
    "        \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def attack_test_testset(attack_data,labels, model,attack_model, criterion,attack_criterion, optimizer,attack_optimizer, epoch, use_cuda):\n",
    "    model.eval()\n",
    "    attack_model.eval()\n",
    "    \n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    top5 = AverageMeter()\n",
    "    \n",
    "    sum_correct = 0.0\n",
    "    end = time.time()\n",
    "#     len_t =  min((len(attack_data)//batch_size) ,(len(train_data)//batch_size))-1\n",
    "    len_t = len(attack_data)//batch_size + 1\n",
    "    \n",
    "    for ind in range(len_t):\n",
    "        # measure data loading time\n",
    "        inputs = attack_data[ind*batch_size:(ind+1)*batch_size]\n",
    "        targets = labels[ind*batch_size:(ind+1)*batch_size]\n",
    "        \n",
    "#         inputs_attack = attack_data[ind*batch_size:(ind+1)*batch_size]\n",
    "#         targets_attack = attack_label[ind*batch_size:(ind+1)*batch_size]\n",
    "#         #print ( len(targets_attack), len(targets))\n",
    "        \n",
    "        data_time.update(time.time() - end)\n",
    "        if use_cuda:\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "#             inputs_attack , targets_attack = inputs_attack.cuda(), targets_attack.cuda()\n",
    "        inputs, targets = torch.autograd.Variable(inputs), torch.autograd.Variable(targets)\n",
    "#         inputs_attack , targets_attack = torch.autograd.Variable(inputs_attack), torch.autograd.Variable(targets_attack)\n",
    "\n",
    "        # compute output\n",
    "        outputs,h_layer = model(inputs)\n",
    "#         outputs_non,h_layer_non = model(inputs_attack)\n",
    "        \n",
    "        comb_inputs_h = h_layer  #torch.cat((h_layer,h_layer_non))\n",
    "        comb_inputs = outputs  #torch.cat((outputs,outputs_non))\n",
    "        \n",
    "        if use_cuda:\n",
    "#             comb_targets= torch.cat((targets,targets_attack)).view([-1,1]).type(torch.cuda.FloatTensor)\n",
    "            comb_targets= targets.view([-1,1]).type(torch.cuda.FloatTensor)\n",
    "        else:\n",
    "#             comb_targets= torch.cat((targets,targets_attack)).view([-1,1]).type(torch.FloatTensor)\n",
    "            comb_targets= targets.view([-1,1]).type(torch.FloatTensor)\n",
    "            \n",
    "        #print (comb_inputs.size(),comb_targets.size())\n",
    "        attack_input = comb_inputs #torch.cat((comb_inputs,comb_targets),1)\n",
    "        \n",
    "        \n",
    "        one_hot_tr = torch.from_numpy((np.zeros((attack_input.size()[0],outputs.size(1))))).cuda().type(torch.cuda.FloatTensor)\n",
    "#         target_one_hot_tr = one_hot_tr.scatter_(1, torch.cat((targets,targets_attack)).type(torch.cuda.LongTensor).view([-1,1]).data,1)\n",
    "        target_one_hot_tr = one_hot_tr.scatter_(1, targets.type(torch.cuda.LongTensor).view([-1,1]).data,1)\n",
    "        \n",
    "        infer_input_one_hot = torch.autograd.Variable(target_one_hot_tr)\n",
    "         \n",
    "        \n",
    "        \n",
    "        #attack_output = attack_model(att_inp).view([-1])\n",
    "        attack_output = attack_model(attack_input,comb_inputs_h,infer_input_one_hot).view([-1])\n",
    "        #attack_output = attack_model(attack_input).view([-1])\n",
    "        att_labels = np.zeros((inputs.size()[0])) #+inputs_attack.size()[0]))\n",
    "        att_labels [:inputs.size()[0]] =0.0\n",
    "#         att_labels [inputs.size()[0]:] =0.0\n",
    "        is_member_labels = torch.from_numpy(att_labels).type(torch.FloatTensor)\n",
    "        if use_cuda:\n",
    "            is_member_labels = is_member_labels.cuda()\n",
    "        \n",
    "        v_is_member_labels = torch.autograd.Variable(is_member_labels)\n",
    "        \n",
    "        loss = attack_criterion(attack_output, v_is_member_labels)\n",
    "        \n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        #prec1,p5 = accuracy(attack_output.data, v_is_member_labels.data, topk=(1,2))\n",
    "        \n",
    "        prec1=np.mean(np.equal((attack_output.data.cpu().numpy() > 0.5),(v_is_member_labels.data.cpu().numpy()> 0.5)))\n",
    "        losses.update(loss.data, attack_input.size()[0])\n",
    "        top1.update(prec1, attack_input.size()[0])\n",
    "        \n",
    "#         print('prec1: ', prec1)\n",
    "        #raise\n",
    "        correct = np.sum(np.equal((attack_output.data.cpu().numpy() > 0.5),(v_is_member_labels.data.cpu().numpy() > 0.5)))\n",
    "        sum_correct += correct\n",
    "        \n",
    "        # compute gradient and do SGD step\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        # plot progress\n",
    "        if ind%100==0:\n",
    "            print  ('({batch}/{size}) Data: {data:.3f}s | Batch: {bt:.3f}s | | Loss: {loss:.4f} | top1: {top1: .4f} '.format(\n",
    "                    batch=ind + 1,\n",
    "                    size=len_t,\n",
    "                    data=data_time.avg,\n",
    "                    bt=batch_time.avg,\n",
    "                    loss=losses.avg,\n",
    "                    top1=top1.avg,\n",
    "                    ))\n",
    "#         break\n",
    "    return (losses.avg, top1.avg, sum_correct) #, loss, attack_input)\n",
    "        \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def train_defense_softmax(train_data,labels,attack_data,attack_label, model,attack_model, criterion,attack_criterion, optimizer,attack_optimizer, epoch, use_cuda,num_batchs=100000,skip_batch=0):\n",
    "    # switch to train mode\n",
    "    model.eval()\n",
    "    attack_model.train()\n",
    "    \n",
    "    softmax = nn.Softmax()\n",
    "    \n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    top5 = AverageMeter()\n",
    "    \n",
    "    \n",
    "    end = time.time()\n",
    "    len_t =  min((len(attack_data)//batch_size) ,(len(train_data)//batch_size))+1\n",
    "    \n",
    "    #print (skip_batch, len_t)\n",
    "    \n",
    "    for ind in range(skip_batch, len_t):\n",
    "        \n",
    "        if ind >= skip_batch+num_batchs:\n",
    "            break\n",
    "        # measure data loading time\n",
    "        inputs = train_data[ind*batch_size:(ind+1)*batch_size]\n",
    "        targets = labels[ind*batch_size:(ind+1)*batch_size]\n",
    "        \n",
    "        inputs_attack = attack_data[ind*batch_size:(ind+1)*batch_size]\n",
    "        targets_attack = attack_label[ind*batch_size:(ind+1)*batch_size]\n",
    "        #print ( len(targets_attack), len(targets))\n",
    "        \n",
    "        data_time.update(time.time() - end)\n",
    "        if use_cuda:\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "            inputs_attack , targets_attack = inputs_attack.cuda(), targets_attack.cuda()\n",
    "            \n",
    "        inputs, targets = torch.autograd.Variable(inputs), torch.autograd.Variable(targets)\n",
    "        inputs_attack , targets_attack = torch.autograd.Variable(inputs_attack), torch.autograd.Variable(targets_attack)\n",
    "        # compute output\n",
    "        outputs, _,_,_, h_layer = model(inputs)\n",
    "        outputs_non, _,_,_, h_layer_non = model(inputs_attack)\n",
    "        \n",
    "        classifier_input = torch.cat((inputs,inputs_attack))\n",
    "#         comb_inputs_h = torch.cat((h_layer,h_layer_non))\n",
    "        comb_inputs = torch.cat((outputs,outputs_non))\n",
    "        \n",
    "#         if use_cuda:\n",
    "#             comb_targets= torch.cat((targets,targets_attack)).view([-1,1]).type(torch.cuda.FloatTensor)\n",
    "#         else:\n",
    "#             comb_targets= torch.cat((targets,targets_attack)).view([-1,1]).type(torch.FloatTensor)\n",
    "            \n",
    "#         print (comb_inputs.size(),comb_targets.size())\n",
    "#         print('comb_inputs.shape:',comb_inputs.shape)\n",
    "#         print('comb_inputs:', comb_inputs[0,:])\n",
    "        sort_inputs, indices= torch.sort(comb_inputs)\n",
    "#         print('sort_inputs.shape:',sort_inputs.shape)\n",
    "#         print('sort_inputs:', sort_inputs[0,:])\n",
    "#         print(torch.sort(comb_inputs[0,:]))\n",
    "#         break\n",
    "        attack_input = softmax(sort_inputs) #torch.cat((comb_inputs,comb_targets),1)\n",
    "#         print('attack_input:', attack_input[0,:])\n",
    "#         print('attack_input.shape:',attack_input.shape)\n",
    "#         break\n",
    "#         one_hot_tr = torch.from_numpy((np.zeros((attack_input.size()[0],outputs.size(1))))).cuda().type(torch.cuda.FloatTensor)\n",
    "#         target_one_hot_tr = one_hot_tr.scatter_(1, torch.cat((targets,targets_attack)).type(torch.cuda.LongTensor).view([-1,1]).data,1)\n",
    "        \n",
    "#         infer_input_one_hot = torch.autograd.Variable(target_one_hot_tr)\n",
    "         \n",
    "        \n",
    "        \n",
    "#         sf= nn.Softmax(dim=0)\n",
    "        \n",
    "#         att_inp=torch.stack([attack_input, infer_input_one_hot],1)\n",
    "        \n",
    "        \n",
    "#         att_inp = att_inp.view([attack_input.size()[0],1,2,attack_input.size(1)])\n",
    "        \n",
    "        #attack_output = attack_model(att_inp).view([-1])\n",
    "#         attack_output = attack_model(attack_input,comb_inputs_h,infer_input_one_hot).view([-1])\n",
    "#         attack_output = attack_model(attack_input).view([-1])\n",
    "        attack_output,_ = attack_model(attack_input)\n",
    "        attack_output = attack_output.view([-1])\n",
    "        att_labels = np.zeros((inputs.size()[0]+inputs_attack.size()[0]))\n",
    "        att_labels [:inputs.size()[0]] =1.0\n",
    "        att_labels [inputs.size()[0]:] =0.0\n",
    "        is_member_labels = torch.from_numpy(att_labels).type(torch.FloatTensor)\n",
    "        \n",
    "        if use_cuda:\n",
    "            is_member_labels = is_member_labels.cuda()\n",
    "        \n",
    "        v_is_member_labels = torch.autograd.Variable(is_member_labels)\n",
    "        \n",
    "        \n",
    "#         classifier_targets = comb_targets.clone().view([-1]).type(torch.cuda.LongTensor)\n",
    "        \n",
    "        loss_attack = attack_criterion(attack_output, v_is_member_labels)\n",
    "        \n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        #prec1,p5 = accuracy(attack_output.data, v_is_member_labels.data, topk=(1,2))\n",
    "        \n",
    "        prec1=np.mean(np.equal((attack_output.data.cpu().numpy() >0.5),(v_is_member_labels.data.cpu().numpy()> 0.5)))\n",
    "        losses.update(loss_attack.data, attack_input.size()[0])\n",
    "        top1.update(prec1, attack_input.size()[0])\n",
    "        \n",
    "        #print ( attack_output.data.cpu().numpy(),v_is_member_labels.data.cpu().numpy() ,attack_input.data.cpu().numpy())\n",
    "        #raise\n",
    "        \n",
    "        \n",
    "        # compute gradient and do SGD step\n",
    "        attack_optimizer.zero_grad()\n",
    "        loss_attack.backward()\n",
    "        attack_optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        # plot progress\n",
    "        if ind%100==0:\n",
    "            print  ('({batch}/{size}) Data: {data:.3f}s | Batch: {bt:.3f}s | | Loss: {loss:.4f} | top1: {top1: .4f} '.format(\n",
    "                    batch=ind + 1,\n",
    "                    size=len_t,\n",
    "                    data=data_time.avg,\n",
    "                    bt=batch_time.avg,\n",
    "                    loss=losses.avg,\n",
    "                    top1=top1.avg,\n",
    "                    ))\n",
    "    return (losses.avg, top1.avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def test_defense_softmax(train_data,labels,attack_data,attack_label, model,attack_model, criterion,attack_criterion, optimizer,attack_optimizer, epoch, use_cuda):\n",
    "    model.eval()\n",
    "    attack_model.eval()\n",
    "    \n",
    "    softmax = nn.Softmax()\n",
    "\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    top5 = AverageMeter()\n",
    "    \n",
    "    sum_correct = 0.0\n",
    "    \n",
    "    end = time.time()\n",
    "    len_t =  min((len(attack_data)//batch_size) ,(len(train_data)//batch_size))+1\n",
    "#     print(len_t)\n",
    "    for ind in range(len_t):\n",
    "        # measure data loading time\n",
    "        inputs = train_data[ind*batch_size:(ind+1)*batch_size]\n",
    "        targets = labels[ind*batch_size:(ind+1)*batch_size]\n",
    "        \n",
    "        inputs_attack = attack_data[ind*batch_size:(ind+1)*batch_size]\n",
    "        targets_attack = attack_label[ind*batch_size:(ind+1)*batch_size]\n",
    "        #print ( len(targets_attack), len(targets))\n",
    "        \n",
    "        data_time.update(time.time() - end)\n",
    "        if use_cuda:\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "            inputs_attack , targets_attack = inputs_attack.cuda(), targets_attack.cuda()\n",
    "        inputs, targets = torch.autograd.Variable(inputs), torch.autograd.Variable(targets)\n",
    "        inputs_attack , targets_attack = torch.autograd.Variable(inputs_attack), torch.autograd.Variable(targets_attack)\n",
    "\n",
    "        # compute output\n",
    "        outputs, _,_,_,h_layer = model(inputs)\n",
    "        outputs_non, _,_,_,h_layer_non = model(inputs_attack)\n",
    "        \n",
    "#         comb_inputs_h = torch.cat((h_layer,h_layer_non))\n",
    "        comb_inputs = torch.cat((outputs,outputs_non))\n",
    "        \n",
    "#         if use_cuda:\n",
    "#             comb_targets= torch.cat((targets,targets_attack)).view([-1,1]).type(torch.cuda.FloatTensor)\n",
    "#         else:\n",
    "#             comb_targets= torch.cat((targets,targets_attack)).view([-1,1]).type(torch.FloatTensor)\n",
    "            \n",
    "        #print (comb_inputs.size(),comb_targets.size())\n",
    "        sort_inputs, indices= torch.sort(comb_inputs)\n",
    "        attack_input = softmax(sort_inputs) #torch.cat((comb_inputs,comb_targets),1)\n",
    "        \n",
    "        \n",
    "#         one_hot_tr = torch.from_numpy((np.zeros((attack_input.size()[0],outputs.size(1))))).cuda().type(torch.cuda.FloatTensor)\n",
    "#         target_one_hot_tr = one_hot_tr.scatter_(1, torch.cat((targets,targets_attack)).type(torch.cuda.LongTensor).view([-1,1]).data,1)\n",
    "        \n",
    "#         infer_input_one_hot = torch.autograd.Variable(target_one_hot_tr)\n",
    "         \n",
    "        \n",
    "        \n",
    "        #attack_output = attack_model(att_inp).view([-1])\n",
    "#         attack_output = attack_model(attack_input,comb_inputs_h,infer_input_one_hot).view([-1])\n",
    "#         attack_output = attack_model(attack_input).view([-1])\n",
    "        attack_output,_ = attack_model(attack_input)\n",
    "        attack_output = attack_output.view([-1])\n",
    "        att_labels = np.zeros((inputs.size()[0]+inputs_attack.size()[0]))\n",
    "        att_labels [:inputs.size()[0]] =1.0\n",
    "        att_labels [inputs.size()[0]:] =0.0\n",
    "        is_member_labels = torch.from_numpy(att_labels).type(torch.FloatTensor)\n",
    "        if use_cuda:\n",
    "            is_member_labels = is_member_labels.cuda()\n",
    "        \n",
    "        v_is_member_labels = torch.autograd.Variable(is_member_labels)\n",
    "\n",
    "        \n",
    "        loss = attack_criterion(attack_output, v_is_member_labels)\n",
    "        \n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        #prec1,p5 = accuracy(attack_output.data, v_is_member_labels.data, topk=(1,2))\n",
    "        \n",
    "        prec1=np.mean(np.equal((attack_output.data.cpu().numpy() >0.5),(v_is_member_labels.data.cpu().numpy()> 0.5)))\n",
    "        losses.update(loss.data, attack_input.size()[0])\n",
    "        top1.update(prec1, attack_input.size()[0])\n",
    "        \n",
    "        correct = np.sum(np.equal((attack_output.data.cpu().numpy() >0.5),(v_is_member_labels.data.cpu().numpy()> 0.5)))\n",
    "        sum_correct += correct\n",
    "        #raise\n",
    "        \n",
    "        # compute gradient and do SGD step\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        # plot progress\n",
    "        if ind%100==0:\n",
    "            print  ('({batch}/{size}) Data: {data:.3f}s | Batch: {bt:.3f}s | | Loss: {loss:.4f} | top1: {top1: .4f} '.format(\n",
    "                    batch=ind + 1,\n",
    "                    size=len_t,\n",
    "                    data=data_time.avg,\n",
    "                    bt=batch_time.avg,\n",
    "                    loss=losses.avg,\n",
    "                    top1=top1.avg,\n",
    "                    ))\n",
    "            \n",
    "#         break\n",
    "#     return (losses.avg, top1.avg)  #,prec1,attack_output,  v_is_member_labels)\n",
    "        \n",
    "    return (losses.avg, top1.avg, sum_correct)\n",
    "\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def test_defense_softmax_unsort(train_data,labels,attack_data,attack_label, model,attack_model, criterion,attack_criterion, optimizer,attack_optimizer, epoch, use_cuda):\n",
    "    model.eval()\n",
    "    attack_model.eval()\n",
    "    \n",
    "    softmax = nn.Softmax()\n",
    "\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    top5 = AverageMeter()\n",
    "    \n",
    "    sum_correct = 0.0\n",
    "    \n",
    "    end = time.time()\n",
    "    len_t =  min((len(attack_data)//batch_size) ,(len(train_data)//batch_size))+1\n",
    "#     print(len_t)\n",
    "    for ind in range(len_t):\n",
    "        # measure data loading time\n",
    "        inputs = train_data[ind*batch_size:(ind+1)*batch_size]\n",
    "        targets = labels[ind*batch_size:(ind+1)*batch_size]\n",
    "        \n",
    "        inputs_attack = attack_data[ind*batch_size:(ind+1)*batch_size]\n",
    "        targets_attack = attack_label[ind*batch_size:(ind+1)*batch_size]\n",
    "        #print ( len(targets_attack), len(targets))\n",
    "        \n",
    "        data_time.update(time.time() - end)\n",
    "        if use_cuda:\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "            inputs_attack , targets_attack = inputs_attack.cuda(), targets_attack.cuda()\n",
    "        inputs, targets = torch.autograd.Variable(inputs), torch.autograd.Variable(targets)\n",
    "        inputs_attack , targets_attack = torch.autograd.Variable(inputs_attack), torch.autograd.Variable(targets_attack)\n",
    "\n",
    "        # compute output\n",
    "        outputs,h_layer = model(inputs)\n",
    "        outputs_non,h_layer_non = model(inputs_attack)\n",
    "        \n",
    "#         comb_inputs_h = torch.cat((h_layer,h_layer_non))\n",
    "        comb_inputs = torch.cat((outputs,outputs_non))\n",
    "        \n",
    "#         if use_cuda:\n",
    "#             comb_targets= torch.cat((targets,targets_attack)).view([-1,1]).type(torch.cuda.FloatTensor)\n",
    "#         else:\n",
    "#             comb_targets= torch.cat((targets,targets_attack)).view([-1,1]).type(torch.FloatTensor)\n",
    "            \n",
    "        #print (comb_inputs.size(),comb_targets.size())\n",
    "#         ---------------sort-------------------------------\n",
    "#         sort_inputs, indices= torch.sort(comb_inputs)\n",
    "#         attack_input = softmax(sort_inputs) #torch.cat((comb_inputs,comb_targets),1)\n",
    "#         ---------------sort-------------------------------\n",
    "        attack_input = softmax(comb_inputs)\n",
    "        \n",
    "#         one_hot_tr = torch.from_numpy((np.zeros((attack_input.size()[0],outputs.size(1))))).cuda().type(torch.cuda.FloatTensor)\n",
    "#         target_one_hot_tr = one_hot_tr.scatter_(1, torch.cat((targets,targets_attack)).type(torch.cuda.LongTensor).view([-1,1]).data,1)\n",
    "        \n",
    "#         infer_input_one_hot = torch.autograd.Variable(target_one_hot_tr)\n",
    "         \n",
    "        \n",
    "        \n",
    "        #attack_output = attack_model(att_inp).view([-1])\n",
    "#         attack_output = attack_model(attack_input,comb_inputs_h,infer_input_one_hot).view([-1])\n",
    "#         attack_output = attack_model(attack_input).view([-1])\n",
    "        attack_output,_ = attack_model(attack_input)\n",
    "        attack_output = attack_output.view([-1])\n",
    "        att_labels = np.zeros((inputs.size()[0]+inputs_attack.size()[0]))\n",
    "        att_labels [:inputs.size()[0]] =1.0\n",
    "        att_labels [inputs.size()[0]:] =0.0\n",
    "        is_member_labels = torch.from_numpy(att_labels).type(torch.FloatTensor)\n",
    "        if use_cuda:\n",
    "            is_member_labels = is_member_labels.cuda()\n",
    "        \n",
    "        v_is_member_labels = torch.autograd.Variable(is_member_labels)\n",
    "\n",
    "        \n",
    "        loss = attack_criterion(attack_output, v_is_member_labels)\n",
    "        \n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        #prec1,p5 = accuracy(attack_output.data, v_is_member_labels.data, topk=(1,2))\n",
    "        \n",
    "        prec1=np.mean(np.equal((attack_output.data.cpu().numpy() >0.5),(v_is_member_labels.data.cpu().numpy()> 0.5)))\n",
    "        losses.update(loss.data, attack_input.size()[0])\n",
    "        top1.update(prec1, attack_input.size()[0])\n",
    "        \n",
    "        correct = np.sum(np.equal((attack_output.data.cpu().numpy() >0.5),(v_is_member_labels.data.cpu().numpy()> 0.5)))\n",
    "        sum_correct += correct\n",
    "        #raise\n",
    "        \n",
    "        # compute gradient and do SGD step\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        # plot progress\n",
    "        if ind%100==0:\n",
    "            print  ('({batch}/{size}) Data: {data:.3f}s | Batch: {bt:.3f}s | | Loss: {loss:.4f} | top1: {top1: .4f} '.format(\n",
    "                    batch=ind + 1,\n",
    "                    size=len_t,\n",
    "                    data=data_time.avg,\n",
    "                    bt=batch_time.avg,\n",
    "                    loss=losses.avg,\n",
    "                    top1=top1.avg,\n",
    "                    ))\n",
    "            \n",
    "#         break\n",
    "#     return (losses.avg, top1.avg)  #,prec1,attack_output,  v_is_member_labels)\n",
    "        \n",
    "    return (losses.avg, top1.avg, sum_correct)\n",
    "\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "classes = 100\n",
    "\n",
    "# Complement Entropy (CE)\n",
    "\n",
    "\n",
    "class ComplementEntropy(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(ComplementEntropy, self).__init__()\n",
    "\n",
    "    # here we implemented step by step for corresponding to our formula\n",
    "    # described in the paper\n",
    "    def forward(self, yHat, y):\n",
    "        self.batch_size = len(y)\n",
    "        self.classes = classes\n",
    "        yHat = F.softmax(yHat, dim=1)\n",
    "        Yg = torch.gather(yHat, 1, torch.unsqueeze(y, 1))\n",
    "        Yg_ = (1 - Yg) + 1e-7  # avoiding numerical issues (first)\n",
    "        Px = yHat / Yg_.view(len(yHat), 1)\n",
    "        Px_log = torch.log(Px + 1e-10)  # avoiding numerical issues (second)\n",
    "        y_zerohot = torch.ones(self.batch_size, self.classes).scatter_(\n",
    "            1, y.view(self.batch_size, 1).data.cpu(), 0)\n",
    "        output = Px * Px_log * y_zerohot.cuda()\n",
    "        loss = torch.sum(output)\n",
    "        loss /= float(self.batch_size)\n",
    "        loss /= float(self.classes)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "classes = 100\n",
    "\n",
    "class GuidedComplementEntropy(nn.Module):\n",
    "\n",
    "    def __init__(self, alpha):\n",
    "        super(GuidedComplementEntropy, self).__init__()\n",
    "        self.alpha = alpha\n",
    "\n",
    "    # here we implemented step by step for corresponding to our formula\n",
    "    # described in the paper\n",
    "    def forward(self, yHat, y):\n",
    "        self.batch_size = len(y)\n",
    "        self.classes = classes\n",
    "        yHat = F.softmax(yHat, dim=1)\n",
    "        Yg = torch.gather(yHat, 1, torch.unsqueeze(y, 1))\n",
    "        Yg_ = (1 - Yg) + 1e-7  # avoiding numerical issues (first)\n",
    "        # avoiding numerical issues (second)\n",
    "        guided_factor = (Yg + 1e-7) ** self.alpha\n",
    "        Px = yHat / Yg_.view(len(yHat), 1)\n",
    "        Px_log = torch.log(Px + 1e-10)  # avoiding numerical issues (third)\n",
    "        y_zerohot = torch.ones(self.batch_size, self.classes).scatter_(\n",
    "            1, y.view(self.batch_size, 1).data.cpu(), 0)\n",
    "        output = Px * Px_log * y_zerohot.cuda()\n",
    "        guided_output = guided_factor.squeeze() * torch.sum(output, dim=1)\n",
    "        loss = torch.sum(guided_output)\n",
    "        loss /= float(self.batch_size)\n",
    "        loss /= math.log(float(self.classes))\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def train_mod8(train_data,labels, model, criterion, optimizer, epoch, use_cuda,num_batchs=999999, alpha = 1.0):\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "    softmax = nn.Softmax()\n",
    "\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    losses_var = AverageMeter()\n",
    "    max_train_outputs = AverageMeter()\n",
    "    min_train_outputs = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    top5 = AverageMeter()\n",
    "    \n",
    "    print('alpha: ', alpha)\n",
    "    end = time.time()\n",
    "    len_t =  (len(train_data)//batch_size)-1\n",
    "    \n",
    "    for ind in range(len_t):\n",
    "        if ind > num_batchs:\n",
    "            break\n",
    "        # measure data loading time\n",
    "        inputs = train_data[ind*batch_size:(ind+1)*batch_size]\n",
    "        targets = labels[ind*batch_size:(ind+1)*batch_size]\n",
    "        data_time.update(time.time() - end)\n",
    "        if use_cuda:\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "        inputs, targets = torch.autograd.Variable(inputs), torch.autograd.Variable(targets)\n",
    "\n",
    "        # compute output\n",
    "        outputs,_ = model(inputs)\n",
    "        \n",
    "        soft_outputs = softmax(outputs)\n",
    "        max_outputs = torch.max(soft_outputs,1).values\n",
    "        min_outputs = torch.min(max_outputs)\n",
    "        \n",
    "        mean_outputs = torch.mean(soft_outputs)\n",
    "        var = torch.mean(torch.sum((soft_outputs - mean_outputs).pow(2),1))\n",
    "        \n",
    "        loss = criterion(outputs, targets) + alpha*var \n",
    "        \n",
    "#         loss = criterion(outputs, targets)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        prec1, prec5 = accuracy(outputs.data, targets.data, topk=(1, 5))\n",
    "        losses.update(loss.data, inputs.size()[0])\n",
    "        losses_var.update(var.data, inputs.size()[0])\n",
    "        top1.update(prec1, inputs.size()[0])\n",
    "        top5.update(prec5, inputs.size()[0])\n",
    "        max_train_outputs.update(torch.mean(max_outputs), inputs.size()[0])\n",
    "        min_train_outputs.update(min_outputs, inputs.size()[0])\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        # plot progress\n",
    "        if ind%100==0:\n",
    "            print  ('({batch}/{size}) Data: {data:.3f}s | Batch: {bt:.3f}s| Loss: {loss:.4f} | Var: {loss_var:.4f} | Max: {tmax:.4f} | Min: {tmin:.4f}| top1: {top1: .4f} | top5: {top5: .4f}'.format(\n",
    "                    batch=ind + 1,\n",
    "                    size=len_t,\n",
    "                    data=data_time.avg,\n",
    "                    bt=batch_time.avg,\n",
    "                    loss=losses.avg,\n",
    "                    loss_var=losses_var.avg,\n",
    "                    tmax = max_train_outputs.avg,\n",
    "                    tmin = min_train_outputs.avg,\n",
    "                    top1=top1.avg,\n",
    "                    top5=top5.avg,\n",
    "                    ))\n",
    "    return (losses.avg,losses_var.avg, top1.avg)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def train_mod9(train_data,labels,untrain_data, untrain_labels, model, criterion, optimizer, epoch, use_cuda,num_batchs=999999, alpha = 1.0, beta = 1.0,lamd = 1.0):\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "    softmax = nn.Softmax()\n",
    "\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    losses_d = AverageMeter()\n",
    "    losses_a = AverageMeter()\n",
    "    losses_var = AverageMeter()\n",
    "    max_train_outputs = AverageMeter()\n",
    "    max_untrain_outputs = AverageMeter()\n",
    "    min_untrain_outputs = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    top5 = AverageMeter()\n",
    "    \n",
    "    print('alpha: ', alpha, ' beta: ', beta, ', lamd: ',lamd)\n",
    "    end = time.time()\n",
    "    len_t =  (len(train_data)//batch_size)-1\n",
    "    \n",
    "    for ind in range(len_t):\n",
    "        if ind > num_batchs:\n",
    "            break\n",
    "        # measure data loading time\n",
    "        inputs = train_data[ind*batch_size:(ind+1)*batch_size]\n",
    "        targets = labels[ind*batch_size:(ind+1)*batch_size]\n",
    "        r= np.arange(untrain_data.shape[0])\n",
    "        np.random.shuffle(r)\n",
    "        untrain_inputs = untrain_data[r[:batch_size]]\n",
    "        untrain_targets = untrain_labels[r[:batch_size]]\n",
    "\n",
    "        data_time.update(time.time() - end)\n",
    "        if use_cuda:\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "            untrain_inputs, untrain_targets = untrain_inputs.cuda(), untrain_targets.cuda()\n",
    "        inputs, targets = torch.autograd.Variable(inputs), torch.autograd.Variable(targets)\n",
    "        untrain_inputs, untrain_targets = torch.autograd.Variable(untrain_inputs), torch.autograd.Variable(untrain_targets)\n",
    "\n",
    "        # compute output\n",
    "        outputs,_ = model(inputs)\n",
    "        untrain_outputs,_ = model(untrain_inputs)\n",
    "\n",
    "        soft_outputs = softmax(outputs)\n",
    "        soft_untrain_outputs = softmax(untrain_outputs)\n",
    "\n",
    "        sort_soft_outputs,_ = torch.sort(soft_outputs)\n",
    "        sort_soft_untrain_outputs,_ = torch.sort(soft_untrain_outputs)\n",
    "        \n",
    "        mean_outputs = torch.mean(soft_outputs)\n",
    "        var = torch.mean(torch.sum((soft_outputs - mean_outputs).pow(2),1))\n",
    "        \n",
    "        loss_d = alpha*(torch.mean(torch.sum(torch.abs(sort_soft_outputs - sort_soft_untrain_outputs),1)))\n",
    "#         print('loss_d: ', loss_d)\n",
    "        max_soft_outputs = torch.max(soft_outputs,1).values\n",
    "        max_soft_untrain_outputs = torch.mean(torch.max(sort_soft_untrain_outputs,1).values)\n",
    "        min_soft_untrain_outputs = torch.min(torch.max(sort_soft_untrain_outputs,1).values)\n",
    "#         print('max_soft_outputs: ', max_soft_outputs)\n",
    "#         print('max_soft_untrain_outputs: ', max_soft_untrain_outputs)\n",
    "#         print('min_soft_untrain_outputs: ', min_soft_untrain_outputs)\n",
    "#         max_untrain_outputs = max_untrain_outputs + max_soft_untrain_outputs\n",
    "        loss_a = beta*torch.mean(torch.abs(max_soft_outputs - min_soft_untrain_outputs))\n",
    "#         print('loss_a: ', loss_a)\n",
    "        loss = criterion(outputs, targets) + loss_d + loss_a + lamd*var\n",
    "#         print('loss: ', loss)\n",
    "#         print('inputs.size()[0]: ', inputs.size()[0])\n",
    "#         loss = criterion(outputs, targets)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        prec1, prec5 = accuracy(outputs.data, targets.data, topk=(1, 5))\n",
    "        losses.update(loss.data, inputs.size()[0])\n",
    "        losses_d.update(loss_d.data, untrain_inputs.size()[0])\n",
    "        losses_a.update(loss_a.data, untrain_inputs.size()[0])\n",
    "        max_train_outputs.update(torch.mean(max_soft_outputs), inputs.size()[0])\n",
    "#         max_untrain_outputs.update(max_soft_untrain_outputs, 1)\n",
    "        max_untrain_outputs.update(max_soft_untrain_outputs, inputs.size()[0])\n",
    "        min_untrain_outputs.update(min_soft_untrain_outputs, inputs.size()[0])\n",
    "        top1.update(prec1, inputs.size()[0])\n",
    "        top5.update(prec5, inputs.size()[0])\n",
    "        losses_var.update(var.data, inputs.size()[0])\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "        \n",
    "        # plot progress\n",
    "        if ind%100==0:\n",
    "            print  ('({batch}/{size})| Loss: {loss:.4f}| Loss_d: {loss_d:.4f}| Loss_a:{loss_a:.4f}|max train:{max_train:.4f}|max untrain:{max_untrain:.4f}|min: {min_untrain:.4f}|top1:{top1: .4f}|top5:{top5: .4f}'.format(\n",
    "                    batch=ind + 1,\n",
    "                    size=len_t,\n",
    "#                     data=data_time.avg,\n",
    "#                     bt=batch_time.avg,\n",
    "                    loss=losses.avg,\n",
    "                    loss_d = losses_d.avg,\n",
    "                    loss_a = losses_a.avg,\n",
    "                    max_train = max_train_outputs.avg,\n",
    "                    max_untrain = max_untrain_outputs.avg,    #torch.mean(max_untrain_outputs),\n",
    "                    min_untrain = min_untrain_outputs.avg,\n",
    "                    top1=top1.avg,\n",
    "                    top5=top5.avg,\n",
    "                    ))\n",
    "#             print  ('({batch}/{size}) Data: {data:.3f}s | Batch: {bt:.3f}s | | Loss: {loss:.4f} |  Loss_d: {loss_d:.4f} |  Loss_a: {loss_a:.4f} | top1: {top1: .4f} | top5: {top5: .4f}'.format(\n",
    "#                     batch=ind + 1,\n",
    "#                     size=len_t,\n",
    "#                     data=data_time.avg,\n",
    "#                     bt=batch_time.avg,\n",
    "#                     loss=losses.avg,\n",
    "#                     loss_d = losses_d.avg,\n",
    "#                     loss_a = losses_a.avg,\n",
    "\n",
    "#                     top1=top1.avg,\n",
    "#                     top5=top5.avg,\n",
    "#                     ))\n",
    "    return (losses.avg, losses_d.avg, losses_a.avg, losses_var.avg, top1.avg)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def test_mod8(test_data,labels, model, criterion, epoch, use_cuda):\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    losses_var = AverageMeter()\n",
    "    max_train_outputs = AverageMeter()\n",
    "    min_train_outputs = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    top5 = AverageMeter()\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "    softmax = nn.Softmax()\n",
    "    end = time.time()\n",
    "    len_t =  (len(test_data)//batch_size)\n",
    "    \n",
    "    for ind in range(len_t):\n",
    "        # measure data loading time\n",
    "        inputs = test_data[ind*batch_size:(ind+1)*batch_size]\n",
    "        targets = labels[ind*batch_size:(ind+1)*batch_size]\n",
    "        \n",
    "        data_time.update(time.time() - end)\n",
    "        if use_cuda:\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "        inputs, targets = torch.autograd.Variable(inputs, volatile=True), torch.autograd.Variable(targets)\n",
    "\n",
    "        # compute output\n",
    "        outputs,_ = model(inputs)\n",
    "        \n",
    "        loss = criterion(outputs, targets)\n",
    "        soft_outputs = softmax(outputs)\n",
    "        max_outputs = torch.max(soft_outputs,1).values\n",
    "        min_outputs = torch.min(max_outputs)\n",
    "        \n",
    "        mean_outputs = torch.mean(soft_outputs)\n",
    "        var = torch.mean(torch.sum((soft_outputs - mean_outputs).pow(2),1))\n",
    "        \n",
    "        # measure accuracy and record loss\n",
    "        prec1, prec5 = accuracy(outputs.data, targets.data, topk=(1, 5))\n",
    "        losses.update(loss.data, inputs.size()[0])\n",
    "        losses_var.update(var.data, inputs.size()[0])\n",
    "        top1.update(prec1, inputs.size()[0])\n",
    "        top5.update(prec5, inputs.size()[0])\n",
    "        max_train_outputs.update(torch.mean(max_outputs), inputs.size()[0])\n",
    "        min_train_outputs.update(min_outputs, inputs.size()[0])\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        # plot progress\n",
    "        if ind % 100==0:\n",
    "            \n",
    "            print  ('({batch}/{size}) Data: {data:.3f}s | Batch: {bt:.3f}s| Loss: {loss:.4f} | Var: {loss_var:.4f} | Max: {tmax:.4f} | Min: {tmin:.4f}| top1: {top1: .4f} | top5: {top5: .4f}'.format(\n",
    "                    batch=ind + 1,\n",
    "                    size=len_t,\n",
    "                    data=data_time.avg,\n",
    "                    bt=batch_time.avg,\n",
    "                    loss=losses.avg,\n",
    "                    loss_var=losses_var.avg,\n",
    "                    tmax = max_train_outputs.avg,\n",
    "                    tmin = min_train_outputs.avg,\n",
    "                    top1=top1.avg,\n",
    "                    top5=top5.avg,\n",
    "                    ))\n",
    "    return (losses.avg, losses_var.avg, top1.avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def train_attack_softmax_sort_mod(train_data,labels,attack_data,attack_label, model,attack_model, criterion,attack_criterion, optimizer,attack_optimizer, epoch, use_cuda,num_batchs=100000,skip_batch=0):\n",
    "    # switch to train mode\n",
    "    model.eval()\n",
    "    attack_model.train()\n",
    "    \n",
    "    softmax = nn.Softmax()\n",
    "    \n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    top5 = AverageMeter()\n",
    "    \n",
    "    \n",
    "    end = time.time()\n",
    "    len_t =  min((len(attack_data)//batch_size) ,(len(train_data)//batch_size))+1\n",
    "    \n",
    "    #print (skip_batch, len_t)\n",
    "    \n",
    "    for ind in range(skip_batch, len_t):\n",
    "        \n",
    "        if ind >= skip_batch+num_batchs:\n",
    "            break\n",
    "        # measure data loading time\n",
    "        inputs = train_data[ind*batch_size:(ind+1)*batch_size]\n",
    "        targets = labels[ind*batch_size:(ind+1)*batch_size]\n",
    "        \n",
    "        inputs_attack = attack_data[ind*batch_size:(ind+1)*batch_size]\n",
    "        targets_attack = attack_label[ind*batch_size:(ind+1)*batch_size]\n",
    "        #print ( len(targets_attack), len(targets))\n",
    "        \n",
    "        data_time.update(time.time() - end)\n",
    "        if use_cuda:\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "            inputs_attack , targets_attack = inputs_attack.cuda(), targets_attack.cuda()\n",
    "            \n",
    "        inputs, targets = torch.autograd.Variable(inputs), torch.autograd.Variable(targets)\n",
    "        inputs_attack , targets_attack = torch.autograd.Variable(inputs_attack), torch.autograd.Variable(targets_attack)\n",
    "        # compute output\n",
    "        outputs, h_layer = model(inputs)\n",
    "        outputs_non, h_layer_non = model(inputs_attack)\n",
    "        \n",
    "        classifier_input = torch.cat((inputs,inputs_attack))\n",
    "        comb_inputs_h = torch.cat((h_layer,h_layer_non))\n",
    "        comb_inputs = torch.cat((outputs,outputs_non))\n",
    "        \n",
    "        if use_cuda:\n",
    "            comb_targets= torch.cat((targets,targets_attack)).view([-1,1]).type(torch.cuda.FloatTensor)\n",
    "        else:\n",
    "            comb_targets= torch.cat((targets,targets_attack)).view([-1,1]).type(torch.FloatTensor)\n",
    "            \n",
    "        #print (comb_inputs.size(),comb_targets.size())\n",
    "        \n",
    "        sort_inputs, indices= torch.sort(comb_inputs)\n",
    "        \n",
    "        attack_input = softmax(sort_inputs) #torch.cat((comb_inputs,comb_targets),1)\n",
    "        \n",
    "        \n",
    "        one_hot_tr = torch.from_numpy((np.zeros((attack_input.size()[0],outputs.size(1))))).cuda().type(torch.cuda.FloatTensor)\n",
    "        target_one_hot_tr = one_hot_tr.scatter_(1, torch.cat((targets,targets_attack)).type(torch.cuda.LongTensor).view([-1,1]).data,1)\n",
    "        \n",
    "        for i in range(len(indices)):\n",
    "            target_one_hot_tr[i] = target_one_hot_tr[i][indices[i]]\n",
    "        \n",
    "        infer_input_one_hot = torch.autograd.Variable(target_one_hot_tr)\n",
    "        \n",
    "        \n",
    "#         sf= nn.Softmax(dim=0)\n",
    "        \n",
    "#         att_inp=torch.stack([attack_input, infer_input_one_hot],1)\n",
    "        \n",
    "        \n",
    "#         att_inp = att_inp.view([attack_input.size()[0],1,2,attack_input.size(1)])\n",
    "        \n",
    "        #attack_output = attack_model(att_inp).view([-1])\n",
    "#         attack_output = attack_model(attack_input,comb_inputs_h,infer_input_one_hot).view([-1])\n",
    "        attack_output, _ = attack_model(attack_input,comb_inputs_h,infer_input_one_hot)\n",
    "        attack_output = attack_output.view([-1])\n",
    "        #attack_output = attack_model(attack_input).view([-1])\n",
    "        att_labels = np.zeros((inputs.size()[0]+inputs_attack.size()[0]))\n",
    "        att_labels [:inputs.size()[0]] =1.0\n",
    "        att_labels [inputs.size()[0]:] =0.0\n",
    "        is_member_labels = torch.from_numpy(att_labels).type(torch.FloatTensor)\n",
    "        \n",
    "        if use_cuda:\n",
    "            is_member_labels = is_member_labels.cuda()\n",
    "        \n",
    "        v_is_member_labels = torch.autograd.Variable(is_member_labels)\n",
    "        \n",
    "        \n",
    "#         classifier_targets = comb_targets.clone().view([-1]).type(torch.cuda.LongTensor)\n",
    "        \n",
    "        loss_attack = attack_criterion(attack_output, v_is_member_labels)\n",
    "        \n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        #prec1,p5 = accuracy(attack_output.data, v_is_member_labels.data, topk=(1,2))\n",
    "        \n",
    "        prec1=np.mean(np.equal((attack_output.data.cpu().numpy() >0.5),(v_is_member_labels.data.cpu().numpy()> 0.5)))\n",
    "        losses.update(loss_attack.data, attack_input.size()[0])\n",
    "        top1.update(prec1, attack_input.size()[0])\n",
    "        \n",
    "        #print ( attack_output.data.cpu().numpy(),v_is_member_labels.data.cpu().numpy() ,attack_input.data.cpu().numpy())\n",
    "        #raise\n",
    "        \n",
    "        \n",
    "        \n",
    "        # compute gradient and do SGD step\n",
    "        attack_optimizer.zero_grad()\n",
    "        loss_attack.backward()\n",
    "        attack_optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        # plot progress\n",
    "        if ind%100==0:\n",
    "            print  ('({batch}/{size}) Data: {data:.3f}s | Batch: {bt:.3f}s | | Loss: {loss:.4f} | top1: {top1: .4f} '.format(\n",
    "                    batch=ind + 1,\n",
    "                    size=len_t,\n",
    "                    data=data_time.avg,\n",
    "                    bt=batch_time.avg,\n",
    "                    loss=losses.avg,\n",
    "                    top1=top1.avg,\n",
    "                    ))\n",
    "    return (losses.avg, top1.avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def test_attack_softmax_sort_mod(train_data,labels,attack_data,attack_label, model,attack_model, criterion,attack_criterion, optimizer,attack_optimizer, epoch, use_cuda):\n",
    "    model.eval()\n",
    "    attack_model.eval()\n",
    "    \n",
    "    softmax = nn.Softmax()\n",
    "\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    top5 = AverageMeter()\n",
    "    \n",
    "    sum_correct = 0.0\n",
    "    \n",
    "    end = time.time()\n",
    "    len_t =  min((len(attack_data)//batch_size) ,(len(train_data)//batch_size))+1\n",
    "    \n",
    "    for ind in range(len_t):\n",
    "        # measure data loading time\n",
    "        inputs = train_data[ind*batch_size:(ind+1)*batch_size]\n",
    "        targets = labels[ind*batch_size:(ind+1)*batch_size]\n",
    "        \n",
    "        inputs_attack = attack_data[ind*batch_size:(ind+1)*batch_size]\n",
    "        targets_attack = attack_label[ind*batch_size:(ind+1)*batch_size]\n",
    "        #print ( len(targets_attack), len(targets))\n",
    "        \n",
    "        data_time.update(time.time() - end)\n",
    "        if use_cuda:\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "            inputs_attack , targets_attack = inputs_attack.cuda(), targets_attack.cuda()\n",
    "        inputs, targets = torch.autograd.Variable(inputs), torch.autograd.Variable(targets)\n",
    "        inputs_attack , targets_attack = torch.autograd.Variable(inputs_attack), torch.autograd.Variable(targets_attack)\n",
    "\n",
    "        # compute output\n",
    "        outputs,h_layer = model(inputs)\n",
    "        outputs_non,h_layer_non = model(inputs_attack)\n",
    "        \n",
    "        comb_inputs_h = torch.cat((h_layer,h_layer_non))\n",
    "        comb_inputs = torch.cat((outputs,outputs_non))\n",
    "        \n",
    "        if use_cuda:\n",
    "            comb_targets= torch.cat((targets,targets_attack)).view([-1,1]).type(torch.cuda.FloatTensor)\n",
    "        else:\n",
    "            comb_targets= torch.cat((targets,targets_attack)).view([-1,1]).type(torch.FloatTensor)\n",
    "            \n",
    "        #print (comb_inputs.size(),comb_targets.size())\n",
    "        sort_inputs, indices= torch.sort(comb_inputs)\n",
    "        \n",
    "        attack_input = softmax(sort_inputs) #torch.cat((comb_inputs,comb_targets),1)\n",
    "        \n",
    "        \n",
    "        one_hot_tr = torch.from_numpy((np.zeros((attack_input.size()[0],outputs.size(1))))).cuda().type(torch.cuda.FloatTensor)\n",
    "        target_one_hot_tr = one_hot_tr.scatter_(1, torch.cat((targets,targets_attack)).type(torch.cuda.LongTensor).view([-1,1]).data,1)\n",
    "        \n",
    "        for i in range(len(indices)):\n",
    "            target_one_hot_tr[i] = target_one_hot_tr[i][indices[i]]\n",
    "        \n",
    "        infer_input_one_hot = torch.autograd.Variable(target_one_hot_tr)\n",
    "        \n",
    "        \n",
    "        #attack_output = attack_model(att_inp).view([-1])\n",
    "        attack_output, _ = attack_model(attack_input,comb_inputs_h,infer_input_one_hot)\n",
    "        attack_output = attack_output.view([-1])\n",
    "        #attack_output = attack_model(attack_input).view([-1])\n",
    "        att_labels = np.zeros((inputs.size()[0]+inputs_attack.size()[0]))\n",
    "        att_labels [:inputs.size()[0]] =1.0\n",
    "        att_labels [inputs.size()[0]:] =0.0\n",
    "        is_member_labels = torch.from_numpy(att_labels).type(torch.FloatTensor)\n",
    "        if use_cuda:\n",
    "            is_member_labels = is_member_labels.cuda()\n",
    "        \n",
    "        v_is_member_labels = torch.autograd.Variable(is_member_labels)\n",
    "        \n",
    "        \n",
    "        \n",
    "        loss = attack_criterion(attack_output, v_is_member_labels)\n",
    "        \n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        #prec1,p5 = accuracy(attack_output.data, v_is_member_labels.data, topk=(1,2))\n",
    "        \n",
    "        prec1=np.mean(np.equal((attack_output.data.cpu().numpy() >0.5),(v_is_member_labels.data.cpu().numpy()> 0.5)))\n",
    "        losses.update(loss.data, attack_input.size()[0])\n",
    "        top1.update(prec1, attack_input.size()[0])\n",
    "        \n",
    "        correct = np.sum(np.equal((attack_output.data.cpu().numpy() >0.5),(v_is_member_labels.data.cpu().numpy()> 0.5)))\n",
    "        sum_correct += correct\n",
    "        #raise\n",
    "        \n",
    "        # compute gradient and do SGD step\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        # plot progress\n",
    "        if ind%100==0:\n",
    "            print  ('({batch}/{size}) Data: {data:.3f}s | Batch: {bt:.3f}s | | Loss: {loss:.4f} | top1: {top1: .4f} '.format(\n",
    "                    batch=ind + 1,\n",
    "                    size=len_t,\n",
    "                    data=data_time.avg,\n",
    "                    bt=batch_time.avg,\n",
    "                    loss=losses.avg,\n",
    "                    top1=top1.avg,\n",
    "                    ))\n",
    "            \n",
    "#         break\n",
    "#     return (losses.avg, top1.avg)  #,prec1,attack_output,  v_is_member_labels)\n",
    "        \n",
    "    return (losses.avg, top1.avg, sum_correct)\n",
    "\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def train_max_var(train_data,labels, model, criterion, optimizer, class_count, class_index, epoch, use_cuda,num_batchs=999999, alpha = 1.0):\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "    softmax = nn.Softmax()\n",
    "\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    losses_var = AverageMeter()\n",
    "    max_train_outputs = AverageMeter()\n",
    "    min_train_outputs = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    top5 = AverageMeter()\n",
    "    \n",
    "    print('alpha: ', alpha)\n",
    "    end = time.time()\n",
    "    # len_t =  (len(train_classifier_label_tensor)//batch_size)-1\n",
    "    len_t = np.max(class_count)/10\n",
    "    batch_index = np.copy(class_index)\n",
    "    batch_data = torch.Tensor()\n",
    "    batch_label = torch.LongTensor()\n",
    "    for ind in range(len_t):\n",
    "        if ind > num_batchs:\n",
    "            break\n",
    "    #     # measure data loading time\n",
    "    #     inputs = train_classifier_data_tensor[ind*batch_size:(ind+1)*batch_size]\n",
    "    #     targets = train_classifier_label_tensor[ind*batch_size:(ind+1)*batch_size]\n",
    "        inputs = torch.Tensor()\n",
    "        targets = torch.LongTensor()\n",
    "        for i in range(class_num):\n",
    "            if batch_index[i] + 10 > class_index[i+1]:\n",
    "            #             batch_data = sort_train_classifier_data[batch_index[i]: class_index[i+1]]\n",
    "                batch_index[i] = class_index[i]\n",
    "                inputs = torch.cat((inputs, train_classifier_data_tensor[batch_index[i]: batch_index[i] + 10]), 0)\n",
    "                targets = torch.cat((targets, train_classifier_label_tensor[batch_index[i]: batch_index[i] + 10]),0)\n",
    "                batch_index[i] = batch_index[i] + 10\n",
    "\n",
    "            else:\n",
    "                inputs = torch.cat((inputs, train_classifier_data_tensor[batch_index[i]: batch_index[i] + 10]), 0)\n",
    "                targets= torch.cat((targets, train_classifier_label_tensor[batch_index[i]: batch_index[i] + 10]),0)\n",
    "                batch_index[i] = batch_index[i] + 10\n",
    "\n",
    "        data_time.update(time.time() - end)\n",
    "        if use_cuda:\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "        inputs, targets = torch.autograd.Variable(inputs), torch.autograd.Variable(targets)\n",
    "\n",
    "        # compute output\n",
    "        outputs,_ = model(inputs)\n",
    "\n",
    "        soft_outputs = softmax(outputs)\n",
    "        max_outputs = torch.max(soft_outputs,1).values\n",
    "        min_outputs = torch.min(max_outputs)\n",
    "        \n",
    "        var = []\n",
    "        for i in range(class_num):\n",
    "            mean_outputs = torch.mean(soft_outputs[i*10:(i+1)*10],0)\n",
    "            var.append(torch.mean(torch.sum((soft_outputs[i*10:(i+1)*10] - mean_outputs).pow(2),1)))\n",
    "        batch_var = torch.stack(var,0)\n",
    "        loss_var = alpha*(-torch.mean(batch_var))\n",
    "        loss = criterion(outputs, targets) + loss_var\n",
    "        \n",
    "#         loss = criterion(outputs, targets)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        prec1, prec5 = accuracy(outputs.data, targets.data, topk=(1, 5))\n",
    "        losses.update(loss.data, inputs.size()[0])\n",
    "        losses_var.update(loss_var.data, inputs.size()[0])\n",
    "        top1.update(prec1, inputs.size()[0])\n",
    "        top5.update(prec5, inputs.size()[0])\n",
    "        max_train_outputs.update(torch.mean(max_outputs), inputs.size()[0])\n",
    "        min_train_outputs.update(min_outputs, inputs.size()[0])\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        # plot progress\n",
    "        if ind%20==0:\n",
    "            print  ('({batch}/{size}) Data: {data:.3f}s | Batch: {bt:.3f}s| Loss: {loss:.4f} | Var: {loss_var:.4f} | Max: {tmax:.4f} | Min: {tmin:.4f}| top1: {top1: .4f} | top5: {top5: .4f}'.format(\n",
    "                    batch=ind + 1,\n",
    "                    size=len_t,\n",
    "                    data=data_time.avg,\n",
    "                    bt=batch_time.avg,\n",
    "                    loss=losses.avg,\n",
    "                    loss_var=losses_var.avg,\n",
    "                    tmax = max_train_outputs.avg,\n",
    "                    tmin = min_train_outputs.avg,\n",
    "                    top1=top1.avg,\n",
    "                    top5=top5.avg,\n",
    "                    ))\n",
    "    return (losses.avg,losses_var.avg, top1.avg)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def train_max_var_min_a(train_data,labels, model, criterion, optimizer, class_count, class_index, epoch, use_cuda,num_batchs=999999, alpha = 1.0, beta = 1.0):\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "    softmax = nn.Softmax()\n",
    "\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    losses_var = AverageMeter()\n",
    "    losses_a = AverageMeter()\n",
    "    max_train_outputs = AverageMeter()\n",
    "    min_train_outputs = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    top5 = AverageMeter()\n",
    "    \n",
    "    print('alpha: ', alpha,' beta: ', beta)\n",
    "    end = time.time()\n",
    "    # len_t =  (len(train_classifier_label_tensor)//batch_size)-1\n",
    "    len_t = np.max(class_count)/10\n",
    "    batch_index = np.copy(class_index)\n",
    "    batch_data = torch.Tensor()\n",
    "    batch_label = torch.LongTensor()\n",
    "    for ind in range(len_t):\n",
    "        if ind > num_batchs:\n",
    "            break\n",
    "    #     # measure data loading time\n",
    "    #     inputs = train_classifier_data_tensor[ind*batch_size:(ind+1)*batch_size]\n",
    "    #     targets = train_classifier_label_tensor[ind*batch_size:(ind+1)*batch_size]\n",
    "        inputs = torch.Tensor()\n",
    "        targets = torch.LongTensor()\n",
    "        for i in range(class_num):\n",
    "            if batch_index[i] + 10 > class_index[i+1]:\n",
    "            #             batch_data = sort_train_classifier_data[batch_index[i]: class_index[i+1]]\n",
    "                batch_index[i] = class_index[i]\n",
    "                inputs = torch.cat((inputs, train_classifier_data_tensor[batch_index[i]: batch_index[i] + 10]), 0)\n",
    "                targets = torch.cat((targets, train_classifier_label_tensor[batch_index[i]: batch_index[i] + 10]),0)\n",
    "                batch_index[i] = batch_index[i] + 10\n",
    "\n",
    "            else:\n",
    "                inputs = torch.cat((inputs, train_classifier_data_tensor[batch_index[i]: batch_index[i] + 10]), 0)\n",
    "                targets= torch.cat((targets, train_classifier_label_tensor[batch_index[i]: batch_index[i] + 10]),0)\n",
    "                batch_index[i] = batch_index[i] + 10\n",
    "\n",
    "        data_time.update(time.time() - end)\n",
    "        if use_cuda:\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "        inputs, targets = torch.autograd.Variable(inputs), torch.autograd.Variable(targets)\n",
    "\n",
    "        # compute output\n",
    "        outputs,_ = model(inputs)\n",
    "\n",
    "        soft_outputs = softmax(outputs)\n",
    "        max_outputs = torch.max(soft_outputs,1).values\n",
    "        min_outputs = torch.min(max_outputs)\n",
    "        \n",
    "#         max_soft_outputs = torch.max(soft_outputs,1).values\n",
    "#         max_soft_untrain_outputs = torch.mean(torch.max(sort_soft_untrain_outputs,1).values)\n",
    "#         min_soft_untrain_outputs = torch.min(torch.max(sort_soft_untrain_outputs,1).values)\n",
    "#         print('max_soft_outputs: ', max_soft_outputs)\n",
    "#         print('max_soft_untrain_outputs: ', max_soft_untrain_outputs)\n",
    "#         print('min_soft_untrain_outputs: ', min_soft_untrain_outputs)\n",
    "#         max_untrain_outputs = max_untrain_outputs + max_soft_untrain_outputs\n",
    "        loss_a = beta*torch.mean(torch.abs(max_outputs - min_outputs))\n",
    "    \n",
    "        var = []\n",
    "        for i in range(class_num):\n",
    "            mean_outputs = torch.mean(soft_outputs[i*10:(i+1)*10],0)\n",
    "            var.append(torch.mean(torch.sum((soft_outputs[i*10:(i+1)*10] - mean_outputs).pow(2),1)))\n",
    "        batch_var = torch.stack(var,0)\n",
    "        loss_var = alpha*(-torch.mean(batch_var))\n",
    "#         print(\"batch_var: \", batch_var)\n",
    "#         loss_var = alpha*(-torch.sum(batch_var))\n",
    "        loss = criterion(outputs, targets) + loss_var + loss_a\n",
    "        \n",
    "#         loss = criterion(outputs, targets)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        prec1, prec5 = accuracy(outputs.data, targets.data, topk=(1, 5))\n",
    "        losses.update(loss.data, inputs.size()[0])\n",
    "        losses_var.update(loss_var.data, inputs.size()[0])\n",
    "        losses_a.update(loss_a.data, inputs.size()[0])\n",
    "\n",
    "        top1.update(prec1, inputs.size()[0])\n",
    "        top5.update(prec5, inputs.size()[0])\n",
    "        max_train_outputs.update(torch.mean(max_outputs), inputs.size()[0])\n",
    "        min_train_outputs.update(min_outputs, inputs.size()[0])\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        # plot progress\n",
    "        if ind%20==0:\n",
    "            print  ('({batch}/{size}) Data:{data:.3f}s | Batch:{bt:.3f}s| Loss: {loss:.4f} | Var: {loss_var:.4f}|loss_a: {loss_a:.4f}| Max: {tmax:.4f} | Min: {tmin:.4f}| top1: {top1: .4f} | top5: {top5: .4f}'.format(\n",
    "                    batch=ind + 1,\n",
    "                    size=len_t,\n",
    "                    data=data_time.avg,\n",
    "                    bt=batch_time.avg,\n",
    "                    loss=losses.avg,\n",
    "                    loss_var=losses_var.avg,\n",
    "                    loss_a = losses_a.avg,\n",
    "                    tmax = max_train_outputs.avg,\n",
    "                    tmin = min_train_outputs.avg,\n",
    "                    top1=top1.avg,\n",
    "                    top5=top5.avg,\n",
    "                    ))\n",
    "    return (losses.avg,losses_var.avg,losses_a.avg, top1.avg)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def train_max_var_mod2(train_data,labels, model, criterion, optimizer, epoch, use_cuda,num_batchs=999999,num_class=100, alpha = 1.0):\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "    softmax = nn.Softmax()\n",
    "\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    losses_var = AverageMeter()\n",
    "    max_train_outputs = AverageMeter()\n",
    "    min_train_outputs = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    top5 = AverageMeter()\n",
    "    \n",
    "    print('alpha: ', alpha)\n",
    "    end = time.time()\n",
    "    len_t =  (len(train_data)//batch_size)\n",
    "    \n",
    "#     mean_class = torch.from_numpy(np.zeros((num_class,num_class))).cuda().type(torch.cuda.FloatTensor)\n",
    "    mean_class = np.zeros((num_class,num_class))\n",
    "    var_n = np.zeros(num_class)\n",
    "#     mean_var = torch.from_numpy(np.zeros((num_class))).cuda().type(torch.cuda.FloatTensor)\n",
    "    mean_var = np.zeros((num_class))\n",
    " \n",
    "    \n",
    "    for ind in range(len_t):\n",
    "        if ind > num_batchs:\n",
    "            break\n",
    "        # measure data loading time\n",
    "        inputs = train_data[ind*batch_size:(ind+1)*batch_size]\n",
    "        targets = labels[ind*batch_size:(ind+1)*batch_size]\n",
    "        data_time.update(time.time() - end)\n",
    "        if use_cuda:\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "        inputs, targets = torch.autograd.Variable(inputs), torch.autograd.Variable(targets)\n",
    "\n",
    "        # compute output\n",
    "        outputs,_ = model(inputs)\n",
    "        \n",
    "        soft_outputs = softmax(outputs)\n",
    "        max_outputs = torch.max(soft_outputs,1).values\n",
    "        min_outputs = torch.min(max_outputs)\n",
    "        \n",
    "#         mean_outputs = torch.mean(soft_outputs,0)\n",
    "#         var = -torch.mean(torch.sum((soft_outputs - mean_outputs).pow(2),1))\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            var_n[targets[i]] += 1\n",
    "#             mean_class[targets[i]] = mean_class[targets[i]]*(var_n[targets[i]]-1)/var_n[targets[i]] + soft_outputs[i]/var_n[targets[i]]\n",
    "            mean_class[targets[i]] = mean_class[targets[i]]*(var_n[targets[i]]-1)/var_n[targets[i]] + soft_outputs[i].data.cpu().numpy()/var_n[targets[i]]\n",
    "#             mean_var[targets[i]] = mean_var[targets[i]]*(var_n[targets[i]]-1)/var_n[targets[i]] + torch.sum((soft_outputs[i] - mean_class[targets[i]]).pow(2))/var_n[targets[i]]\n",
    "            mean_var[targets[i]] = mean_var[targets[i]]*(var_n[targets[i]]-1)/var_n[targets[i]] + np.sum((soft_outputs[i].data.cpu().numpy() - mean_class[targets[i]])**2)/var_n[targets[i]]\n",
    "\n",
    "            \n",
    "        var = -torch.mean(torch.from_numpy(mean_var)).cuda()*alpha\n",
    "        var = torch.autograd.Variable(var)\n",
    "        loss = criterion(outputs, targets) + var \n",
    "        \n",
    "#         loss = criterion(outputs, targets)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        prec1, prec5 = accuracy(outputs.data, targets.data, topk=(1, 5))\n",
    "        losses.update(loss.data, inputs.size()[0])\n",
    "        losses_var.update(var.data, inputs.size()[0])\n",
    "        top1.update(prec1, inputs.size()[0])\n",
    "        top5.update(prec5, inputs.size()[0])\n",
    "        max_train_outputs.update(torch.mean(max_outputs), inputs.size()[0])\n",
    "        min_train_outputs.update(min_outputs, inputs.size()[0])\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()#retain_graph=True)\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        # plot progress\n",
    "        if ind%20==0:\n",
    "            print  ('({batch}/{size}) Data: {data:.3f}s |Batch: {bt:.3f}s| Loss: {loss:.4f} |Var: {loss_var:.4f} | Max: {tmax:.4f} | Min: {tmin:.4f}| top1: {top1: .4f} | top5: {top5: .4f}'.format(\n",
    "                    batch=ind + 1,\n",
    "                    size=len_t,\n",
    "                    data=data_time.avg,\n",
    "                    bt=batch_time.avg,\n",
    "                    loss=losses.avg,\n",
    "                    loss_var=losses_var.avg,\n",
    "                    tmax = max_train_outputs.avg,\n",
    "                    tmin = min_train_outputs.avg,\n",
    "                    top1=top1.avg,\n",
    "                    top5=top5.avg,\n",
    "                    ))\n",
    "    return (losses.avg,losses_var.avg, top1.avg)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def train_max_var_mod3(train_data,labels, model, criterion, optimizer, mean_class,var_n,mean_var, epoch, use_cuda,num_batchs=999999,num_class=100, alpha = 1.0):\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "    softmax = nn.Softmax()\n",
    "\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    losses_var = AverageMeter()\n",
    "    max_train_outputs = AverageMeter()\n",
    "    min_train_outputs = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    top5 = AverageMeter()\n",
    "    \n",
    "    print('alpha: ', alpha)\n",
    "    end = time.time()\n",
    "    len_t =  (len(train_data)//batch_size)\n",
    "    \n",
    "#     mean_class = torch.from_numpy(np.zeros((num_class,num_class))).cuda().type(torch.cuda.FloatTensor)\n",
    "#     mean_class = np.zeros((num_class,num_class))\n",
    "#     var_n = np.zeros(num_class)\n",
    "# #     mean_var = torch.from_numpy(np.zeros((num_class))).cuda().type(torch.cuda.FloatTensor)\n",
    "#     mean_var = np.zeros((num_class))\n",
    " \n",
    "    \n",
    "    for ind in range(len_t):\n",
    "        if ind > num_batchs:\n",
    "            break\n",
    "        # measure data loading time\n",
    "        inputs = train_data[ind*batch_size:(ind+1)*batch_size]\n",
    "        targets = labels[ind*batch_size:(ind+1)*batch_size]\n",
    "        data_time.update(time.time() - end)\n",
    "        if use_cuda:\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "        inputs, targets = torch.autograd.Variable(inputs), torch.autograd.Variable(targets)\n",
    "\n",
    "        # compute output\n",
    "        outputs,_ = model(inputs)\n",
    "        \n",
    "        soft_outputs = softmax(outputs)\n",
    "        max_outputs = torch.max(soft_outputs,1).values\n",
    "        min_outputs = torch.min(max_outputs)\n",
    "        \n",
    "#         mean_outputs = torch.mean(soft_outputs,0)\n",
    "#         var = -torch.mean(torch.sum((soft_outputs - mean_outputs).pow(2),1))\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            var_n[targets[i]] += 1\n",
    "#             mean_class[targets[i]] = mean_class[targets[i]]*(var_n[targets[i]]-1)/var_n[targets[i]] + soft_outputs[i]/var_n[targets[i]]\n",
    "            mean_class[targets[i]] = mean_class[targets[i]]*(var_n[targets[i]]-1)/var_n[targets[i]] + soft_outputs[i].data.cpu().numpy()/var_n[targets[i]]\n",
    "#             mean_var[targets[i]] = mean_var[targets[i]]*(var_n[targets[i]]-1)/var_n[targets[i]] + torch.sum((soft_outputs[i] - mean_class[targets[i]]).pow(2))/var_n[targets[i]]\n",
    "            mean_var[targets[i]] = mean_var[targets[i]]*(var_n[targets[i]]-1)/var_n[targets[i]] + np.sum((soft_outputs[i].data.cpu().numpy() - mean_class[targets[i]])**2)/var_n[targets[i]]\n",
    "\n",
    "            \n",
    "        var = -torch.mean(torch.from_numpy(mean_var)).cuda()*alpha\n",
    "        var = torch.autograd.Variable(var)\n",
    "        loss = criterion(outputs, targets) + var \n",
    "        \n",
    "#         loss = criterion(outputs, targets)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        prec1, prec5 = accuracy(outputs.data, targets.data, topk=(1, 5))\n",
    "        losses.update(loss.data, inputs.size()[0])\n",
    "        losses_var.update(var.data, inputs.size()[0])\n",
    "        top1.update(prec1, inputs.size()[0])\n",
    "        top5.update(prec5, inputs.size()[0])\n",
    "        max_train_outputs.update(torch.mean(max_outputs), inputs.size()[0])\n",
    "        min_train_outputs.update(min_outputs, inputs.size()[0])\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()#retain_graph=True)\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        # plot progress\n",
    "        if ind%20==0:\n",
    "            print  ('({batch}/{size}) Data: {data:.3f}s |Batch: {bt:.3f}s| Loss: {loss:.4f} |Var: {loss_var:.4f} | Max: {tmax:.4f} | Min: {tmin:.4f}| top1: {top1: .4f} | top5: {top5: .4f}'.format(\n",
    "                    batch=ind + 1,\n",
    "                    size=len_t,\n",
    "                    data=data_time.avg,\n",
    "                    bt=batch_time.avg,\n",
    "                    loss=losses.avg,\n",
    "                    loss_var=losses_var.avg,\n",
    "                    tmax = max_train_outputs.avg,\n",
    "                    tmin = min_train_outputs.avg,\n",
    "                    top1=top1.avg,\n",
    "                    top5=top5.avg,\n",
    "                    ))\n",
    "    return (losses.avg,losses_var.avg, top1.avg)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def train_max_var_mod4(train_data,labels, model, criterion, optimizer, mean_class,var_n, epoch, use_cuda,num_batchs=999999,num_class=100, alpha = 1.0):\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "    softmax = nn.Softmax()\n",
    "\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    losses_var = AverageMeter()\n",
    "    max_train_outputs = AverageMeter()\n",
    "    min_train_outputs = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    top5 = AverageMeter()\n",
    "    \n",
    "    print('alpha: ', alpha)\n",
    "    end = time.time()\n",
    "    len_t =  (len(train_data)//batch_size)\n",
    "    \n",
    "#     mean_class = torch.from_numpy(np.zeros((num_class,num_class))).cuda().type(torch.cuda.FloatTensor)\n",
    "#     mean_class = np.zeros((num_class,num_class))\n",
    "#     var_n = np.zeros(num_class)\n",
    "# #     mean_var = torch.from_numpy(np.zeros((num_class))).cuda().type(torch.cuda.FloatTensor)\n",
    "#     mean_var = np.zeros((num_class))\n",
    "    mean_var = torch.from_numpy(np.zeros((num_class))).cuda().type(torch.cuda.FloatTensor)\n",
    "    \n",
    "    for ind in range(len_t):\n",
    "        if ind > num_batchs:\n",
    "            break\n",
    "        # measure data loading time\n",
    "        inputs = train_data[ind*batch_size:(ind+1)*batch_size]\n",
    "        targets = labels[ind*batch_size:(ind+1)*batch_size]\n",
    "        data_time.update(time.time() - end)\n",
    "        if use_cuda:\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "        inputs, targets = torch.autograd.Variable(inputs), torch.autograd.Variable(targets)\n",
    "\n",
    "        # compute output\n",
    "        outputs,_ = model(inputs)\n",
    "        \n",
    "        soft_outputs = softmax(outputs)\n",
    "        max_outputs = torch.max(soft_outputs,1).values\n",
    "        min_outputs = torch.min(max_outputs)\n",
    "        \n",
    "#         mean_outputs = torch.mean(soft_outputs,0)\n",
    "#         var = -torch.mean(torch.sum((soft_outputs - mean_outputs).pow(2),1))\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            var_n[targets[i]] += 1\n",
    "#             mean_class[targets[i]] = mean_class[targets[i]]*(var_n[targets[i]]-1)/var_n[targets[i]] + soft_outputs[i]/var_n[targets[i]]\n",
    "            mean_class[targets[i]] = mean_class[targets[i]]*(var_n[targets[i]]-1)/var_n[targets[i]] + soft_outputs[i].data.cpu().numpy()/var_n[targets[i]]\n",
    "            mean_var[targets[i]] = mean_var[targets[i]]*(var_n[targets[i]]-1)/var_n[targets[i]] + torch.sum((soft_outputs[i] - torch.from_numpy(mean_class[targets[i]]).cuda()).pow(2))/var_n[targets[i]]\n",
    "#             mean_var[targets[i]] = mean_var[targets[i]]*(var_n[targets[i]]-1)/var_n[targets[i]] + np.sum((soft_outputs[i].data.cpu().numpy() - mean_class[targets[i]])**2)/var_n[targets[i]]\n",
    "\n",
    "        var = torch.mean(mean_var)*alpha\n",
    "#         var = -torch.mean(torch.from_numpy(mean_var)).cuda()*alpha\n",
    "#         var = torch.autograd.Variable(var)\n",
    "        loss = criterion(outputs, targets) + var \n",
    "        \n",
    "#         loss = criterion(outputs, targets)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        prec1, prec5 = accuracy(outputs.data, targets.data, topk=(1, 5))\n",
    "        losses.update(loss.data, inputs.size()[0])\n",
    "        losses_var.update(var.data, inputs.size()[0])\n",
    "        top1.update(prec1, inputs.size()[0])\n",
    "        top5.update(prec5, inputs.size()[0])\n",
    "        max_train_outputs.update(torch.mean(max_outputs), inputs.size()[0])\n",
    "        min_train_outputs.update(min_outputs, inputs.size()[0])\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        # plot progress\n",
    "        if ind%10==0:\n",
    "            print  ('({batch}/{size}) Data: {data:.3f}s |Batch: {bt:.3f}s| Loss: {loss:.4f} |Var: {loss_var:.4f} | Max: {tmax:.4f} | Min: {tmin:.4f}| top1: {top1: .4f} | top5: {top5: .4f}'.format(\n",
    "                    batch=ind + 1,\n",
    "                    size=len_t,\n",
    "                    data=data_time.avg,\n",
    "                    bt=batch_time.avg,\n",
    "                    loss=losses.avg,\n",
    "                    loss_var=losses_var.avg,\n",
    "                    tmax = max_train_outputs.avg,\n",
    "                    tmin = min_train_outputs.avg,\n",
    "                    top1=top1.avg,\n",
    "                    top5=top5.avg,\n",
    "                    ))\n",
    "    return (losses.avg,losses_var.avg, top1.avg)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def train_max_var_mod7(train_data,labels, model, criterion, optimizer, epoch, use_cuda,num_batchs=999999, alpha = 1.0):\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "    softmax = nn.Softmax()\n",
    "\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    losses_var = AverageMeter()\n",
    "    max_train_outputs = AverageMeter()\n",
    "    min_train_outputs = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    top5 = AverageMeter()\n",
    "    \n",
    "    print('alpha: ', alpha)\n",
    "    end = time.time()\n",
    "    len_t =  (len(train_data)//batch_size)-1\n",
    "    \n",
    "    for ind in range(len_t):\n",
    "        if ind > num_batchs:\n",
    "            break\n",
    "        # measure data loading time\n",
    "        inputs = train_data[ind*batch_size:(ind+1)*batch_size]\n",
    "        targets = labels[ind*batch_size:(ind+1)*batch_size]\n",
    "        data_time.update(time.time() - end)\n",
    "        if use_cuda:\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "        inputs, targets = torch.autograd.Variable(inputs), torch.autograd.Variable(targets)\n",
    "\n",
    "        # compute output\n",
    "        outputs,_ = model(inputs)\n",
    "        \n",
    "        soft_outputs = softmax(outputs)\n",
    "        max_outputs = torch.max(soft_outputs,1).values # max for each data\n",
    "        min_outputs = torch.min(max_outputs)\n",
    "        \n",
    "        mean_outputs = torch.mean(soft_outputs,0)\n",
    "        var = torch.mean(torch.sum((soft_outputs - mean_outputs).pow(2),1))*alpha\n",
    "        \n",
    "        loss = criterion(outputs, targets) + var \n",
    "        \n",
    "#         loss = criterion(outputs, targets)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        prec1, prec5 = accuracy(outputs.data, targets.data, topk=(1, 5))\n",
    "        losses.update(loss.data, inputs.size()[0])\n",
    "        losses_var.update(var.data, inputs.size()[0])\n",
    "        top1.update(prec1, inputs.size()[0])\n",
    "        top5.update(prec5, inputs.size()[0])\n",
    "        max_train_outputs.update(torch.mean(max_outputs), inputs.size()[0])\n",
    "        min_train_outputs.update(min_outputs, inputs.size()[0])\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        # plot progress\n",
    "        if ind%10==0:\n",
    "            print  ('({batch}/{size}) Data: {data:.3f}s | Batch: {bt:.3f}s| Loss: {loss:.4f} | Var: {loss_var:.4f} | Max: {tmax:.4f} | Min: {tmin:.4f}| top1: {top1: .4f} | top5: {top5: .4f}'.format(\n",
    "                    batch=ind + 1,\n",
    "                    size=len_t,\n",
    "                    data=data_time.avg,\n",
    "                    bt=batch_time.avg,\n",
    "                    loss=losses.avg,\n",
    "                    loss_var=losses_var.avg,\n",
    "                    tmax = max_train_outputs.avg,\n",
    "                    tmin = min_train_outputs.avg,\n",
    "                    top1=top1.avg,\n",
    "                    top5=top5.avg,\n",
    "                    ))\n",
    "    return (losses.avg,losses_var.avg, top1.avg)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def train_max_var_mod5(train_data,labels, model, criterion, optimizer, mean_class,var_n, epoch, use_cuda,num_batchs=999999,num_class=100, alpha = 1.0):\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "    softmax = nn.Softmax()\n",
    "\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    losses_var = AverageMeter()\n",
    "    max_train_outputs = AverageMeter()\n",
    "    min_train_outputs = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    top5 = AverageMeter()\n",
    "    \n",
    "    print('alpha: ', alpha)\n",
    "    end = time.time()\n",
    "    len_t =  (len(train_data)//batch_size)\n",
    "    \n",
    "#     mean_class = torch.from_numpy(np.zeros((num_class,num_class))).cuda().type(torch.cuda.FloatTensor)\n",
    "#     mean_class = np.zeros((num_class,num_class))\n",
    "#     var_n = np.zeros(num_class)\n",
    "#     mean_var = torch.from_numpy(np.zeros((num_class))).cuda().type(torch.cuda.FloatTensor)\n",
    "#     mean_var = np.zeros((num_class))\n",
    " \n",
    "    \n",
    "    for ind in range(len_t):\n",
    "        if ind > num_batchs:\n",
    "            break\n",
    "        # measure data loading time\n",
    "        inputs = train_data[ind*batch_size:(ind+1)*batch_size]\n",
    "        targets = labels[ind*batch_size:(ind+1)*batch_size]\n",
    "        data_time.update(time.time() - end)\n",
    "        if use_cuda:\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "        inputs, targets = torch.autograd.Variable(inputs), torch.autograd.Variable(targets)\n",
    "\n",
    "        # compute output\n",
    "        outputs,_ = model(inputs)\n",
    "        \n",
    "        soft_outputs = softmax(outputs)\n",
    "        max_outputs = torch.max(soft_outputs,1).values\n",
    "        min_outputs = torch.min(max_outputs)\n",
    "        \n",
    "#         mean_outputs = torch.mean(soft_outputs,0)\n",
    "#         var = -torch.mean(torch.sum((soft_outputs - mean_outputs).pow(2),1))\n",
    "\n",
    "        for i in range(batch_size):\n",
    "#         var_n[targets[i]] = var_n[targets[i]] + 1\n",
    "            var_n[targets[i]] += 1\n",
    "    #         mean_class[targets[i]] = mean_class[targets[i]]*(var_n[targets[i]]-1)/var_n[targets[i]] + soft_outputs[i]/var_n[targets[i]]\n",
    "            mean_class[targets[i]] = mean_class[targets[i]]*(var_n[targets[i]]-1)/var_n[targets[i]] + soft_outputs[i].data.cpu().numpy()/var_n[targets[i]]\n",
    "    #         mean_var[targets[i]] = mean_var[targets[i]]*(var_n[targets[i]]-1)/var_n[targets[i]] + torch.sum((soft_outputs[i] - mean_class[targets[i]]).pow(2))/var_n[targets[i]]\n",
    "    #         mean_var[targets[i]] = mean_var[targets[i]]*(var_n[targets[i]]-1)/var_n[targets[i]] + torch.sum((soft_outputs[i] - torch.from_numpy(mean_class[targets[i]]).cuda()).pow(2))/var_n[targets[i]]\n",
    "\n",
    "        temp_mean = torch.from_numpy(mean_class).cuda()\n",
    "        mean_var = torch.sum((soft_outputs - temp_mean[targets]).pow(2),1)\n",
    "    \n",
    "        var = torch.mean(mean_var)*alpha\n",
    "#         var = -torch.mean(torch.from_numpy(mean_var)).cuda()*alpha\n",
    "#         var = torch.autograd.Variable(var)\n",
    "        loss = criterion(outputs, targets) + var \n",
    "        \n",
    "#         loss = criterion(outputs, targets)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        prec1, prec5 = accuracy(outputs.data, targets.data, topk=(1, 5))\n",
    "        losses.update(loss.data, inputs.size()[0])\n",
    "        losses_var.update(var.data, inputs.size()[0])\n",
    "        top1.update(prec1, inputs.size()[0])\n",
    "        top5.update(prec5, inputs.size()[0])\n",
    "        max_train_outputs.update(torch.mean(max_outputs), inputs.size()[0])\n",
    "        min_train_outputs.update(min_outputs, inputs.size()[0])\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward() #retain_graph=True)\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        # plot progress\n",
    "        if ind%20==0:\n",
    "            print  ('({batch}/{size}) Data: {data:.3f}s |Batch: {bt:.3f}s| Loss: {loss:.4f} |Var: {loss_var:.4f} | Max: {tmax:.4f} | Min: {tmin:.4f}| top1: {top1: .4f} | top5: {top5: .4f}'.format(\n",
    "                    batch=ind + 1,\n",
    "                    size=len_t,\n",
    "                    data=data_time.avg,\n",
    "                    bt=batch_time.avg,\n",
    "                    loss=losses.avg,\n",
    "                    loss_var=losses_var.avg,\n",
    "                    tmax = max_train_outputs.avg,\n",
    "                    tmin = min_train_outputs.avg,\n",
    "                    top1=top1.avg,\n",
    "                    top5=top5.avg,\n",
    "                    ))\n",
    "    return (losses.avg,losses_var.avg, top1.avg)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def train_half_diff(train_data,labels, model, criterion, optimizer,alpha, epoch, use_cuda,num_batchs=999999):\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "    print('alpha = ', alpha)\n",
    "    \n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    top5 = AverageMeter()\n",
    "    diffes = AverageMeter()\n",
    "    \n",
    "    end = time.time()\n",
    "    len_t =  (len(train_data)//batch_size)-1\n",
    "    \n",
    "    for ind in range(len_t):\n",
    "        if ind > num_batchs:\n",
    "            break\n",
    "        # measure data loading time\n",
    "        inputs = train_data[ind*batch_size:(ind+1)*batch_size]\n",
    "        targets = labels[ind*batch_size:(ind+1)*batch_size]\n",
    "        data_time.update(time.time() - end)\n",
    "        if use_cuda:\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "        inputs, targets = torch.autograd.Variable(inputs), torch.autograd.Variable(targets)\n",
    "\n",
    "        # compute output\n",
    "        outputs, y1,y2,y3,y4,y5 = model(inputs)\n",
    "        \n",
    "        out_list = [y1,y2,y3,y4,y5, outputs]\n",
    "#         out_list[0].shape\n",
    "        sum_diff = torch.zeros(out_list[0].shape[0]).cuda()\n",
    "        for out_layer in out_list:\n",
    "\n",
    "            # hidden_outputs.shape\n",
    "            hidden_map = torch.ones(out_layer.shape[1]).cuda()\n",
    "            hidden_map[out_layer.shape[1]//2:] = -1\n",
    "        #     torch.sum(hidden_map)\n",
    "            hd_diff_map = out_layer * hidden_map\n",
    "            # hd_diff_map.shape\n",
    "            hd_diff = torch.sum(hd_diff_map, 1)\n",
    "            var_hd = hd_diff ** 2 / hd_diff_map.shape[1]\n",
    "            sum_diff += var_hd\n",
    "        \n",
    "        diff_var = sum_diff.mean() * alpha\n",
    "        loss = criterion(outputs, targets) + diff_var\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        prec1, prec5 = accuracy(outputs.data, targets.data, topk=(1, 5))\n",
    "        losses.update(loss.data, inputs.size()[0])\n",
    "        diffes.update(diff_var.data, inputs.size()[0])\n",
    "        top1.update(prec1, inputs.size()[0])\n",
    "        top5.update(prec5, inputs.size()[0])\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        # plot progress\n",
    "        if ind%100==0:\n",
    "            print  ('({batch}/{size}) Data: {data:.3f}s | Batch: {bt:.3f}s | | Loss: {loss:.4f} | | diff: {diff:.4f} | top1: {top1: .4f} | top5: {top5: .4f}'.format(\n",
    "                    batch=ind + 1,\n",
    "                    size=len_t,\n",
    "                    data=data_time.avg,\n",
    "                    bt=batch_time.avg,\n",
    "                    loss=losses.avg,\n",
    "                    diff=diffes.avg,\n",
    "                    top1=top1.avg,\n",
    "                    top5=top5.avg,\n",
    "                    ))\n",
    "    return (losses.avg, top1.avg, diffes.avg)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def train_half_diff_2(train_data,labels, model, criterion, optimizer,alpha, epoch, use_cuda,num_batchs=999999):\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "    \n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    top5 = AverageMeter()\n",
    "    diffes = AverageMeter()\n",
    "    \n",
    "    end = time.time()\n",
    "    len_t =  (len(train_data)//batch_size)-1\n",
    "    \n",
    "    for ind in range(len_t):\n",
    "        if ind > num_batchs:\n",
    "            break\n",
    "        # measure data loading time\n",
    "        inputs = train_data[ind*batch_size:(ind+1)*batch_size]\n",
    "        targets = labels[ind*batch_size:(ind+1)*batch_size]\n",
    "        data_time.update(time.time() - end)\n",
    "        if use_cuda:\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "        inputs, targets = torch.autograd.Variable(inputs), torch.autograd.Variable(targets)\n",
    "\n",
    "        # compute output\n",
    "        outputs, hidden_outputs = model(inputs)\n",
    "        \n",
    "        hidden_map = torch.ones(256).cuda()\n",
    "        hidden_map[128:] = -1\n",
    "        torch.sum(hidden_map)\n",
    "        hd_diff_map = hidden_outputs * hidden_map\n",
    "        # hd_diff_map.shape\n",
    "        hd_diff = torch.mean(torch.sum(hd_diff_map, 1))** 2 / 256\n",
    "\n",
    "        output_map = torch.ones(10).cuda()\n",
    "        output_map[5:] = -1\n",
    "        output_diff_map = outputs * output_map\n",
    "        # hd_diff_map.shape\n",
    "        output_diff = torch.mean(torch.sum(output_diff_map , 1)) ** 2 / 10\n",
    "#         output_diff \n",
    "\n",
    "        diff_var = alpha * (hd_diff + output_diff) \n",
    "        \n",
    "        loss = criterion(outputs, targets) + diff_var\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        prec1, prec5 = accuracy(outputs.data, targets.data, topk=(1, 5))\n",
    "        losses.update(loss.data, inputs.size()[0])\n",
    "        diffes.update(diff_var.data, inputs.size()[0])\n",
    "        top1.update(prec1, inputs.size()[0])\n",
    "        top5.update(prec5, inputs.size()[0])\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        # plot progress\n",
    "        if ind%100==0:\n",
    "            print  ('({batch}/{size}) Data: {data:.3f}s | Batch: {bt:.3f}s | | Loss: {loss:.4f} | | diff: {diff:.4f} | top1: {top1: .4f} | top5: {top5: .4f}'.format(\n",
    "                    batch=ind + 1,\n",
    "                    size=len_t,\n",
    "                    data=data_time.avg,\n",
    "                    bt=batch_time.avg,\n",
    "                    loss=losses.avg,\n",
    "                    diff=diffes.avg,\n",
    "                    top1=top1.avg,\n",
    "                    top5=top5.avg,\n",
    "                    ))\n",
    "    return (losses.avg, top1.avg, diffes.avg)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def train_half_diff_min_var(train_data,labels, model, criterion, optimizer,alpha, epoch, use_cuda, var_n,mean_class,beta):\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "    softmax = nn.Softmax()\n",
    "    \n",
    "    losses_var = AverageMeter()\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    top5 = AverageMeter()\n",
    "    diffes = AverageMeter()\n",
    "    max_train_outputs = AverageMeter()\n",
    "    min_train_outputs = AverageMeter()\n",
    "    \n",
    "    end = time.time()\n",
    "    len_t =  (len(train_data)//batch_size)-1\n",
    "    \n",
    "    for ind in range(len_t):\n",
    "        # measure data loading time\n",
    "        \n",
    "        inputs = train_data[ind*batch_size:(ind+1)*batch_size]\n",
    "        targets = labels[ind*batch_size:(ind+1)*batch_size]\n",
    "        data_time.update(time.time() - end)\n",
    "        if use_cuda:\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "        inputs, targets = torch.autograd.Variable(inputs), torch.autograd.Variable(targets)\n",
    "\n",
    "        # compute output\n",
    "        outputs, y1,y3,y4,y5 = model(inputs)\n",
    "        \n",
    "        out_list = [y1,y3,y4,y5, outputs]\n",
    "#         out_list[0].shape\n",
    "        sum_diff = torch.zeros(out_list[0].shape[0]).cuda()\n",
    "        for out_layer in out_list:\n",
    "\n",
    "            # hidden_outputs.shape\n",
    "            hidden_map = torch.ones(out_layer.shape[1]).cuda()\n",
    "            hidden_map[out_layer.shape[1]//2:] = -1\n",
    "        #     torch.sum(hidden_map)\n",
    "            hd_diff_map = out_layer * hidden_map\n",
    "            # hd_diff_map.shape\n",
    "            hd_diff = torch.sum(hd_diff_map, 1)\n",
    "            var_hd = hd_diff ** 2 / hd_diff_map.shape[1]\n",
    "            sum_diff += var_hd\n",
    "        \n",
    "        diff_var = sum_diff.mean() * alpha\n",
    "        \n",
    "        soft_outputs = softmax(outputs)\n",
    "        max_outputs = torch.max(soft_outputs,1).values\n",
    "        min_outputs = torch.min(max_outputs)\n",
    "        \n",
    "        \n",
    "#         mean_outputs = torch.mean(soft_outputs,0)\n",
    "#         var = -torch.mean(torch.sum((soft_outputs - mean_outputs).pow(2),1))\n",
    "\n",
    "        for i in range(batch_size):\n",
    "#         var_n[targets[i]] = var_n[targets[i]] + 1\n",
    "            var_n[targets[i]] += 1\n",
    "    #         mean_class[targets[i]] = mean_class[targets[i]]*(var_n[targets[i]]-1)/var_n[targets[i]] + soft_outputs[i]/var_n[targets[i]]\n",
    "            mean_class[targets[i]] = mean_class[targets[i]]*(var_n[targets[i]]-1)/var_n[targets[i]] + soft_outputs[i].data.cpu().numpy()/var_n[targets[i]]\n",
    "    #         mean_var[targets[i]] = mean_var[targets[i]]*(var_n[targets[i]]-1)/var_n[targets[i]] + torch.sum((soft_outputs[i] - mean_class[targets[i]]).pow(2))/var_n[targets[i]]\n",
    "    #         mean_var[targets[i]] = mean_var[targets[i]]*(var_n[targets[i]]-1)/var_n[targets[i]] + torch.sum((soft_outputs[i] - torch.from_numpy(mean_class[targets[i]]).cuda()).pow(2))/var_n[targets[i]]\n",
    "\n",
    "        temp_mean = torch.from_numpy(mean_class).cuda()\n",
    "        mean_var = torch.sum((soft_outputs - temp_mean[targets]).pow(2),1)\n",
    "    \n",
    "        var = torch.mean(mean_var)*beta\n",
    "        \n",
    "        loss = criterion(outputs, targets) + diff_var + var\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        prec1, prec5 = accuracy(outputs.data, targets.data, topk=(1, 5))\n",
    "        losses.update(loss.data, inputs.size()[0])\n",
    "        diffes.update(diff_var.data, inputs.size()[0])\n",
    "        top1.update(prec1, inputs.size()[0])\n",
    "        top5.update(prec5, inputs.size()[0])\n",
    "        losses_var.update(var.data, inputs.size()[0])\n",
    "        max_train_outputs.update(torch.mean(max_outputs), inputs.size()[0])\n",
    "        min_train_outputs.update(min_outputs, inputs.size()[0])     \n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        # plot progress\n",
    "        if ind%10==0:\n",
    "            print  ('({batch}/{size}) Data: {data:.3f}s | Batch: {bt:.3f}s | | Loss: {loss:.4f} |var: {loss_var:.4f}| diff: {diff:.4f}|Max: {tmax:.4f} | Min: {tmin:.4f}| top1: {top1: .4f} | top5: {top5: .4f}'.format(\n",
    "                    batch=ind + 1,\n",
    "                    size=len_t,\n",
    "                    data=data_time.avg,\n",
    "                    bt=batch_time.avg,\n",
    "                    loss=losses.avg,\n",
    "                    loss_var=losses_var.avg,\n",
    "                    diff=diffes.avg,\n",
    "                    tmax = max_train_outputs.avg,\n",
    "                    tmin = min_train_outputs.avg,\n",
    "                    top1=top1.avg,\n",
    "                    top5=top5.avg,\n",
    "                    ))\n",
    "    return (losses.avg, top1.avg, diffes.avg, losses_var.avg)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def _log_value(probs, small_value=1e-30):\n",
    "    return -torch.log(torch.max(probs, torch.tensor(small_value).cuda()))\n",
    "\n",
    "def _m_entr_comp(probs, true_labels):\n",
    "    log_probs = _log_value(probs)\n",
    "    reverse_probs = 1-probs\n",
    "    log_reverse_probs = _log_value(reverse_probs)\n",
    "#     modified_probs = np.copy(probs)\n",
    "    modified_probs = probs.detach().clone()\n",
    "    modified_probs[range(true_labels.size(0)), true_labels] = reverse_probs[range(true_labels.size(0)), true_labels]\n",
    "    modified_log_probs = log_reverse_probs.detach().clone()\n",
    "    modified_log_probs[range(true_labels.size(0)), true_labels] = log_probs[range(true_labels.size(0)), true_labels]\n",
    "    return torch.sum(torch.mul(modified_probs, modified_log_probs),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def train_half_diff_min_var_me(train_data,labels, model, criterion, optimizer,alpha, epoch, use_cuda, var_n,mean_class,beta, gamma):\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "    softmax = nn.Softmax()\n",
    "    \n",
    "    losses_var = AverageMeter()\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    top5 = AverageMeter()\n",
    "    diffes = AverageMeter()\n",
    "    max_train_outputs = AverageMeter()\n",
    "    min_train_outputs = AverageMeter()\n",
    "    me_vars = AverageMeter()\n",
    "    end = time.time()\n",
    "    len_t =  (len(train_data)//batch_size)-1\n",
    "    \n",
    "    for ind in range(len_t):\n",
    "        # measure data loading time\n",
    "        inputs = train_data[ind*batch_size:(ind+1)*batch_size]\n",
    "        targets = labels[ind*batch_size:(ind+1)*batch_size]\n",
    "        data_time.update(time.time() - end)\n",
    "        if use_cuda:\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "        inputs, targets = torch.autograd.Variable(inputs), torch.autograd.Variable(targets)\n",
    "\n",
    "        # compute output\n",
    "        outputs, y1,y3,y4,y5 = model(inputs)\n",
    "        \n",
    "        out_list = [y1,y3,y4,y5, outputs]\n",
    "#         out_list[0].shape\n",
    "        sum_diff = torch.zeros(out_list[0].shape[0]).cuda()\n",
    "        for out_layer in out_list:\n",
    "\n",
    "            # hidden_outputs.shape\n",
    "            hidden_map = torch.ones(out_layer.shape[1]).cuda()\n",
    "            hidden_map[out_layer.shape[1]//2:] = -1\n",
    "        #     torch.sum(hidden_map)\n",
    "            hd_diff_map = out_layer * hidden_map\n",
    "            # hd_diff_map.shape\n",
    "            hd_diff = torch.sum(hd_diff_map, 1)\n",
    "            var_hd = hd_diff ** 2 / hd_diff_map.shape[1]\n",
    "            sum_diff += var_hd\n",
    "        \n",
    "        diff_var = sum_diff.mean() * alpha\n",
    "        \n",
    "        soft_outputs = softmax(outputs)\n",
    "        max_outputs = torch.max(soft_outputs,1).values\n",
    "        min_outputs = torch.min(max_outputs)\n",
    "        \n",
    "#         s_tr_m_entr = _m_entr_comp(soft_outputs.data.cpu().numpy(), targets.data.cpu().numpy())\n",
    "        s_tr_m_entr = _m_entr_comp(soft_outputs, targets)\n",
    "        me_var = -torch.var(s_tr_m_entr) * gamma\n",
    "#         me_var = torch.tensor(me_var).cuda()\n",
    "\n",
    "#         mean_outputs = torch.mean(soft_outputs,0)\n",
    "#         var = -torch.mean(torch.sum((soft_outputs - mean_outputs).pow(2),1))\n",
    "\n",
    "        for i in range(batch_size):\n",
    "#         var_n[targets[i]] = var_n[targets[i]] + 1\n",
    "            var_n[targets[i]] += 1\n",
    "    #         mean_class[targets[i]] = mean_class[targets[i]]*(var_n[targets[i]]-1)/var_n[targets[i]] + soft_outputs[i]/var_n[targets[i]]\n",
    "            mean_class[targets[i]] = mean_class[targets[i]]*(var_n[targets[i]]-1)/var_n[targets[i]] + soft_outputs[i].data.cpu().numpy()/var_n[targets[i]]\n",
    "    #         mean_var[targets[i]] = mean_var[targets[i]]*(var_n[targets[i]]-1)/var_n[targets[i]] + torch.sum((soft_outputs[i] - mean_class[targets[i]]).pow(2))/var_n[targets[i]]\n",
    "    #         mean_var[targets[i]] = mean_var[targets[i]]*(var_n[targets[i]]-1)/var_n[targets[i]] + torch.sum((soft_outputs[i] - torch.from_numpy(mean_class[targets[i]]).cuda()).pow(2))/var_n[targets[i]]\n",
    "\n",
    "        temp_mean = torch.from_numpy(mean_class).cuda()\n",
    "        mean_var = torch.sum((soft_outputs - temp_mean[targets]).pow(2),1)\n",
    "    \n",
    "        var = torch.mean(mean_var)*beta\n",
    "        \n",
    "        loss = criterion(outputs, targets) + diff_var + var +  me_var\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        prec1, prec5 = accuracy(outputs.data, targets.data, topk=(1, 5))\n",
    "        losses.update(loss.data, inputs.size()[0])\n",
    "        diffes.update(diff_var.data, inputs.size()[0])\n",
    "        top1.update(prec1, inputs.size()[0])\n",
    "        top5.update(prec5, inputs.size()[0])\n",
    "        losses_var.update(var.data, inputs.size()[0])\n",
    "        me_vars.update(me_var.data, inputs.size()[0])\n",
    "        max_train_outputs.update(torch.mean(max_outputs), inputs.size()[0])\n",
    "        min_train_outputs.update(min_outputs, inputs.size()[0])     \n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        # plot progress\n",
    "        if ind%100==0:\n",
    "            print  ('({batch}/{size}) | Batch: {bt:.3f}s | | Loss: {loss:.4f} |var: {loss_var:.4f}| diff: {diff:.4f}|me_var: {me_vars:.4f}|Max: {tmax:.4f} | Min: {tmin:.4f}| top1: {top1: .4f} | top5: {top5: .4f}'.format(\n",
    "                    batch=ind + 1,\n",
    "                    size=len_t,\n",
    "#                     data=data_time.avg,\n",
    "                    bt=batch_time.avg,\n",
    "                    loss=losses.avg,\n",
    "                    loss_var=losses_var.avg,\n",
    "                    diff=diffes.avg,\n",
    "                    me_vars = me_vars.avg,\n",
    "                    tmax = max_train_outputs.avg,\n",
    "                    tmin = min_train_outputs.avg,\n",
    "                    top1=top1.avg,\n",
    "                    top5=top5.avg,\n",
    "                    ))\n",
    "    return (losses.avg, top1.avg, diffes.avg, losses_var.avg)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print('train_classifier_data: ',len(train_classifier_data))\n",
    "\n",
    "print('train_attack_data: ',len(train_attack_data))\n",
    "\n",
    "print('test_data: ',len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "small_train_classifier_data_length = 10000\n",
    "small_train_classifier_data = X[:small_train_classifier_data_length]\n",
    "small_train_classifier_label = Y[:small_train_classifier_data_length]\n",
    "\n",
    "len(small_train_classifier_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "a = np.zeros(100)\n",
    "for i in range(len(Y)):\n",
    "    a[Y[i]] += 1\n",
    "\n",
    "sort_a = np.sort(a)\n",
    "class_index = np.argsort(a)\n",
    "select_class = class_index[90:]\n",
    "select_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class10_index = []\n",
    "for i in range(len(Y)):\n",
    "    if Y[i] in select_class:\n",
    "        class10_index.append(i)\n",
    "\n",
    "class10_index = np.asarray(class10_index)\n",
    "class10_index.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "ori_class10_label = Y[class10_index]\n",
    "print(ori_class10_label.shape)\n",
    "class10_data = X[class10_index]\n",
    "sort_select_class = np.sort(select_class).tolist()\n",
    "sort_select_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class10_label = np.zeros(len(ori_class10_label), dtype=int)\n",
    "for i in range(len(class10_label)):\n",
    "    class10_label[i] = sort_select_class.index(ori_class10_label[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class10_train_classifier_data = class10_data[:7000]\n",
    "class10_train_attack_data = class10_data[7000:14000]\n",
    "class10_test_data = class10_data[14000:]\n",
    "\n",
    "class10_train_classifier_label = class10_label[:7000]\n",
    "class10_train_attack_label = class10_label[7000:14000]\n",
    "class10_test_label = class10_label[14000:]\n",
    "\n",
    "print('class10_train_classifier_data: ',len(class10_train_classifier_data))\n",
    "\n",
    "print('class10_train_attack_data: ',len(class10_train_attack_data))\n",
    "\n",
    "print('class10_test_data: ',len(class10_test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# npdata = np.load('texas10_sort_data.npz')\n",
    "# sort_class10_data = npdata['x'][:,:]\n",
    "# sort_class10_label = npdata['y'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class10_500_trainset_index = []\n",
    "class10_500_attack_index = []\n",
    "class10_500_testset_index = []\n",
    "class10_500_count = np.zeros(10)\n",
    "for i in range(len(class10_label)):\n",
    "    if(class10_500_count[class10_label[i]]<500):\n",
    "        class10_500_trainset_index.append(i)\n",
    "        class10_500_count[class10_label[i]] += 1\n",
    "    elif(500<= class10_500_count[class10_label[i]]<1000):\n",
    "        class10_500_attack_index.append(i)\n",
    "        class10_500_count[class10_label[i]] += 1\n",
    "    elif(1000<= class10_500_count[class10_label[i]]<1500):\n",
    "        class10_500_testset_index.append(i)\n",
    "        class10_500_count[class10_label[i]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class10_500_trainset_index = np.asarray(class10_500_trainset_index)\n",
    "class10_500_attack_index = np.asarray(class10_500_attack_index)\n",
    "class10_500_testset_index = np.asarray(class10_500_testset_index)\n",
    "\n",
    "print(class10_500_trainset_index.shape)\n",
    "print(class10_500_attack_index.shape)\n",
    "print(class10_500_testset_index.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class10_500_trainset_data = class10_data[class10_500_trainset_index]\n",
    "class10_500_attack_data = class10_data[class10_500_attack_index]\n",
    "class10_500_testset_data = class10_data[class10_500_testset_index]\n",
    "\n",
    "class10_500_trainset_label = class10_label[class10_500_trainset_index]\n",
    "class10_500_attack_label = class10_label[class10_500_attack_index]\n",
    "class10_500_testset_label = class10_label[class10_500_testset_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class10_500_trainset_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# start train\n",
    "lr=0.001\n",
    "epochs=20\n",
    "# p = 0.7\n",
    "state={}\n",
    "state['lr']=lr\n",
    "# net = Texas()\n",
    "# net = Texas_drop(p=p)\n",
    "# net = Texas_2layer()\n",
    "# net = Texas_1layer(num_classes=10)\n",
    "net = Texas_layer_out(num_classes=100)\n",
    "net = torch.nn.DataParallel(net).cuda()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=lr)\n",
    "batch_size=128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    global state\n",
    "    if epoch in [800, 1500]:\n",
    "#     if epoch in [100, 90]:\n",
    "        state['lr'] *= 10 \n",
    "#         state['lr'] *= 1\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = state['lr']\n",
    "    if epoch in [810,400,80,150, 1500]:\n",
    "#     if epoch in [100, 90]:\n",
    "        state['lr'] *= 0.1 \n",
    "#         state['lr'] *= 1\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = state['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "batch_size=256\n",
    "best_acc = 0.0\n",
    "best_epoch = 0\n",
    "epochs = 100\n",
    "num_class = 100\n",
    "mean_class = np.zeros((num_class,num_class))\n",
    "var_n = np.zeros(num_class)\n",
    "alpha = 20\n",
    "beta = 0\n",
    "train_time_list = []\n",
    "print('alpha = ', alpha, ' beta = ', beta)\n",
    "\n",
    "for epoch in range(0, epochs):\n",
    "    adjust_learning_rate(optimizer, epoch)\n",
    "#     if epoch == 30:\n",
    "#         alpha = 3000\n",
    "#         print('alpha = ', alpha, ' beta = ', beta)\n",
    "    r= np.arange(len(train_classifier_data))\n",
    "    np.random.shuffle(r)\n",
    "    s_train_classifier_data = train_classifier_data[r]\n",
    "    s_train_classifier_label = train_classifier_label[r]\n",
    "    \n",
    "    train_classifier_data_tensor = torch.from_numpy(s_train_classifier_data).type(torch.FloatTensor)\n",
    "    train_classifier_label_tensor = torch.from_numpy(s_train_classifier_label).type(torch.LongTensor)\n",
    "    \n",
    "    \n",
    "    test_data_tensor = torch.from_numpy(test_data).type(torch.FloatTensor)\n",
    "    test_label_tensor = torch.from_numpy(test_label).type(torch.LongTensor)\n",
    "    \n",
    "    print('\\nEpoch: [%d | %d] LR: %f' % (epoch + 1, epochs, state['lr']))\n",
    "    train_time = time.time()\n",
    "    train_loss, train_acc, diff, var = train_half_diff_min_var(train_classifier_data_tensor,train_classifier_label_tensor, net, criterion, optimizer, alpha, epoch, use_cuda, var_n,mean_class,beta)\n",
    "    train_time_list.append(time.time()-train_time)\n",
    "    print ('train acc: %.4f, train loss: %.4f, train diff: %.4f, last var: %.4f'%(train_acc, train_loss, diff, var))\n",
    "    test_loss, test_acc = test(test_data_tensor,test_label_tensor, net, criterion, epoch, use_cuda)\n",
    "    #privacy_loss, privacy_acc = privacy_train(trainloader,testloader,model,inferenece_model,criterion_attack,optimizer_mem,epoch,use_cuda)\n",
    "    \n",
    "    # append logger file\n",
    "    \n",
    "    is_best = test_acc > best_acc\n",
    "    best_acc = max(test_acc, best_acc)\n",
    "    print ('test acc: %.4f, test loss: %.4f, best acc: %.4f'%(test_acc, test_loss, best_acc))\n",
    "    \n",
    "        # save model\n",
    "    if is_best or epoch+1 == epochs:\n",
    "        if best_acc > 50:\n",
    "            best_epoch = epoch+1;\n",
    "            save_checkpoint({\n",
    "                    'epoch': epoch + 1,\n",
    "                    'state_dict': net.state_dict(),\n",
    "                    'acc': test_acc,\n",
    "                    'best_acc': best_acc,\n",
    "                    'optimizer' : optimizer.state_dict(),\n",
    "                }, is_best, filename='Texas_5layer_balance_output_partition_alpha20_min_var_beta0_epoch_%d'%(epoch+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "batch_size=256\n",
    "best_acc = 0.0\n",
    "best_epoch = 0\n",
    "epochs = 200\n",
    "num_class = 100\n",
    "mean_class = np.zeros((num_class,num_class))\n",
    "var_n = np.zeros(num_class)\n",
    "alpha = 500\n",
    "beta = 3000\n",
    "train_time_list = []\n",
    "print('alpha = ', alpha, ' beta = ', beta)\n",
    "\n",
    "for epoch in range(0, epochs):\n",
    "    adjust_learning_rate(optimizer, epoch)\n",
    "#     if epoch == 30:\n",
    "#         alpha = 3000\n",
    "#         print('alpha = ', alpha, ' beta = ', beta)\n",
    "    r= np.arange(len(train_classifier_data))\n",
    "    np.random.shuffle(r)\n",
    "    s_train_classifier_data = train_classifier_data[r]\n",
    "    s_train_classifier_label = train_classifier_label[r]\n",
    "    \n",
    "    train_classifier_data_tensor = torch.from_numpy(s_train_classifier_data).type(torch.FloatTensor)\n",
    "    train_classifier_label_tensor = torch.from_numpy(s_train_classifier_label).type(torch.LongTensor)\n",
    "    \n",
    "    \n",
    "    test_data_tensor = torch.from_numpy(test_data).type(torch.FloatTensor)\n",
    "    test_label_tensor = torch.from_numpy(test_label).type(torch.LongTensor)\n",
    "    \n",
    "    print('\\nEpoch: [%d | %d] LR: %f' % (epoch + 1, epochs, state['lr']))\n",
    "    train_time = time.time()\n",
    "    train_loss, train_acc, diff, var = train_half_diff_min_var(train_classifier_data_tensor,train_classifier_label_tensor, net, criterion, optimizer, alpha, epoch, use_cuda, var_n,mean_class,beta)\n",
    "    train_time_list.append(time.time()-train_time)\n",
    "    print ('train acc: %.4f, train loss: %.4f, train diff: %.4f, last var: %.4f'%(train_acc, train_loss, diff, var))\n",
    "    test_loss, test_acc = test(test_data_tensor,test_label_tensor, net, criterion, epoch, use_cuda)\n",
    "    #privacy_loss, privacy_acc = privacy_train(trainloader,testloader,model,inferenece_model,criterion_attack,optimizer_mem,epoch,use_cuda)\n",
    "    \n",
    "    # append logger file\n",
    "    \n",
    "    is_best = test_acc > best_acc\n",
    "    best_acc = max(test_acc, best_acc)\n",
    "    print ('test acc: %.4f, test loss: %.4f, best acc: %.4f'%(test_acc, test_loss, best_acc))\n",
    "    \n",
    "        # save model\n",
    "    if is_best or epoch+1 == epochs:\n",
    "        if best_acc > 50:\n",
    "            best_epoch = epoch+1;\n",
    "            save_checkpoint({\n",
    "                    'epoch': epoch + 1,\n",
    "                    'state_dict': net.state_dict(),\n",
    "                    'acc': test_acc,\n",
    "                    'best_acc': best_acc,\n",
    "                    'optimizer' : optimizer.state_dict(),\n",
    "                }, is_best, filename='Texas_5layer_balance_output_partition_alpha500_min_var_beta3000_epoch_%d'%(epoch+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "batch_size=128\n",
    "best_acc = 0.0\n",
    "best_epoch = 0\n",
    "epochs = 200\n",
    "num_class = 100\n",
    "mean_class = np.zeros((num_class,num_class))\n",
    "var_n = np.zeros(num_class)\n",
    "alpha = 1000\n",
    "beta = 200\n",
    "print('alpha = ', alpha, ' beta = ', beta)\n",
    "\n",
    "for epoch in range(0, epochs):\n",
    "    adjust_learning_rate(optimizer, epoch)\n",
    "    if epoch == 30:\n",
    "        alpha = 3000\n",
    "        print('alpha = ', alpha, ' beta = ', beta)\n",
    "    r= np.arange(len(train_classifier_data))\n",
    "    np.random.shuffle(r)\n",
    "    s_train_classifier_data = train_classifier_data[r]\n",
    "    s_train_classifier_label = train_classifier_label[r]\n",
    "    \n",
    "    train_classifier_data_tensor = torch.from_numpy(s_train_classifier_data).type(torch.FloatTensor)\n",
    "    train_classifier_label_tensor = torch.from_numpy(s_train_classifier_label).type(torch.LongTensor)\n",
    "    \n",
    "    \n",
    "    test_data_tensor = torch.from_numpy(test_data).type(torch.FloatTensor)\n",
    "    test_label_tensor = torch.from_numpy(test_label).type(torch.LongTensor)\n",
    "    \n",
    "    print('\\nEpoch: [%d | %d] LR: %f' % (epoch + 1, epochs, state['lr']))\n",
    "        \n",
    "    train_loss, train_acc, diff, var = train_half_diff_min_var(train_classifier_data_tensor,train_classifier_label_tensor, net, criterion, optimizer, alpha, epoch, use_cuda, var_n,mean_class,beta)\n",
    "    print ('train acc: %.4f, train loss: %.4f, train diff: %.4f, last var: %.4f'%(train_acc, train_loss, diff, var))\n",
    "    test_loss, test_acc = test(test_data_tensor,test_label_tensor, net, criterion, epoch, use_cuda)\n",
    "    #privacy_loss, privacy_acc = privacy_train(trainloader,testloader,model,inferenece_model,criterion_attack,optimizer_mem,epoch,use_cuda)\n",
    "    \n",
    "    # append logger file\n",
    "    \n",
    "    is_best = test_acc > best_acc\n",
    "    best_acc = max(test_acc, best_acc)\n",
    "    print ('test acc: %.4f, test loss: %.4f, best acc: %.4f'%(test_acc, test_loss, best_acc))\n",
    "    \n",
    "    # save model\n",
    "    if is_best or epoch+1 == epochs:\n",
    "        if best_acc > 40:\n",
    "            best_epoch = epoch+1;\n",
    "            save_checkpoint({\n",
    "                    'epoch': epoch + 1,\n",
    "                    'state_dict': net.state_dict(),\n",
    "                    'acc': test_acc,\n",
    "                    'best_acc': best_acc,\n",
    "                    'optimizer' : optimizer.state_dict(),\n",
    "                }, False, filename='Texas_5layer_balance_output_partition_alpha3000_min_var_beta200_epoch_%d'%(epoch+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# lr = 0.001\n",
    "batch_size=256\n",
    "best_acc = 0.0\n",
    "best_epoch = 0\n",
    "epochs = 100\n",
    "for epoch in range(0, epochs):\n",
    "    adjust_learning_rate(optimizer, epoch)\n",
    "    r= np.arange(len(train_classifier_data))\n",
    "    np.random.shuffle(r)\n",
    "    s_train_classifier_data = train_classifier_data[r]\n",
    "    s_train_classifier_label = train_classifier_label[r]\n",
    "    \n",
    "    train_classifier_data_tensor = torch.from_numpy(s_train_classifier_data).type(torch.FloatTensor)\n",
    "    train_classifier_label_tensor = torch.from_numpy(s_train_classifier_label).type(torch.LongTensor)\n",
    "    \n",
    "    \n",
    "    test_data_tensor = torch.from_numpy(test_data).type(torch.FloatTensor)\n",
    "    test_label_tensor = torch.from_numpy(test_label).type(torch.LongTensor)\n",
    "    \n",
    "    print('\\nEpoch: [%d | %d] LR: %f' % (epoch + 1, epochs, state['lr']))\n",
    "        \n",
    "    train_loss, train_acc = train(train_classifier_data_tensor,train_classifier_label_tensor, net, criterion, optimizer, epoch, use_cuda)\n",
    "    print ('train acc: %.4f, train loss: %.4f'%(train_acc, train_loss))\n",
    "    test_loss, test_acc = test(test_data_tensor,test_label_tensor, net, criterion, epoch, use_cuda)\n",
    "    #privacy_loss, privacy_acc = privacy_train(trainloader,testloader,model,inferenece_model,criterion_attack,optimizer_mem,epoch,use_cuda)\n",
    "    \n",
    "    # append logger file\n",
    "    \n",
    "    is_best = test_acc > best_acc\n",
    "    best_acc = max(test_acc, best_acc)\n",
    "    print ('test acc: %.4f, test loss: %.4f, best acc: %.4f'%(test_acc, test_loss, best_acc))\n",
    "    \n",
    "    # save model\n",
    "    if is_best or epoch+1 == epochs:\n",
    "        if best_acc > 40:\n",
    "            best_epoch = epoch+1;\n",
    "            save_checkpoint({\n",
    "                    'epoch': epoch + 1,\n",
    "                    'state_dict': net.state_dict(),\n",
    "                    'acc': test_acc,\n",
    "                    'best_acc': best_acc,\n",
    "                    'optimizer' : optimizer.state_dict(),\n",
    "                }, False, filename='Texas100_5layer_No_defenss_epoch_%d'%(epoch+1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# lr = 0.0001\n",
    "batch_size=128\n",
    "best_acc = 0.0\n",
    "best_epoch = 0\n",
    "epochs = 100\n",
    "for epoch in range(0, epochs):\n",
    "    adjust_learning_rate(optimizer, epoch)\n",
    "    r= np.arange(len(small_train_classifier_data))\n",
    "    np.random.shuffle(r)\n",
    "    s_train_classifier_data = small_train_classifier_data[r]\n",
    "    s_train_classifier_label = small_train_classifier_label[r]\n",
    "    \n",
    "    train_classifier_data_tensor = torch.from_numpy(s_train_classifier_data).type(torch.FloatTensor)\n",
    "    train_classifier_label_tensor = torch.from_numpy(s_train_classifier_label).type(torch.LongTensor)\n",
    "    \n",
    "    \n",
    "    test_data_tensor = torch.from_numpy(test_data).type(torch.FloatTensor)\n",
    "    test_label_tensor = torch.from_numpy(test_label).type(torch.LongTensor)\n",
    "    \n",
    "    print('\\nEpoch: [%d | %d] LR: %f' % (epoch + 1, epochs, state['lr']))\n",
    "        \n",
    "    train_loss, train_acc = train(train_classifier_data_tensor,train_classifier_label_tensor, net, criterion, optimizer, epoch, use_cuda)\n",
    "    print ('train acc: %.4f, train loss: %.4f'%(train_acc, train_loss))\n",
    "    test_loss, test_acc = test(test_data_tensor,test_label_tensor, net, criterion, epoch, use_cuda)\n",
    "    #privacy_loss, privacy_acc = privacy_train(trainloader,testloader,model,inferenece_model,criterion_attack,optimizer_mem,epoch,use_cuda)\n",
    "    \n",
    "    # append logger file\n",
    "    \n",
    "    is_best = test_acc > best_acc\n",
    "    best_acc = max(test_acc, best_acc)\n",
    "    print ('test acc: %.4f, test loss: %.4f, best acc: %.4f'%(test_acc, test_loss, best_acc))\n",
    "    \n",
    "    # save model\n",
    "    if is_best or epoch+1 == epochs:\n",
    "        if best_acc > 58:\n",
    "            best_epoch = epoch+1;\n",
    "            save_checkpoint({\n",
    "                    'epoch': epoch + 1,\n",
    "                    'state_dict': net.state_dict(),\n",
    "                    'acc': test_acc,\n",
    "                    'best_acc': best_acc,\n",
    "                    'optimizer' : optimizer.state_dict(),\n",
    "                }, False, filename='Small_1_layer_No_defenss_100_epoch_%d'%(epoch+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# lr = 0.0001\n",
    "batch_size=128\n",
    "best_acc = 0.0\n",
    "best_epoch = 0\n",
    "epochs = 40\n",
    "for epoch in range(0, epochs):\n",
    "    adjust_learning_rate(optimizer, epoch)\n",
    "    r= np.arange(len(small_train_classifier_data))\n",
    "    np.random.shuffle(r)\n",
    "    s_train_classifier_data = small_train_classifier_data[r]\n",
    "    s_train_classifier_label = small_train_classifier_label[r]\n",
    "    \n",
    "    train_classifier_data_tensor = torch.from_numpy(s_train_classifier_data).type(torch.FloatTensor)\n",
    "    train_classifier_label_tensor = torch.from_numpy(s_train_classifier_label).type(torch.LongTensor)\n",
    "    \n",
    "    \n",
    "    test_data_tensor = torch.from_numpy(test_data).type(torch.FloatTensor)\n",
    "    test_label_tensor = torch.from_numpy(test_label).type(torch.LongTensor)\n",
    "    \n",
    "    print('\\nEpoch: [%d | %d] LR: %f' % (epoch + 1, epochs, state['lr']))\n",
    "        \n",
    "    train_loss, train_acc = train(train_classifier_data_tensor,train_classifier_label_tensor, net, criterion, optimizer, epoch, use_cuda)\n",
    "    print ('train acc: %.4f, train loss: %.4f'%(train_acc, train_loss))\n",
    "    test_loss, test_acc = test(test_data_tensor,test_label_tensor, net, criterion, epoch, use_cuda)\n",
    "    #privacy_loss, privacy_acc = privacy_train(trainloader,testloader,model,inferenece_model,criterion_attack,optimizer_mem,epoch,use_cuda)\n",
    "    \n",
    "    # append logger file\n",
    "    \n",
    "    is_best = test_acc > best_acc\n",
    "    best_acc = max(test_acc, best_acc)\n",
    "    print ('test acc: %.4f, test loss: %.4f, best acc: %.4f'%(test_acc, test_loss, best_acc))\n",
    "    \n",
    "    # save model\n",
    "    if is_best or epoch+1 == epochs:\n",
    "        if best_acc > 40:\n",
    "            best_epoch = epoch+1;\n",
    "            save_checkpoint({\n",
    "                    'epoch': epoch + 1,\n",
    "                    'state_dict': net.state_dict(),\n",
    "                    'acc': test_acc,\n",
    "                    'best_acc': best_acc,\n",
    "                    'optimizer' : optimizer.state_dict(),\n",
    "                }, False, filename='Small_1_layer_No_defenss_epoch_%d'%(epoch+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# lr = 0.0001\n",
    "batch_size=128\n",
    "# best_acc = 0.0\n",
    "best_epoch = 0\n",
    "epochs = 80\n",
    "for epoch in range(40, epochs):\n",
    "    adjust_learning_rate(optimizer, epoch)\n",
    "    r= np.arange(len(small_train_classifier_data))\n",
    "    np.random.shuffle(r)\n",
    "    s_train_classifier_data = small_train_classifier_data[r]\n",
    "    s_train_classifier_label = small_train_classifier_label[r]\n",
    "    \n",
    "    train_classifier_data_tensor = torch.from_numpy(s_train_classifier_data).type(torch.FloatTensor)\n",
    "    train_classifier_label_tensor = torch.from_numpy(s_train_classifier_label).type(torch.LongTensor)\n",
    "    \n",
    "    \n",
    "    test_data_tensor = torch.from_numpy(test_data).type(torch.FloatTensor)\n",
    "    test_label_tensor = torch.from_numpy(test_label).type(torch.LongTensor)\n",
    "    \n",
    "    print('\\nEpoch: [%d | %d] LR: %f' % (epoch + 1, epochs, state['lr']))\n",
    "        \n",
    "    train_loss, train_acc = train(train_classifier_data_tensor,train_classifier_label_tensor, net, criterion, optimizer, epoch, use_cuda)\n",
    "    print ('train acc: %.4f, train loss: %.4f'%(train_acc, train_loss))\n",
    "    test_loss, test_acc = test(test_data_tensor,test_label_tensor, net, criterion, epoch, use_cuda)\n",
    "    #privacy_loss, privacy_acc = privacy_train(trainloader,testloader,model,inferenece_model,criterion_attack,optimizer_mem,epoch,use_cuda)\n",
    "    \n",
    "    # append logger file\n",
    "    \n",
    "    is_best = test_acc > best_acc\n",
    "    best_acc = max(test_acc, best_acc)\n",
    "    print ('test acc: %.4f, test loss: %.4f, best acc: %.4f'%(test_acc, test_loss, best_acc))\n",
    "    \n",
    "    # save model\n",
    "    if is_best or epoch+1 == epochs:\n",
    "        if best_acc > 40:\n",
    "            best_epoch = epoch+1;\n",
    "            save_checkpoint({\n",
    "                    'epoch': epoch + 1,\n",
    "                    'state_dict': net.state_dict(),\n",
    "                    'acc': test_acc,\n",
    "                    'best_acc': best_acc,\n",
    "                    'optimizer' : optimizer.state_dict(),\n",
    "                }, False, filename='Small_1_layer_No_defenss_epoch_%d'%(epoch+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# lr = 0.00001\n",
    "batch_size=128\n",
    "# best_acc = 0.0\n",
    "best_epoch = 0\n",
    "epochs = 120\n",
    "for epoch in range(80, epochs):\n",
    "    adjust_learning_rate(optimizer, epoch)\n",
    "    r= np.arange(len(small_train_classifier_data))\n",
    "    np.random.shuffle(r)\n",
    "    s_train_classifier_data = small_train_classifier_data[r]\n",
    "    s_train_classifier_label = small_train_classifier_label[r]\n",
    "    \n",
    "    train_classifier_data_tensor = torch.from_numpy(s_train_classifier_data).type(torch.FloatTensor)\n",
    "    train_classifier_label_tensor = torch.from_numpy(s_train_classifier_label).type(torch.LongTensor)\n",
    "    \n",
    "    \n",
    "    test_data_tensor = torch.from_numpy(test_data).type(torch.FloatTensor)\n",
    "    test_label_tensor = torch.from_numpy(test_label).type(torch.LongTensor)\n",
    "    \n",
    "    print('\\nEpoch: [%d | %d] LR: %f' % (epoch + 1, epochs, state['lr']))\n",
    "        \n",
    "    train_loss, train_acc = train(train_classifier_data_tensor,train_classifier_label_tensor, net, criterion, optimizer, epoch, use_cuda)\n",
    "    print ('train acc: %.4f, train loss: %.4f'%(train_acc, train_loss))\n",
    "    test_loss, test_acc = test(test_data_tensor,test_label_tensor, net, criterion, epoch, use_cuda)\n",
    "    #privacy_loss, privacy_acc = privacy_train(trainloader,testloader,model,inferenece_model,criterion_attack,optimizer_mem,epoch,use_cuda)\n",
    "    \n",
    "    # append logger file\n",
    "    \n",
    "    is_best = test_acc > best_acc\n",
    "    best_acc = max(test_acc, best_acc)\n",
    "    print ('test acc: %.4f, test loss: %.4f, best acc: %.4f'%(test_acc, test_loss, best_acc))\n",
    "    \n",
    "    # save model\n",
    "    if is_best or epoch+1 == epochs:\n",
    "        if best_acc > 40:\n",
    "            best_epoch = epoch+1;\n",
    "            save_checkpoint({\n",
    "                    'epoch': epoch + 1,\n",
    "                    'state_dict': net.state_dict(),\n",
    "                    'acc': test_acc,\n",
    "                    'best_acc': best_acc,\n",
    "                    'optimizer' : optimizer.state_dict(),\n",
    "                }, False, filename='Small_1_layer_No_defenss_epoch_%d'%(epoch+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# model debug\n",
    "model = net\n",
    "num_batchs = 99999\n",
    "alpha = 100.0\n",
    "\n",
    "batch_size = 1000\n",
    "\n",
    "# r= np.arange(len(train_classifier_data))\n",
    "# np.random.shuffle(r)\n",
    "# train_classifier_data = train_classifier_data[r]\n",
    "# train_classifier_label = train_classifier_label[r]\n",
    "\n",
    "class_num = 100\n",
    "# set_index = np.argsort(train_classifier_label)\n",
    "# sort_train_classifier_data = train_classifier_data[set_index]\n",
    "# sort_train_classifier_label = train_classifier_label[set_index]\n",
    "\n",
    "# class_count = np.zeros(class_num, dtype=int)\n",
    "# for i in range(len(sort_train_classifier_label)):\n",
    "#     class_count[sort_train_classifier_label[i]] += 1\n",
    "    \n",
    "# class_sum = 0\n",
    "# class_index = np.zeros(class_num+1, dtype=int)\n",
    "# for i in range(class_num):\n",
    "#     class_index[i] = class_sum\n",
    "#     class_sum += class_count[i]\n",
    "# class_index[class_num] = class_sum\n",
    "\n",
    "\n",
    "# train_classifier_data_tensor = torch.from_numpy(sort_train_classifier_data).type(torch.FloatTensor)\n",
    "# train_classifier_label_tensor = torch.from_numpy(sort_train_classifier_label).type(torch.LongTensor)\n",
    "\n",
    "\n",
    "test_data_tensor = torch.from_numpy(train_classifier_data).type(torch.FloatTensor)\n",
    "test_label_tensor = torch.from_numpy(train_classifier_label).type(torch.LongTensor)\n",
    "print(test_label_tensor)\n",
    "model.train()\n",
    "softmax = nn.Softmax()\n",
    "\n",
    "batch_time = AverageMeter()\n",
    "data_time = AverageMeter()\n",
    "losses = AverageMeter()\n",
    "top1 = AverageMeter()\n",
    "top5 = AverageMeter()\n",
    "\n",
    "\n",
    "end = time.time()\n",
    "len_t = 10\n",
    "# len_t =  (len(train_classifier_label_tensor)//batch_size)-1\n",
    "# len_t = np.max(class_count)/10\n",
    "batch_index = np.copy(class_index)\n",
    "batch_data = torch.Tensor()\n",
    "batch_label = torch.LongTensor()\n",
    "for ind in range(len_t):\n",
    "    if ind > num_batchs:\n",
    "        break\n",
    "#     # measure data loading time\n",
    "#     inputs = train_classifier_data_tensor[ind*batch_size:(ind+1)*batch_size]\n",
    "#     targets = train_classifier_label_tensor[ind*batch_size:(ind+1)*batch_size]\n",
    "    inputs = test_data_tensor[ind*batch_size:(ind+1)*batch_size]\n",
    "    targets = test_label_tensor[ind*batch_size:(ind+1)*batch_size]\n",
    "#     inputs = torch.Tensor()\n",
    "#     targets = torch.LongTensor()\n",
    "#     print('\\nIndex: ',ind)\n",
    "#     for i in range(class_num):\n",
    "#         if (batch_index[i] + 10) > class_index[i+1]:\n",
    "#         #             batch_data = sort_train_classifier_data[batch_index[i]: class_index[i+1]]\n",
    "#             print('batch_index[i]: ', batch_index[i], 'i: ',i)\n",
    "#             batch_index[i] = class_index[i]\n",
    "#             print('reassign batch_index[i]: ', batch_index[i], 'i: ',i)\n",
    "#             print('class_index: ',class_index)\n",
    "#             inputs = torch.cat((inputs, train_classifier_data_tensor[batch_index[i]: batch_index[i] + 10]), 0)\n",
    "#             targets = torch.cat((targets, train_classifier_label_tensor[batch_index[i]: batch_index[i] + 10]),0)\n",
    "#             batch_index[i] = batch_index[i] + 10\n",
    "\n",
    "#         else:\n",
    "#             inputs = torch.cat((inputs, train_classifier_data_tensor[batch_index[i]: batch_index[i] + 10]), 0)\n",
    "#             targets= torch.cat((targets, train_classifier_label_tensor[batch_index[i]: batch_index[i] + 10]),0)\n",
    "#             batch_index[i] = batch_index[i] + 10\n",
    "    \n",
    "    data_time.update(time.time() - end)\n",
    "    if use_cuda:\n",
    "        inputs, targets = inputs.cuda(), targets.cuda()\n",
    "    inputs, targets = torch.autograd.Variable(inputs), torch.autograd.Variable(targets)\n",
    "\n",
    "    # compute output\n",
    "    outputs,y1,y2,y3,y4 = model(inputs)\n",
    "\n",
    "    soft_outputs = softmax(outputs)\n",
    "    max_outputs = torch.max(soft_outputs,1).values\n",
    "#     var = []\n",
    "    \n",
    "#     print('soft_outputs.shape: ', soft_outputs.shape)\n",
    "#     print(soft_outputs[99*10:(99+1)*10])\n",
    "#     for i in range(class_num):\n",
    "#         mean_outputs = torch.mean(soft_outputs[i*10:(i+1)*10],0)\n",
    "#         var.append(torch.mean(torch.sum((soft_outputs[i*10:(i+1)*10] - mean_outputs).pow(2),1)))\n",
    "#     batch_var = torch.stack(var,0)\n",
    "#     print(\"batch_var:\", batch_var)\n",
    "#     loss_var = alpha*(-torch.mean(batch_var))\n",
    "#     loss = criterion(outputs, targets) #+ loss_var\n",
    "# #     print(\"loss_var:\" ,loss_var)\n",
    "\n",
    "    # measure accuracy and record loss\n",
    "    prec1, prec5 = accuracy(outputs.data, targets.data, topk=(1, 5))\n",
    "#     losses.update(loss.data, inputs.size()[0])\n",
    "#     top1.update(prec1, inputs.size()[0])\n",
    "#     top5.update(prec5, inputs.size()[0])\n",
    "\n",
    "    print(prec1)\n",
    "    # compute gradient and do SGD step\n",
    "#     optimizer.zero_grad()\n",
    "#     loss.backward()\n",
    "#     optimizer.step()\n",
    "\n",
    "    # measure elapsed time\n",
    "    batch_time.update(time.time() - end)\n",
    "    end = time.time()\n",
    "    if ind == 10:\n",
    "        break\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "torch.mean(torch.var(soft_outputs,0))\n",
    "\n",
    "y2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "probs = soft_outputs\n",
    "true_labels = targets\n",
    "print(probs)\n",
    "log_probs = _log_value(probs)\n",
    "reverse_probs = 1-probs\n",
    "log_reverse_probs = _log_value(reverse_probs)\n",
    "modified_probs = probs.detach().clone()\n",
    "modified_probs[range(true_labels.size(0)), true_labels] = reverse_probs[range(true_labels.size(0)), true_labels]\n",
    "modified_log_probs = log_reverse_probs.detach().clone()\n",
    "modified_log_probs[range(true_labels.size(0)), true_labels] = log_probs[range(true_labels.size(0)), true_labels]\n",
    "me = torch.sum(torch.mul(modified_probs, modified_log_probs),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "torch.var(me)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "fig = plt.figure(figsize=(20,15))\n",
    "\n",
    "plt.hist(me.data.cpu().numpy(), bins=10, label = 'me')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "s_tr_m_entr = _m_entr_comp(soft_outputs.data.cpu().numpy(), targets.data.cpu().numpy())\n",
    "loss = criterion(outputs, targets) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "mean1 = np.mean(s_tr_m_entr)\n",
    "mean1\n",
    "np.var(s_tr_m_entr)\n",
    "\n",
    "inputs.size()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "np.mean(np.power(np.abs(s_tr_m_entr - mean1),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "out_list = [y1,y2,y3,y4,y5, outputs]\n",
    "out_list[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "out_list = [y1,y2,y3,y4,y5, outputs]\n",
    "out_list[0].shape\n",
    "sum_diff = torch.zeros(out_list[0].shape[0]).cuda()\n",
    "for out_layer in out_list:\n",
    "    \n",
    "    # hidden_outputs.shape\n",
    "    hidden_map = torch.ones(out_layer.shape[1]).cuda()\n",
    "    hidden_map[out_layer.shape[1]//2:] = -1\n",
    "#     torch.sum(hidden_map)\n",
    "    hd_diff_map = out_layer * hidden_map\n",
    "    # hd_diff_map.shape\n",
    "    hd_diff = torch.sum(hd_diff_map, 1)\n",
    "    var_hd = hd_diff ** 2 / hd_diff_map.shape[1]\n",
    "    print(hd_diff_map.shape[1])\n",
    "    sum_diff += var_hd\n",
    "# output_map = torch.ones(10).cuda()\n",
    "# output_map[5:] = -1\n",
    "# output_diff_map = outputs * output_map\n",
    "# # hd_diff_map.shape\n",
    "# output_diff = torch.mean(torch.sum(output_diff_map , 1))\n",
    "# output_diff \n",
    "\n",
    "# diff_var = (hd_diff ** 2 + output_diff ** 2)/2\n",
    "# diff_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "var_hd = hd_diff ** 2 / y5.shape[1]\n",
    "var_hd[0]\n",
    "sum_diff.mean() * alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "outputs.shape\n",
    "output_map = torch.ones(10).cuda()\n",
    "output_map[5:] = -1\n",
    "output_diff_map = outputs * output_map\n",
    "# hd_diff_map.shape\n",
    "output_diff = torch.mean(torch.sum(output_diff_map , 1))\n",
    "output_diff "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "r= np.arange(len(train_classifier_data))\n",
    "np.random.shuffle(r)\n",
    "train_classifier_data = train_classifier_data[r]\n",
    "train_classifier_label = train_classifier_label[r]\n",
    "set_index = np.argsort(train_classifier_label)\n",
    "set_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print(train_classifier_label[set_index[105]])\n",
    "print(np.where(train_classifier_data[set_index[105]]==1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "fortrain_classifier_data[set_index[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "sf_output = soft_outputs[38].data.cpu().numpy()\n",
    "pyplot.plot(sf_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "r1= np.arange(len(train_classifier_data)*0.75)\n",
    "np.random.shuffle(np.intc(r1))\n",
    "r1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "r2= np.arange(len(train_classifier_data)*0.25)\n",
    "# np.random.shuffle(r2)\n",
    "r2 = np.intc(r2) + np.intc(len(train_classifier_data)*0.75)\n",
    "r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "max(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model = net\n",
    "num_batchs = 99999\n",
    "alpha = 1.0\n",
    "\n",
    "r1= np.arange(len(train_classifier_data)*0.75)\n",
    "np.random.shuffle(r1)\n",
    "r1 = np.intc(r1)\n",
    "train_data = train_classifier_data[r1]\n",
    "train_label = train_classifier_label[r1]\n",
    "\n",
    "train_classifier_data_tensor = torch.from_numpy(train_classifier_data).type(torch.FloatTensor)\n",
    "train_classifier_label_tensor = torch.from_numpy(train_classifier_label).type(torch.LongTensor)\n",
    "\n",
    "r2= np.arange(len(train_classifier_data)*0.25)\n",
    "r2 = np.intc(r2) + np.intc(len(train_classifier_data)*0.75)\n",
    "untrain_classifier_data = train_classifier_data[r2]\n",
    "untrain_classifier_label = train_classifier_label[r2]\n",
    "\n",
    "untrain_classifier_data_tensor = torch.from_numpy(untrain_classifier_data).type(torch.FloatTensor)\n",
    "untrain_classifier_label_tensor = torch.from_numpy(untrain_classifier_label).type(torch.LongTensor)\n",
    "\n",
    "\n",
    "train_data = train_classifier_data_tensor\n",
    "labels = train_classifier_label_tensor\n",
    "untrain_data = untrain_classifier_data_tensor\n",
    "untrain_labels = untrain_classifier_label_tensor\n",
    "\n",
    "\n",
    "model.train()\n",
    "softmax = nn.Softmax()\n",
    "\n",
    "batch_time = AverageMeter()\n",
    "data_time = AverageMeter()\n",
    "losses = AverageMeter()\n",
    "top1 = AverageMeter()\n",
    "top5 = AverageMeter()\n",
    "\n",
    "end = time.time()\n",
    "len_t =  (len(train_classifier_label_tensor)//batch_size)-1\n",
    "\n",
    "for ind in range(len_t):\n",
    "    if ind > num_batchs:\n",
    "        break\n",
    "    # measure data loading time\n",
    "    inputs = train_data[ind*batch_size:(ind+1)*batch_size]\n",
    "    targets = labels[ind*batch_size:(ind+1)*batch_size]\n",
    "    r= np.arange(untrain_data.shape[0])\n",
    "    np.random.shuffle(r)\n",
    "    untrain_inputs = untrain_data[r[:batch_size]]\n",
    "    untrain_targets = untrain_labels[r[:batch_size]]\n",
    "\n",
    "    data_time.update(time.time() - end)\n",
    "    if use_cuda:\n",
    "        inputs, targets = inputs.cuda(), targets.cuda()\n",
    "    inputs, targets = torch.autograd.Variable(inputs), torch.autograd.Variable(targets)\n",
    "\n",
    "    # compute output\n",
    "    outputs,_ = model(inputs)\n",
    "    untrain_outputs,_ = model(untrain_inputs)\n",
    "\n",
    "    soft_outputs = softmax(outputs)\n",
    "    soft_untrain_outputs = softmax(untrain_outputs)\n",
    "\n",
    "#         max_outputs = torch.max(soft_outputs,1).values\n",
    "    sort_soft_outputs,_ = torch.sort(soft_outputs)\n",
    "    sort_soft_untrain_outputs,_ = torch.sort(soft_untrain_outputs)\n",
    "\n",
    "    loss = criterion(outputs, targets) + alpha*(torch.mean(torch.sum(torch.abs(sort_soft_outputs - sort_soft_untrain_outputs),1)))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "a = torch.abs(sort_soft_outputs - sort_soft_untrain_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "r2= np.arange(len(train_classifier_data)*0.25)\n",
    "\n",
    "r2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# train_classifier_data = X[:int(train_classifier_ratio*len_train)]\n",
    "# train_attack_data = X[int(train_classifier_ratio*len_train):int((train_classifier_ratio+train_attack_ratio)*len_train)]\n",
    "# test_data = X[int((train_classifier_ratio+train_attack_ratio)*len_train):]\n",
    "\n",
    "# train_classifier_label = Y[:int(train_classifier_ratio*len_train)]\n",
    "# train_attack_label = Y[int(train_classifier_ratio*len_train):int((train_classifier_ratio+train_attack_ratio)*len_train)]\n",
    "# test_label = Y[int((train_classifier_ratio+train_attack_ratio)*len_train):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "len(train_attack_data)\n",
    "\n",
    "r = np.arange(len(train_attack_data))\n",
    "r1 = np.arange(len(train_classifier_data))t\n",
    "np.random.shuffle(r)\n",
    "np.random.shuffle(r1)\n",
    "r2 = r1[r]\n",
    "\n",
    "print(len(r))\n",
    "print(len(r1))\n",
    "print(len(r2))\n",
    "\n",
    "print(max(r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# load saved model\n",
    "\n",
    "# test_data_c = X[int((train_classifier_ratio+train_attack_ratio)*len_train):]\n",
    "# test_label_c = Y[int((train_classifier_ratio+train_attack_ratio)*len_train):]\n",
    "# test_data_c = X[40000:60000]\n",
    "# test_label_c = Y[40000:60000]\n",
    "# test_data_c = class10_data[14000:]\n",
    "# test_label_c = class10_label[14000:]\n",
    "test_data_c = test_data\n",
    "test_label_c = test_label\n",
    "epoch=0\n",
    "batch_size=128\n",
    "# net = Texas()\n",
    "# net = Texas_drop(p)\n",
    "# net = Texas_2layer()\n",
    "# net = Texas_1layer(10)\n",
    "net = Texas_layer_out(100)\n",
    "# net = Texas_layer_out_scale(100, q = 50, alpha = 20)\n",
    "# net = Texas_layer_out_scale2(100, q = 50, alpha = 200)\n",
    "\n",
    "\n",
    "net = torch.nn.DataParallel(net).cuda()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.0001)\n",
    "print(len(test_data_c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# resume='./checkpoints_texas_10class_little_model_defense/Class10_1layer_Modify_min_sortvar_beta100_max_last8_alpha30_defense_epoch_9'\n",
    "resume='./checkpoints_texas/Texas_5layer_balance_output_partition_alpha100_min_var_beta3000_epoch_50'\n",
    "# resume='./checkpoints_texas_10class_little_model_defense/Texas_5layer_balance_output_partition_alpha300_min_var_beta3000_epoch_84'\n",
    "# resume='./checkpoints_texas_10class_little_model_defense/Texas_5layer_balance_output_partition_alpha500_min_var_beta3000_epoch_90'\n",
    "# resume='./checkpoints_texas_10class_little_model_defense/Texas_5layer_balance_output_partition_alpha20_min_var_beta0_epoch_13'\n",
    "# resume='./checkpoints_texas_10class_little_model_defense/Texas_5layer_balance_output_partition_alpha100_min_var_beta0_epoch_59'\n",
    "# resume='./checkpoints_texas_10class_little_model_defense/Texas_5layer_balance_output_partition_alpha300_min_var_beta0_epoch_100'\n",
    "\n",
    "checkpoint = os.path.dirname(resume)\n",
    "checkpoint = torch.load(resume)\n",
    "net.load_state_dict(checkpoint['state_dict'])\n",
    "print('==> Resumed from checkpoint..')\n",
    "epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "test_loss, final_test_acc = test(torch.from_numpy(test_data_c).type(torch.FloatTensor) ,torch.from_numpy(test_label_c).type(torch.LongTensor), net, criterion, epoch, use_cuda)\n",
    "\n",
    "print ('test_loss: {test_loss: .4f}, test_acc: {test_acc: .4f}'.format(test_loss=test_loss, test_acc=final_test_acc))\n",
    "\n",
    "# trainset_loss, trainset_acc = test(torch.from_numpy(small_train_classifier_data).type(torch.FloatTensor) ,torch.from_numpy(small_train_classifier_label).type(torch.LongTensor), net, criterion, epoch, use_cuda)\n",
    "\n",
    "trainset_loss, trainset_acc = test(torch.from_numpy(train_classifier_data).type(torch.FloatTensor) ,torch.from_numpy(train_classifier_label).type(torch.LongTensor), net, criterion, epoch, use_cuda)\n",
    "\n",
    "print ('trainset_loss: {trainset_loss: .4f}, trainset_acc: {trainset_acc: .4f}'.format(trainset_loss=trainset_loss, trainset_acc=trainset_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print(train_classifier_data.shape)\n",
    "print(test_data_c.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "x_evaluate_attacker_tensor = torch.from_numpy(train_classifier_data).type(torch.FloatTensor)\n",
    "y_evaluate_attacker_tensor = torch.from_numpy(train_classifier_label).type(torch.LongTensor)\n",
    "\n",
    "batch_size = 256\n",
    "\n",
    "net.eval()\n",
    "\n",
    "f_evaluate_logits = []\n",
    "f_evaluate_prob = []\n",
    "hidden_layer_logits = []\n",
    "softmax = nn.Softmax()\n",
    "len_t =  (len(x_evaluate_attacker_tensor)//batch_size)+1\n",
    "print(len_t)\n",
    "for ind in range(len_t):\n",
    "    # measure data loading time\n",
    "    inputs = x_evaluate_attacker_tensor[ind*batch_size:(ind+1)*batch_size]\n",
    "    targets = y_evaluate_attacker_tensor[ind*batch_size:(ind+1)*batch_size]\n",
    "    if use_cuda:\n",
    "        inputs, targets = inputs.cuda(), targets.cuda()\n",
    "    inputs, targets = torch.autograd.Variable(inputs), torch.autograd.Variable(targets)\n",
    "    \n",
    "    # compute output\n",
    "    outputs,_,_,_,hidden_layer_outputs = net(inputs)\n",
    "    outputs_value = outputs.data.cpu().numpy()\n",
    "    hidden_layer_outputs_value = hidden_layer_outputs.data.cpu().numpy()\n",
    "#     loss = criterion(outputs, targets)\n",
    "    prob_outputs = softmax(outputs)\n",
    "    prob_outputs_value = prob_outputs.data.cpu().numpy()\n",
    "    for i in range(len(prob_outputs_value)):\n",
    "        f_evaluate_logits.append(outputs_value[i])\n",
    "        f_evaluate_prob.append(prob_outputs_value[i])\n",
    "        hidden_layer_logits.append(hidden_layer_outputs_value[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "f_evaluate_logits_array = np.asarray(f_evaluate_logits)\n",
    "f_evaluate_prob_array = np.asarray(f_evaluate_prob)\n",
    "hidden_layer_logits_array = np.asarray(hidden_layer_logits)\n",
    "print(f_evaluate_logits_array.shape, f_evaluate_prob_array.shape)\n",
    "\n",
    "sort_f_evaluate=np.sort(f_evaluate_prob_array,axis=1)\n",
    "sort_f_evaluate_logits=np.sort(f_evaluate_logits_array,axis=1)\n",
    "sort_hidden_layer_logits = np.sort(hidden_layer_logits_array, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "x_evaluate_attacker_tensor = torch.from_numpy(test_data_c).type(torch.FloatTensor)\n",
    "y_evaluate_attacker_tensor = torch.from_numpy(test_label_c).type(torch.LongTensor)\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "net.eval()\n",
    "\n",
    "test_prob = []\n",
    "test_logits = []\n",
    "test_hidden_layer_logits = []\n",
    "softmax = nn.Softmax()\n",
    "len_t =  (len(x_evaluate_attacker_tensor)//batch_size)+1\n",
    "print(len_t)\n",
    "for ind in range(len_t):\n",
    "    # measure data loading time\n",
    "    inputs = x_evaluate_attacker_tensor[ind*batch_size:(ind+1)*batch_size]\n",
    "    targets = y_evaluate_attacker_tensor[ind*batch_size:(ind+1)*batch_size]\n",
    "    if use_cuda:\n",
    "        inputs, targets = inputs.cuda(), targets.cuda()\n",
    "    inputs, targets = torch.autograd.Variable(inputs), torch.autograd.Variable(targets)\n",
    "    \n",
    "    # compute output\n",
    "    outputs,_,_,_,hidden_layer_outputs = net(inputs)\n",
    "    outputs_value = outputs.data.cpu().numpy()\n",
    "    hidden_layer_outputs_value = hidden_layer_outputs.data.cpu().numpy()\n",
    "#     loss = criterion(outputs, targets)\n",
    "    prob_outputs = softmax(outputs)\n",
    "    prob_outputs_value = prob_outputs.data.cpu().numpy()\n",
    "    for i in range(len(prob_outputs_value)):\n",
    "        test_logits.append(outputs_value[i])\n",
    "        test_prob.append(prob_outputs_value[i])\n",
    "        test_hidden_layer_logits.append(hidden_layer_outputs_value[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "test_prob_array = np.asarray(test_prob)\n",
    "test_logits_array = np.asarray(test_logits)\n",
    "test_hidden_layer_logits_array = np.asarray(test_hidden_layer_logits)\n",
    "print(test_prob_array.shape, test_hidden_layer_logits_array.shape)\n",
    "\n",
    "sort_test_prob=np.sort(test_prob_array,axis=1)\n",
    "sort_test_logits=np.sort(test_logits_array,axis=1)\n",
    "sort_test_hidden_layer_logits = np.sort(test_hidden_layer_logits_array, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "len(f_evaluate_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "test_sum = np.sum(test_logits_array,1)#.shape\n",
    "train_sum = np.sum(f_evaluate_logits_array,1) #.shape\n",
    "print(np.mean(test_sum), np.mean(train_sum))\n",
    "\n",
    "print(np.ptp(test_sum), np.ptp(train_sum))\n",
    "train_sum.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "test_mean = np.mean(test_logits_array,0)#.shape\n",
    "train_mean = np.mean(f_evaluate_logits_array,0)#.shape\n",
    "train_mean.shape\n",
    "\n",
    "# fig = plt.figure(figsize=(30,20))\n",
    "x = np.arange(100)\n",
    "plt.plot(x,train_mean, label='train_mean')\n",
    "plt.plot(x,test_mean, label='test_mean')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "test_mean = np.mean(test_prob_array,0)#.shape\n",
    "train_mean = np.mean(f_evaluate_prob_array,0)#.shape\n",
    "train_mean.shape\n",
    "\n",
    "# fig = plt.figure(figsize=(30,20))\n",
    "x = np.arange(100)\n",
    "plt.plot(x,train_mean, label='train_mean')\n",
    "plt.plot(x,test_mean, label='test_mean')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "test_sum = np.sum(test_hidden_layer_logits_array,1)#.shape\n",
    "train_sum = np.sum(hidden_layer_logits_array,1) #.shape\n",
    "print(np.mean(test_sum), np.mean(train_sum))\n",
    "print(np.ptp(test_sum), np.ptp(train_sum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "test_mean = np.mean(test_hidden_layer_logits_array,0)#.shape\n",
    "train_mean = np.mean(hidden_layer_logits_array,0)#.shape\n",
    "train_mean \n",
    "\n",
    "fig = plt.figure(figsize=(30,20))\n",
    "x = np.arange(128)\n",
    "plt.plot(x,train_mean)\n",
    "plt.plot(x,test_mean)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(30,20))\n",
    "x = np.arange(len(train_sum))\n",
    "plt.plot(x,train_sum)\n",
    "plt.plot(x,test_sum[:len(train_sum)])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "test_hidden_layer_logits_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "test_sum\n",
    "np.sum(test_hidden_layer_logits_array[2])\n",
    "\n",
    "x = np.arange(128)\n",
    "plt.plot(x,test_hidden_layer_logits_array[2])\n",
    "plt.plot(x,np.sort(test_hidden_layer_logits_array[2]))\n",
    "\n",
    "np.sum(test_hidden_layer_logits_array[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from matplotlib import pyplot\n",
    "from matplotlib.pylab import plt\n",
    "# pyplot.plot(predict_origin)\n",
    "# pyplot.plot(f_evaluate_origin[3])\n",
    "# pyplot.plot(f_evaluate_origin[4])\n",
    "# plt.plot(f_evaluate_origin[0])\n",
    "# plt.plot(f_evaluate_origin[1])\n",
    "# plt.plot(f_evaluate_origin[2])\n",
    "for i in range(100):\n",
    "#     plt.plot(f_evaluate_origin[i])\n",
    "    plt.plot(f_evaluate_logits[i])\n",
    "#     plt.plot(result_array[i])\n",
    "#     plt.plot(sort_result_array[i])\n",
    "# for i in range(f_evaluate_origin.shape[0]):\n",
    "#     pyplot.plot(f_evaluate_origin[i])\n",
    "    \n",
    "# plt.ylim(0, 0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for i in range(len(f_evaluate_prob)):\n",
    "    plt.plot(hidden_layer_logits[i])\n",
    "    \n",
    "# plt.ylim(0, 0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for i in range(len(f_evaluate_prob)):\n",
    "    plt.plot(sort_hidden_layer_logits[i])\n",
    "    \n",
    "# plt.ylim(0, 0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for i in range(len(sort_test_hidden_layer_logits)):\n",
    "    plt.plot(sort_test_hidden_layer_logits[i])\n",
    "    \n",
    "# plt.ylim(0, 0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "fig = plt.figure(figsize=(30,20))\n",
    "for i in range(len(f_evaluate_prob)):\n",
    "    plt.plot(sort_f_evaluate[i])\n",
    "    \n",
    "# plt.ylim(0, 0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "fig = plt.figure(figsize=(30,20))\n",
    "for i in range(10000):\n",
    "    plt.plot(sort_test_prob[i])\n",
    "    \n",
    "# plt.ylim(0, 0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for i in range(len(f_evaluate_prob)):\n",
    "    plt.plot(sort_f_evaluate_logits[i])\n",
    "    \n",
    "# plt.ylim(0, 0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for i in range(len(sort_test_hidden_layer_logits)):\n",
    "    plt.plot(sort_test_logits[i])\n",
    "    \n",
    "# plt.ylim(0, 0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "fig = plt.figure(figsize=(30,20))\n",
    "for i in range(len(f_evaluate_prob_array)):\n",
    "    plt.plot(f_evaluate_prob_array[i])\n",
    "    \n",
    "# plt.ylim(0, 0.7)\n",
    "plt.show()\n",
    "\n",
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "fig = plt.figure(figsize=(30,20))\n",
    "for i in range(10000):\n",
    "    plt.plot(test_prob_array[i])\n",
    "    \n",
    "# plt.ylim(0, 0.7)\n",
    "plt.show()\n",
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# load membership inference attack\n",
    "\n",
    "# r= np.arange(len(small_train_classifier_data))\n",
    "# # np.random.shuffle(r)\n",
    "\n",
    "# train_classifier_data_tr_attack = small_train_classifier_data[r[:int(0.5*len(r))]]\n",
    "# train_classifier_label_tr_attack = small_train_classifier_label[r[:int(0.5*len(r))]]\n",
    "\n",
    "# train_classifier_data_te_attack = small_train_classifier_data[r[int(0.5*len(r)):]]\n",
    "# train_classifier_label_te_attack = small_train_classifier_label[r[int(0.5*len(r)):]]\n",
    "\n",
    "r= np.arange(len(train_classifier_data))\n",
    "np.random.shuffle(r)\n",
    "\n",
    "train_classifier_data_tr_attack = train_classifier_data[r[:int(0.5*len(r))]]\n",
    "train_classifier_label_tr_attack = train_classifier_label[r[:int(0.5*len(r))]]\n",
    "\n",
    "train_classifier_data_te_attack = train_classifier_data[r[int(0.5*len(r)):]]\n",
    "train_classifier_label_te_attack = train_classifier_label[r[int(0.5*len(r)):]]\n",
    "\n",
    "len(train_classifier_data_te_attack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "attack_model = InferenceAttack_HZ(100)\n",
    "attack_model = torch.nn.DataParallel(attack_model).cuda()\n",
    "attack_criterion = nn.MSELoss()\n",
    "attack_optimizer = optim.Adam(attack_model.parameters(),lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_defense='./checkpoints_texas/Texas_softmax_NSH_attack_best'\n",
    "print('==> Resuming from checkpoint..')\n",
    "assert os.path.isfile(resume), 'Error: no checkpoint directory found!'\n",
    "checkpoint_defense = os.path.dirname(resume_defense)\n",
    "checkpoint_defense = torch.load(resume_defense)\n",
    "attack_model.load_state_dict(checkpoint_defense['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r= np.arange(len(train_classifier_data_te_attack))\n",
    "np.random.shuffle(r)\n",
    "train_classifier_data_te_attack = train_classifier_data_te_attack[r]\n",
    "train_classifier_label_te_attack = train_classifier_label_te_attack[r]\n",
    "test_data_attack = test_data[r]\n",
    "test_label_attack = test_label[r]\n",
    "train_classifier_data_te_attack_tensor = torch.from_numpy(train_classifier_data_te_attack).type(torch.FloatTensor)\n",
    "train_classifier_label_te_attack_tensor = torch.from_numpy(train_classifier_label_te_attack).type(torch.LongTensor)\n",
    "test_data_tensor = torch.from_numpy(test_data_attack).type(torch.FloatTensor)\n",
    "test_label_tensor = torch.from_numpy(test_label_attack).type(torch.LongTensor)\n",
    "test_loss, test_acc, sum_correct = test_attack_softmax(train_classifier_data_te_attack_tensor,train_classifier_label_te_attack_tensor\n",
    "                                     ,test_data_tensor,test_label_tensor,net,attack_model,criterion,attack_criterion,optimizer,attack_optimizer,epoch,use_cuda)\n",
    "print ('test acc', test_acc, 'test_loss: ',test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# train_attack_data = train_attack_data\n",
    "\n",
    "# train_attack_label = train_attack_label\n",
    "\n",
    "# test_data = test_data\n",
    "# test_label = test_label\n",
    "\n",
    "print('train_attack_data: ', len(train_attack_data), '  test_data: ',len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "train_classifier_data_te_attack.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "test_loss, final_test_acc = test(torch.from_numpy(train_classifier_data_tr_attack).type(torch.FloatTensor) ,torch.from_numpy(train_classifier_label_tr_attack).type(torch.LongTensor), net, criterion, epoch, use_cuda)\n",
    "\n",
    "print ('test_loss: {test_loss: .4f}, test_acc: {test_acc: .4f}'.format(test_loss=test_loss, test_acc=final_test_acc))\n",
    "\n",
    "test_loss, final_test_acc = test(torch.from_numpy(train_classifier_data_te_attack).type(torch.FloatTensor) ,torch.from_numpy(train_classifier_label_te_attack).type(torch.LongTensor), net, criterion, epoch, use_cuda)\n",
    "\n",
    "print ('test_loss: {test_loss: .4f}, test_acc: {test_acc: .4f}'.format(test_loss=test_loss, test_acc=final_test_acc))\n",
    "\n",
    "test_loss, final_test_acc = test(torch.from_numpy(train_attack_data).type(torch.FloatTensor) ,torch.from_numpy(train_attack_label).type(torch.LongTensor), net, criterion, epoch, use_cuda)\n",
    "\n",
    "print ('test_loss: {test_loss: .4f}, test_acc: {test_acc: .4f}'.format(test_loss=test_loss, test_acc=final_test_acc))\n",
    "\n",
    "test_loss, final_test_acc = test(torch.from_numpy(test_data).type(torch.FloatTensor) ,torch.from_numpy(test_label).type(torch.LongTensor), net, criterion, epoch, use_cuda)\n",
    "\n",
    "print ('test_loss: {test_loss: .4f}, test_acc: {test_acc: .4f}'.format(test_loss=test_loss, test_acc=final_test_acc))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "best_acc= 0.0\n",
    "batch_size=128\n",
    "epochs = 200\n",
    "for epoch in range(0, epochs):\n",
    "#     adjust_learning_rate_attack(attack_optimizer, epoch)\n",
    "    \n",
    "    r= np.arange(len(train_classifier_data_tr_attack))\n",
    "    np.random.shuffle(r)\n",
    "    r1= np.arange(len(train_attack_data))\n",
    "    np.random.shuffle(r1)\n",
    "    r2 = r1[r]\n",
    "\n",
    "    train_classifier_data_tr_attack = train_classifier_data_tr_attack[r]\n",
    "    train_classifier_label_tr_attack = train_classifier_label_tr_attack[r]\n",
    "\n",
    "    tr_attack_data = train_attack_data[r2]\n",
    "    tr_attack_label = train_attack_label[r2]\n",
    "\n",
    "\n",
    "    r= np.arange(len(train_classifier_data_te_attack))\n",
    "    np.random.shuffle(r)\n",
    "#     r1= np.arange(len(test_data)*0.5)\n",
    "#     np.random.shuffle(r1)\n",
    "\n",
    "\n",
    "    train_classifier_data_te_attack = train_classifier_data_te_attack[r]\n",
    "    train_classifier_label_te_attack = train_classifier_label_te_attack[r]\n",
    "\n",
    "    test_data_attack = test_data[r]\n",
    "    test_label_attack = test_label[r]\n",
    "    \n",
    "    train_classifier_data_tr_attack_tensor = torch.from_numpy(train_classifier_data_tr_attack).type(torch.FloatTensor)\n",
    "    train_classifier_label_tr_attack_tensor = torch.from_numpy(train_classifier_label_tr_attack).type(torch.LongTensor)\n",
    "\n",
    "    train_classifier_data_te_attack_tensor = torch.from_numpy(train_classifier_data_te_attack).type(torch.FloatTensor)\n",
    "    train_classifier_label_te_attack_tensor = torch.from_numpy(train_classifier_label_te_attack).type(torch.LongTensor)\n",
    "\n",
    "\n",
    "#     r= np.arange(len(train_attack_data))\n",
    "#     np.random.shuffle(r)\n",
    "\n",
    "#     train_attack_data = train_attack_data[r]\n",
    "#     train_attack_label = train_attack_label[r]\n",
    "\n",
    "    train_attack_data_tensor = torch.from_numpy(tr_attack_data).type(torch.FloatTensor)\n",
    "    train_attack_label_tensor = torch.from_numpy(tr_attack_label).type(torch.LongTensor)\n",
    "\n",
    "    test_data_tensor = torch.from_numpy(test_data_attack).type(torch.FloatTensor)\n",
    "    test_label_tensor = torch.from_numpy(test_label_attack).type(torch.LongTensor)\n",
    "    print('\\nEpoch: [%d | %d] , lr : 0.0001'% (epoch + 1, epochs))\n",
    "\n",
    "\n",
    "    train_loss, train_acc = train_attack_softmax(train_classifier_data_tr_attack_tensor,train_classifier_label_tr_attack_tensor\n",
    "                                         ,train_attack_data_tensor,train_attack_label_tensor,net,attack_model,criterion,attack_criterion,optimizer,attack_optimizer,epoch,use_cuda)\n",
    "\n",
    "    print ('train acc',train_acc)\n",
    "    test_loss, test_acc, sum_correct = test_attack_softmax(train_classifier_data_te_attack_tensor,train_classifier_label_te_attack_tensor\n",
    "                                         ,test_data_tensor,test_label_tensor,net,attack_model,criterion,attack_criterion,optimizer,attack_optimizer,epoch,use_cuda)\n",
    "\n",
    "    is_best = test_acc>best_acc or (1-test_acc)>best_acc\n",
    "    \n",
    "    best_acc = max(test_acc, best_acc)\n",
    "    best_acc = max((1-test_acc), best_acc)\n",
    "    if is_best or epoch+1 == epochs:\n",
    "        save_checkpoint({\n",
    "                    'epoch': epoch + 1,\n",
    "                    'state_dict': attack_model.state_dict(),\n",
    "                    'acc': test_acc,\n",
    "                    'best_acc': best_acc,\n",
    "                    'optimizer' : attack_optimizer.state_dict(),\n",
    "                }, False, filename='Texas_softmax_NSH_attack_best')\n",
    "    \n",
    "    print ('test acc',test_acc,best_acc)\n",
    "\n",
    "print('Best classification acc:%.4f'%(final_test_acc))\n",
    "print('Best attack acc:%.4f'%(best_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Texas_5layer_balance_output_partition_alpha500_min_var_beta3000_epoch_90\n",
    "\n",
    "best_acc= 0.0\n",
    "batch_size=128\n",
    "epochs = 200\n",
    "for epoch in range(0, epochs):\n",
    "#     adjust_learning_rate_attack(attack_optimizer, epoch)\n",
    "    \n",
    "    r= np.arange(len(train_classifier_data_tr_attack))\n",
    "    np.random.shuffle(r)\n",
    "    r1= np.arange(len(train_attack_data))\n",
    "    np.random.shuffle(r1)\n",
    "    r2 = r1[r]\n",
    "\n",
    "    train_classifier_data_tr_attack = train_classifier_data_tr_attack[r]\n",
    "    train_classifier_label_tr_attack = train_classifier_label_tr_attack[r]\n",
    "\n",
    "    tr_attack_data = train_attack_data[r2]\n",
    "    tr_attack_label = train_attack_label[r2]\n",
    "\n",
    "\n",
    "    r= np.arange(len(train_classifier_data_te_attack))\n",
    "    np.random.shuffle(r)\n",
    "#     r1= np.arange(len(test_data)*0.5)\n",
    "#     np.random.shuffle(r1)\n",
    "\n",
    "\n",
    "    train_classifier_data_te_attack = train_classifier_data_te_attack[r]\n",
    "    train_classifier_label_te_attack = train_classifier_label_te_attack[r]\n",
    "\n",
    "    test_data_attack = test_data[r]\n",
    "    test_label_attack = test_label[r]\n",
    "    \n",
    "    train_classifier_data_tr_attack_tensor = torch.from_numpy(train_classifier_data_tr_attack).type(torch.FloatTensor)\n",
    "    train_classifier_label_tr_attack_tensor = torch.from_numpy(train_classifier_label_tr_attack).type(torch.LongTensor)\n",
    "\n",
    "    train_classifier_data_te_attack_tensor = torch.from_numpy(train_classifier_data_te_attack).type(torch.FloatTensor)\n",
    "    train_classifier_label_te_attack_tensor = torch.from_numpy(train_classifier_label_te_attack).type(torch.LongTensor)\n",
    "\n",
    "\n",
    "#     r= np.arange(len(train_attack_data))\n",
    "#     np.random.shuffle(r)\n",
    "\n",
    "#     train_attack_data = train_attack_data[r]\n",
    "#     train_attack_label = train_attack_label[r]\n",
    "\n",
    "    train_attack_data_tensor = torch.from_numpy(tr_attack_data).type(torch.FloatTensor)\n",
    "    train_attack_label_tensor = torch.from_numpy(tr_attack_label).type(torch.LongTensor)\n",
    "\n",
    "    test_data_tensor = torch.from_numpy(test_data_attack).type(torch.FloatTensor)\n",
    "    test_label_tensor = torch.from_numpy(test_label_attack).type(torch.LongTensor)\n",
    "    print('\\nEpoch: [%d | %d] , lr : 0.0001'% (epoch + 1, epochs))\n",
    "\n",
    "\n",
    "    train_loss, train_acc = train_attack_softmax(train_classifier_data_tr_attack_tensor,train_classifier_label_tr_attack_tensor\n",
    "                                         ,train_attack_data_tensor,train_attack_label_tensor,net,attack_model,criterion,attack_criterion,optimizer,attack_optimizer,epoch,use_cuda)\n",
    "\n",
    "    print ('train acc',train_acc)\n",
    "    test_loss, test_acc, sum_correct = test_attack_softmax(train_classifier_data_te_attack_tensor,train_classifier_label_te_attack_tensor\n",
    "                                         ,test_data_tensor,test_label_tensor,net,attack_model,criterion,attack_criterion,optimizer,attack_optimizer,epoch,use_cuda)\n",
    "\n",
    "    is_best = test_acc>best_acc or (1-test_acc)>best_acc\n",
    "    \n",
    "    best_acc = max(test_acc, best_acc)\n",
    "    best_acc = max((1-test_acc), best_acc)\n",
    "    if is_best or epoch+1 == epochs:\n",
    "        save_checkpoint({\n",
    "                    'epoch': epoch + 1,\n",
    "                    'state_dict': attack_model.state_dict(),\n",
    "                    'acc': test_acc,\n",
    "                    'best_acc': best_acc,\n",
    "                    'optimizer' : attack_optimizer.state_dict(),\n",
    "                }, False, filename='Texas_5layer_balance_output_partition_alpha500_min_var_beta3000_epoch_90_softmax_NSH_attack_best')\n",
    "    \n",
    "    print ('test acc',test_acc,best_acc)\n",
    "\n",
    "print('Best classification acc:%.4f'%(final_test_acc))\n",
    "print('Best attack acc:%.4f'%(best_acc))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_learning_rate_attack(optimizer, epoch):\n",
    "    global state\n",
    "    if epoch in [40, 90]:\n",
    "#     if (epoch+1)%100 == 0:\n",
    "        state['lr'] *= 0.1 \n",
    "#         state['lr'] *= 1\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = state['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  NN attack model\n",
    "defense_model = Defense_Model(100)\n",
    "defense_model = torch.nn.DataParallel(defense_model).cuda()\n",
    "defense_criterion = nn.MSELoss()\n",
    "# defense_criterion = nn.CrossEntropyLoss()\n",
    "at_lr = 0.001\n",
    "state={}\n",
    "state['lr']=at_lr\n",
    "defense_optimizer = optim.Adam(defense_model.parameters(),lr=at_lr)\n",
    "defense_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_defense='./checkpoints_texas/Texas_softmax_sort_NN_best'\n",
    "print('==> Resuming from checkpoint..')\n",
    "assert os.path.isfile(resume), 'Error: no checkpoint directory found!'\n",
    "checkpoint_defense = os.path.dirname(resume_defense)\n",
    "checkpoint_defense = torch.load(resume_defense)\n",
    "defense_model.load_state_dict(checkpoint_defense['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r= np.arange(len(train_classifier_data_te_attack))\n",
    "np.random.shuffle(r)\n",
    "#     r1= np.arange(len(test_data)*0.5)\n",
    "#     np.random.shuffle(r1)\n",
    "\n",
    "\n",
    "train_classifier_data_te_attack = train_classifier_data_te_attack[r]\n",
    "train_classifier_label_te_attack = train_classifier_label_te_attack[r]\n",
    "\n",
    "test_data_attack = test_data[r]\n",
    "test_label_attack = test_label[r]\n",
    "train_classifier_data_te_attack_tensor = torch.from_numpy(train_classifier_data_te_attack).type(torch.FloatTensor)\n",
    "train_classifier_label_te_attack_tensor = torch.from_numpy(train_classifier_label_te_attack).type(torch.LongTensor)\n",
    "\n",
    "test_data_tensor = torch.from_numpy(test_data_attack).type(torch.FloatTensor)\n",
    "test_label_tensor = torch.from_numpy(test_label_attack).type(torch.LongTensor)\n",
    "test_loss, test_acc, sum_correct = test_defense_softmax(train_classifier_data_te_attack_tensor,train_classifier_label_te_attack_tensor\n",
    "                                     ,test_data_tensor,test_label_tensor,net,defense_model,criterion,defense_criterion,optimizer,defense_optimizer,epoch,use_cuda)\n",
    "\n",
    "\n",
    "print ('test acc', test_acc, 'test_loss: ',test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# \n",
    "\n",
    "best_acc= 0.0\n",
    "batch_size=128\n",
    "epochs = 100\n",
    "for epoch in range(0, epochs):\n",
    "    adjust_learning_rate_attack(defense_optimizer, epoch)\n",
    "    \n",
    "    r= np.arange(len(train_classifier_data_tr_attack))\n",
    "    np.random.shuffle(r)\n",
    "    r1= np.arange(len(train_attack_data))\n",
    "    np.random.shuffle(r1)\n",
    "    r2 = r1[r]\n",
    "\n",
    "    train_classifier_data_tr_attack = train_classifier_data_tr_attack[r]\n",
    "    train_classifier_label_tr_attack = train_classifier_label_tr_attack[r]\n",
    "\n",
    "    tr_attack_data = train_attack_data[r2]\n",
    "    tr_attack_label = train_attack_label[r2]\n",
    "\n",
    "\n",
    "    r= np.arange(len(train_classifier_data_te_attack))\n",
    "    np.random.shuffle(r)\n",
    "#     r1= np.arange(len(test_data)*0.5)\n",
    "#     np.random.shuffle(r1)\n",
    "\n",
    "\n",
    "    train_classifier_data_te_attack = train_classifier_data_te_attack[r]\n",
    "    train_classifier_label_te_attack = train_classifier_label_te_attack[r]\n",
    "\n",
    "    test_data_attack = test_data[r]\n",
    "    test_label_attack = test_label[r]\n",
    "\n",
    "    \n",
    "    train_classifier_data_tr_attack_tensor = torch.from_numpy(train_classifier_data_tr_attack).type(torch.FloatTensor)\n",
    "    train_classifier_label_tr_attack_tensor = torch.from_numpy(train_classifier_label_tr_attack).type(torch.LongTensor)\n",
    "\n",
    "    train_classifier_data_te_attack_tensor = torch.from_numpy(train_classifier_data_te_attack).type(torch.FloatTensor)\n",
    "    train_classifier_label_te_attack_tensor = torch.from_numpy(train_classifier_label_te_attack).type(torch.LongTensor)\n",
    "\n",
    "\n",
    "#     r= np.arange(len(train_attack_data))\n",
    "#     np.random.shuffle(r)\n",
    "\n",
    "#     train_attack_data = train_attack_data[r]\n",
    "#     train_attack_label = train_attack_label[r]\n",
    "\n",
    "    train_attack_data_tensor = torch.from_numpy(tr_attack_data).type(torch.FloatTensor)\n",
    "    train_attack_label_tensor = torch.from_numpy(tr_attack_label).type(torch.LongTensor)\n",
    "\n",
    "    test_data_tensor = torch.from_numpy(test_data_attack).type(torch.FloatTensor)\n",
    "    test_label_tensor = torch.from_numpy(test_label_attack).type(torch.LongTensor)\n",
    "    print('\\nEpoch: [%d | %d] , lr : %f'% (epoch + 1, epochs, state['lr']))\n",
    "\n",
    "\n",
    "    train_loss, train_acc = train_defense_softmax(train_classifier_data_tr_attack_tensor,train_classifier_label_tr_attack_tensor\n",
    "                                         ,train_attack_data_tensor,train_attack_label_tensor,net,defense_model,criterion,defense_criterion,optimizer,defense_optimizer,epoch,use_cuda)\n",
    "\n",
    "    print ('train acc',train_acc)\n",
    "    test_loss, test_acc, sum_correct = test_defense_softmax(train_classifier_data_te_attack_tensor,train_classifier_label_te_attack_tensor\n",
    "                                         ,test_data_tensor,test_label_tensor,net,defense_model,criterion,defense_criterion,optimizer,defense_optimizer,epoch,use_cuda)\n",
    "\n",
    "    is_best = test_acc>best_acc or (1-test_acc)>best_acc\n",
    "    \n",
    "    best_acc = max(test_acc, best_acc)\n",
    "    best_acc = max((1-test_acc), best_acc)\n",
    "    if is_best or epoch+1 == epochs:\n",
    "        save_checkpoint({\n",
    "                    'epoch': epoch + 1,\n",
    "                    'state_dict': defense_model.state_dict(),                                       \n",
    "                    'acc': test_acc,\n",
    "                    'best_acc': best_acc,\n",
    "                    'optimizer' : defense_optimizer.state_dict(),\n",
    "                }, False, filename='Texas_softmax_sort_NN_best')\n",
    "    \n",
    "    print ('test acc',test_acc,best_acc)\n",
    "\n",
    "print('Best classification acc:%.4f'%(final_test_acc))\n",
    "print('Best attack acc:%.4f'%(best_acc))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class10_500_testset_te_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# memg uard implementation\n",
    "\n",
    "# evaluate_train_data = X[5000:10000]\n",
    "# evaluate_test_data = X[40000:45000]\n",
    "# evaluate_train_label = Y[5000:10000]\n",
    "# evaluate_test_label = Y[40000:45000]\n",
    "\n",
    "# evaluate_train_data = X[10000:20000]\n",
    "# evaluate_test_data = X[40000:50000]\n",
    "# evaluate_train_label = Y[10000:20000]\n",
    "# evaluate_test_label = Y[40000:50000]\n",
    "\n",
    "evaluate_train_data = class10_train_classifier_data[3500:]\n",
    "evaluate_train_label = class10_train_classifier_label[3500:]\n",
    "\n",
    "evaluate_test_data = class10_test_data[:3500]\n",
    "evaluate_test_label = class10_test_label[:3500]\n",
    "\n",
    "# evaluate_train_data = train_classifier_data_te_attack\n",
    "# evaluate_train_label = train_classifier_label_te_attack\n",
    "\n",
    "# evaluate_test_data = class10_500_testset_te_data\n",
    "# evaluate_test_label = class10_500_testset_te_label\n",
    "\n",
    "\n",
    "x_evaluate_attacker=np.concatenate((evaluate_train_data,evaluate_test_data),axis=0)\n",
    "y_evaluate_attacker=np.concatenate((evaluate_train_label,evaluate_test_label),axis=0)\n",
    "\n",
    "label_evaluate_attacker=np.zeros([x_evaluate_attacker.shape[0]],dtype=np.int)\n",
    "label_evaluate_attacker[0:evaluate_train_data.shape[0]]=1\n",
    "\n",
    "x_evaluate_attacker_tensor = torch.from_numpy(x_evaluate_attacker).type(torch.FloatTensor)\n",
    "y_evaluate_attacker_tensor = torch.from_numpy(y_evaluate_attacker).type(torch.LongTensor)\n",
    "print(x_evaluate_attacker_tensor.shape, y_evaluate_attacker_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "net.eval()\n",
    "\n",
    "f_evaluate_logits = []\n",
    "f_evaluate_prob = []\n",
    "softmax = nn.Softmax()\n",
    "len_t =  (len(x_evaluate_attacker_tensor)//batch_size)+1\n",
    "print(len_t)\n",
    "for ind in range(len_t):\n",
    "    # measure data loading time\n",
    "    inputs = x_evaluate_attacker_tensor[ind*batch_size:(ind+1)*batch_size]\n",
    "    targets = y_evaluate_attacker_tensor[ind*batch_size:(ind+1)*batch_size]\n",
    "    if use_cuda:\n",
    "        inputs, targets = inputs.cuda(), targets.cuda()\n",
    "    inputs, targets = torch.autograd.Variable(inputs), torch.autograd.Variable(targets)\n",
    "    \n",
    "    # compute output\n",
    "    outputs,_ = net(inputs)\n",
    "    outputs_value = outputs.data.cpu().numpy()\n",
    "#     loss = criterion(outputs, targets)\n",
    "    prob_outputs = softmax(outputs)\n",
    "    prob_outputs_value = prob_outputs.data.cpu().numpy()\n",
    "    for i in range(len(prob_outputs_value)):\n",
    "        f_evaluate_logits.append(outputs_value[i])\n",
    "        f_evaluate_prob.append(prob_outputs_value[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "f_evaluate_logits_array = np.asarray(f_evaluate_logits)\n",
    "f_evaluate_prob_array = np.asarray(f_evaluate_prob)\n",
    "print(f_evaluate_logits_array.shape, f_evaluate_prob_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "f_evaluate_origin=np.copy(f_evaluate_prob_array)  #keep a copy of original one\n",
    "f_evaluate_logits_origin=np.copy(f_evaluate_logits_array)\n",
    "#############as we sort the prediction sscores, back_index is used to get back original scores#############\n",
    "sort_index=np.argsort(f_evaluate_prob_array,axis=1)\n",
    "back_index=np.copy(sort_index)\n",
    "for i in np.arange(back_index.shape[0]):\n",
    "    back_index[i,sort_index[i,:]]=np.arange(back_index.shape[1])\n",
    "\n",
    "# sort the output for attack model\n",
    "f_evaluate=np.sort(f_evaluate_prob_array,axis=1)\n",
    "f_evaluate_logits=np.sort(f_evaluate_logits_array,axis=1)\n",
    "\n",
    "# f_evaluate=f_evaluate_prob_array\n",
    "# f_evaluate_logits=f_evaluate_logits_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print(\"f evaluate shape: {}\".format(f_evaluate.shape))\n",
    "print(\"f evaluate logits shape: {}\".format(f_evaluate_logits.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "input_shape=f_evaluate.shape[1:]\n",
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "defense_model = Defense_Model(10)\n",
    "defense_model = torch.nn.DataParallel(defense_model).cuda()\n",
    "defense_criterion = nn.MSELoss()\n",
    "# defense_criterion = nn.CrossEntropyLoss()\n",
    "at_lr = 0.0001\n",
    "state={}\n",
    "state['lr']=at_lr\n",
    "defense_optimizer = optim.Adam(defense_model.parameters(),lr=at_lr)\n",
    "defense_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "resume_defense='./checkpoints_texas_10class_little_model_defense/Class10_1layer_No_defenss_200_epoch_200_softmax_defensemodel_epoch77'\n",
    "# resume_defense='./checkpoints_texas_prune_little_model_defense/Modify2_var_max_alpha1_beta3_defense_epoch_5_softmax_defensemodel_epoch28'\n",
    "print('==> Resuming attack model from checkpoint..')\n",
    "assert os.path.isfile(resume_defense), 'Error: no checkpoint directory found!'\n",
    "checkpoint_defense = os.path.dirname(resume_defense)\n",
    "checkpoint_defense = torch.load(resume_defense)\n",
    "defense_model.load_state_dict(checkpoint_defense['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "########evaluate the performance of defense's attack model on undefended data#######\n",
    "\n",
    "defense_model.eval()\n",
    "\n",
    "# softmax = nn.Softmax()\n",
    "\n",
    "losses = AverageMeter()\n",
    "top1 = AverageMeter()\n",
    "\n",
    "sum_correct = 0.0\n",
    "\n",
    "# f_evaluate_logits_tensor = torch.from_numpy(f_evaluate_logits).type(torch.FloatTensor)\n",
    "f_evaluate_tensor = torch.from_numpy(f_evaluate).type(torch.FloatTensor)\n",
    "\n",
    "att_labels = np.zeros(f_evaluate_tensor.size()[0])\n",
    "\n",
    "# att_labels = np.zeros(f_evaluate_prob_tensor.size()[0])\n",
    "# att_labels [:10000] =1.0\n",
    "# att_labels [10000:] =0.0\n",
    "att_labels [:len(evaluate_train_label)] =1.0\n",
    "att_labels [len(evaluate_train_label):] =0.0\n",
    "is_member_labels_tensor = torch.from_numpy(att_labels).type(torch.FloatTensor)\n",
    "    \n",
    "len_t =  (len(f_evaluate_tensor)//batch_size)+1\n",
    "print('len_t: ', len_t)\n",
    "\n",
    "list_attack_output = []\n",
    "for ind in range(len_t):\n",
    "    # measure data loading time\n",
    "    inputs = f_evaluate_tensor[ind*batch_size:(ind+1)*batch_size]\n",
    "#     targets = labels[ind*batch_size:(ind+1)*batch_size]\n",
    "\n",
    "    attack_output, attack_output_h = defense_model(inputs)\n",
    "#     .view([-1])\n",
    "#     break\n",
    "    is_member_labels = is_member_labels_tensor[ind*batch_size:(ind+1)*batch_size]\n",
    "    if use_cuda:\n",
    "        is_member_labels = is_member_labels.cuda()\n",
    "\n",
    "    v_is_member_labels = torch.autograd.Variable(is_member_labels)\n",
    "\n",
    "    loss = defense_criterion(attack_output, v_is_member_labels)\n",
    "\n",
    "    # measure accuracy and record loss\n",
    "    #prec1,p5 = accuracy(attack_output.data, v_is_member_labels.data, topk=(1,2))\n",
    "    list_attack_output.append(attack_output.data.cpu().numpy())\n",
    "    prec1=np.mean(np.equal((attack_output.data.cpu().numpy() >0.5),(v_is_member_labels.data.cpu().numpy()> 0.5)))\n",
    "    losses.update(loss.data, inputs.size()[0])\n",
    "    top1.update(prec1, inputs.size()[0])\n",
    "#     print('attack_output: ', attack_output.shape, 'v_is_member_labels: ', v_is_member_labels.shape)\n",
    "    correct = np.sum(np.equal((attack_output.data.cpu().numpy().reshape(-1) >0.5),(v_is_member_labels.data.cpu().numpy()> 0.5)))\n",
    "#     print(\"correct: \", correct)\n",
    "    sum_correct += correct\n",
    "#     break\n",
    "    # plot progress\n",
    "    if ind%100==0:\n",
    "        print  ('({batch}/{size}) | Loss: {loss:.4f} | top1: {top1: .4f} '.format(\n",
    "                batch=ind + 1,\n",
    "                size=len_t,\n",
    "                loss=losses.avg,\n",
    "                top1=top1.avg,\n",
    "                ))\n",
    "\n",
    "test_loss = losses.avg\n",
    "test_acc = top1.avg\n",
    "accurate_acc = sum_correct/len(f_evaluate)\n",
    "print ('evaluate loss: {test_loss: .4f}, evaluate accuracy: {test_acc: .4f}, accurate accuracy: {accurate_acc: .4f}, sum correct: {sum_correct: .1f}'.format(test_loss=test_loss, test_acc=test_acc, accurate_acc=accurate_acc,sum_correct=sum_correct))\n",
    "\n",
    "# (1/157) | Loss: 0.2280 | top1:  0.7109 \n",
    "# (101/157) | Loss: 0.2244 | top1:  0.6838 \n",
    "# evaluate loss:  0.2300, evaluate accuracy:  0.6151, accurate accuracy:  0.6155"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "evaluate_train_data\n",
    "evaluate_test_data\n",
    "evaluate_train_label\n",
    "evaluate_test_label\n",
    "evaluate_train_data_tensor = torch.from_numpy(evaluate_train_data).type(torch.FloatTensor)\n",
    "evaluate_train_label_tensor = torch.from_numpy(evaluate_train_label).type(torch.LongTensor)\n",
    "evaluate_test_data_tensor = torch.from_numpy(evaluate_test_data).type(torch.FloatTensor)\n",
    "evaluate_test_label_tensor = torch.from_numpy(evaluate_test_label).type(torch.LongTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "batch_size = 128\n",
    "attack_train_loss, attack_train_acc, attack_correct_sum = test_defense_softmax(evaluate_train_data_tensor,evaluate_train_label_tensor\n",
    "                                                                               ,evaluate_test_data_tensor,evaluate_test_label_tensor,\n",
    "                                                                               net,defense_model,criterion,defense_criterion,\n",
    "                                                                               optimizer,defense_optimizer,epoch,use_cuda)\n",
    "\n",
    "   \n",
    "\n",
    "print ('attack loss: {test_loss: .4f}, attack acc: {test_acc: .4f}, attack correct sum: {attack_correct_sum: .1f}'.format(test_loss=attack_train_loss, test_acc=attack_train_acc,attack_correct_sum=attack_correct_sum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "defense_model = InferenceAttack_HZ(10)\n",
    "defense_model = torch.nn.DataParallel(defense_model).cuda()\n",
    "defense_criterion = nn.MSELoss()\n",
    "at_lr = 0.0001\n",
    "state={}\n",
    "state['lr']=at_lr\n",
    "defense_optimizer = optim.Adam(defense_model.parameters(),lr=at_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "resume_defense='./checkpoints_texas_10class_little_model_defense/Class10_1layer_No_defenss_200_epoch_200_softmax_epoch73'\n",
    "print('==> Resuming attack model from checkpoint..')\n",
    "assert os.path.isfile(resume_defense), 'Error: no checkpoint directory found!'\n",
    "# checkpoint_defense = os.path.dirname(resume_defense)\n",
    "checkpoint_defense = torch.load(resume_defense)\n",
    "defense_model.load_state_dict(checkpoint_defense['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "batch_size = 128\n",
    "attack_train_loss, attack_train_acc, attack_correct_sum = test_attack_softmax(evaluate_train_data_tensor,evaluate_train_label_tensor\n",
    "                                         ,evaluate_test_data_tensor,evaluate_test_label_tensor,net,defense_model,criterion,defense_criterion,optimizer,defense_optimizer,epoch,use_cuda)\n",
    "\n",
    "print ('attack loss: {test_loss: .4f}, attack acc: {test_acc: .4f}, attack correct sum: {attack_correct_sum: .1f}'.format(test_loss=attack_train_loss, test_acc=attack_train_acc,attack_correct_sum=attack_correct_sum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "attack_train_loss, attack_train_acc, attack_correct_sum = test_attack_softmax_sort_mod(evaluate_train_data_tensor,evaluate_train_label_tensor\n",
    "                                         ,evaluate_test_data_tensor,evaluate_test_label_tensor,net,defense_model,criterion,defense_criterion,optimizer,defense_optimizer,epoch,use_cuda)\n",
    "\n",
    "print ('attack loss: {test_loss: .4f}, attack acc: {test_acc: .4f}, attack correct sum: {attack_correct_sum: .1f}'.format(test_loss=attack_train_loss, test_acc=attack_train_acc,attack_correct_sum=attack_correct_sum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "attack_output_h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "batch_size = 100\n",
    "defense_model.eval()\n",
    "\n",
    "# softmax = nn.Softmax()\n",
    "\n",
    "losses = AverageMeter()\n",
    "top1 = AverageMeter()\n",
    "\n",
    "sum_correct = 0.0\n",
    "\n",
    "# f_evaluate_logits_tensor = torch.from_numpy(result_array_logits).type(torch.FloatTensor)\n",
    "\n",
    "# f_evaluate=np.sort(result_array,axis=1)\n",
    "# f_evaluate_tensor = torch.from_numpy(f_evaluate).type(torch.FloatTensor)\n",
    "f_evaluate_tensor = torch.from_numpy(f_evaluate_origin).type(torch.FloatTensor)\n",
    "\n",
    "# comb_targets= torch.cat((check_test_trainset_label_tensor,check_test_label_tensor)).view([-1,1]).type(torch.cuda.FloatTensor)\n",
    "comb_targets = y_evaluate_attacker_tensor.cuda()\n",
    "att_labels = np.zeros(f_evaluate_tensor.size()[0])\n",
    "\n",
    "# att_labels = np.zeros(f_evaluate_prob_tensor.size()[0])\n",
    "att_labels [:len(evaluate_train_label)] =1.0\n",
    "att_labels [len(evaluate_train_label):] =0.0\n",
    "is_member_labels_tensor = torch.from_numpy(att_labels).type(torch.FloatTensor)\n",
    "    \n",
    "len_t =  (len(f_evaluate_tensor)//batch_size)+1\n",
    "print('len_t: ', len_t)\n",
    "\n",
    "# attack_criterion\n",
    "# attack_optimizer\n",
    "\n",
    "list_attack_output = []\n",
    "for ind in range(len_t):\n",
    "    # measure data loading time\n",
    "    inputs = f_evaluate_tensor[ind*batch_size:(ind+1)*batch_size]\n",
    "    targets = comb_targets[ind*batch_size:(ind+1)*batch_size]\n",
    "    \n",
    "    sort_inputs, indices= torch.sort(inputs)\n",
    "    \n",
    "    one_hot_tr = torch.from_numpy((np.zeros((inputs.size()[0],inputs.size(1))))).cuda().type(torch.cuda.FloatTensor)\n",
    "    target_one_hot_tr = one_hot_tr.scatter_(1, targets.type(torch.cuda.LongTensor).view([-1,1]).data,1)\n",
    "\n",
    "    for i in range(len(indices)):\n",
    "        target_one_hot_tr[i] = target_one_hot_tr[i][indices[i]]\n",
    "    \n",
    "    infer_input_one_hot = torch.autograd.Variable(target_one_hot_tr)\n",
    "    \n",
    "#     attack_output = attack_model(inputs,_,infer_input_one_hot).view([-1])\n",
    "\n",
    "    attack_output, _ = defense_model(sort_inputs,_,infer_input_one_hot)\n",
    "#     attack_output, _ = defense_model(inputs,_,infer_input_one_hot)\n",
    "    attack_output = attack_output.view([-1])\n",
    "#     .view([-1])\n",
    "#     break\n",
    "    is_member_labels = is_member_labels_tensor[ind*batch_size:(ind+1)*batch_size]\n",
    "    if use_cuda:\n",
    "        is_member_labels = is_member_labels.cuda()\n",
    "\n",
    "    v_is_member_labels = torch.autograd.Variable(is_member_labels)\n",
    "\n",
    "    loss = defense_criterion(attack_output, v_is_member_labels)\n",
    "\n",
    "    # measure accuracy and record loss\n",
    "    #prec1,p5 = accuracy(attack_output.data, v_is_member_labels.data, topk=(1,2))\n",
    "    list_attack_output.append(attack_output.data.cpu().numpy())\n",
    "    prec1=np.mean(np.equal((attack_output.data.cpu().numpy() >0.5),(v_is_member_labels.data.cpu().numpy()> 0.5)))\n",
    "    losses.update(loss.data, inputs.size()[0])\n",
    "    top1.update(prec1, inputs.size()[0])\n",
    "#     print('attack_output: ', attack_output.shape, 'v_is_member_labels: ', v_is_member_labels.shape)\n",
    "    correct = np.sum(np.equal((attack_output.data.cpu().numpy().reshape(-1) >0.5),(v_is_member_labels.data.cpu().numpy()> 0.5)))\n",
    "#     print(\"correct: \", correct)\n",
    "    sum_correct += correct\n",
    "#     break\n",
    "    # plot progress\n",
    "    if ind%100==0:\n",
    "        print  ('({batch}/{size}) | Loss: {loss:.4f} | top1: {top1: .4f} '.format(\n",
    "                batch=ind + 1,\n",
    "                size=len_t,\n",
    "                loss=losses.avg,\n",
    "                top1=top1.avg,\n",
    "                ))\n",
    "\n",
    "test_loss = losses.avg\n",
    "test_acc = top1.avg\n",
    "accurate_acc = sum_correct/len(f_evaluate)\n",
    "print ('evaluate loss: {test_loss: .4f}, evaluate accuracy: {test_acc: .4f}, accurate accuracy: {accurate_acc: .4f}, sum correct: {sum_correct: .1f}'.format(test_loss=test_loss, test_acc=test_acc, accurate_acc=accurate_acc,sum_correct=sum_correct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "infer_input_one_hot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "result_folder = './checkpoints_texas_10class_little_model_defense'\n",
    "if not os.path.exists(result_folder):\n",
    "    os.makedirs(result_folder)\n",
    "if not os.path.exists(result_folder+\"/attack\"):\n",
    "    os.makedirs(result_folder+\"/attack\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "############################ Start-to calculate the defense logits for each input ##############################\n",
    "user_label_dim=10\n",
    "num_classes=1\n",
    "\n",
    "label_mask_array=np.zeros([1,user_label_dim],dtype=np.float)\n",
    "##########################################################\n",
    "result_array=np.zeros(f_evaluate.shape,dtype=np.float)\n",
    "result_array_logits=np.zeros(f_evaluate.shape,dtype=np.float)\n",
    "success_fraction=0.0\n",
    "max_iteration=300   #max iteration if can't find adversarial example that satisfies requirements\n",
    "np.random.seed(1000)\n",
    "\n",
    "# outputs = defense_model_intermidiate(inputs)\n",
    "\n",
    "c1=1.0  #used to find adversarial examples \n",
    "c2=10.0    #penalty such that the index of max score is keeped\n",
    "c3=0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Get the saved location npz model res\n",
    "\n",
    "evaluation_noise_filepath=\"./checkpoints_texas_prune_little_model_defense/attack/Small_1_layer_No_defenss_60_epoch_54_softmax_epoch90_NSH_noise_data_strong.npz\"\n",
    "\n",
    "npz_defense=np.load(evaluation_noise_filepath)\n",
    "npz_defense.files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "result_array=npz_defense['defense_output']\n",
    "result_array_logits=npz_defense['defense_output_logits']\n",
    "# origin_array=npz_defense['tc_output']\n",
    "# origin_array_logits=npz_defense['tc_output_logits']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# origin_array.shape\n",
    "\n",
    "# x_evaluate_attacker\n",
    "\n",
    "one_hot_tr = torch.from_numpy((np.zeros((f_evaluate_tensor.size()[0],f_evaluate_tensor.size(1))))).cuda().type(torch.cuda.FloatTensor)\n",
    "target_one_hot_tr = one_hot_tr.scatter_(1, comb_targets.type(torch.cuda.LongTensor).view([-1,1]).data,1)\n",
    "\n",
    "infer_input_one_hot = torch.autograd.Variable(target_one_hot_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "infer_input_one_hot.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "infer_input_one_hot[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "max_label=np.argmax(f_evaluate[0,:])\n",
    "# result_array[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Sort NSH\n",
    "\n",
    "# f_evaluate.shape[0]\n",
    "start_time = time.time()\n",
    "modified_predict_scores = np.array([])\n",
    "success_fraction = 0.\n",
    "\n",
    "for test_sample_id in np.arange(0,f_evaluate.shape[0]):\n",
    "    max_label=np.argmax(f_evaluate[test_sample_id,:])\n",
    "    origin_value=np.copy(f_evaluate[test_sample_id,:]).reshape(1,user_label_dim)\n",
    "    origin_value_logits=np.copy(f_evaluate_logits[test_sample_id,:]).reshape(1,user_label_dim)\n",
    "    label_mask_array[0,:]=0.0\n",
    "    label_mask_array[0,max_label]=1.0\n",
    "    label_mask_tonser = torch.from_numpy(label_mask_array).type(torch.FloatTensor).cuda()\n",
    "#     label_mask_tonser = torch.from_numpy(label_mask_array).type(torch.FloatTensor)\n",
    "    sample_f_logits=np.copy(origin_value_logits)\n",
    "    sample_f_logits_tensor = torch.from_numpy(sample_f_logits).type(torch.FloatTensor).requires_grad_()\n",
    "    sample_f_logits_tensor = sample_f_logits_tensor.cuda()\n",
    "    sample_f_tensor = softmax(sample_f_logits_tensor)\n",
    "    \n",
    "    target_one_hot_tr = torch.from_numpy((np.zeros((sample_f_tensor.size()[0],outputs.size(1))))).cuda().type(torch.cuda.FloatTensor)\n",
    "    target_one_hot_tr[:,y_evaluate_attacker[test_sample_id]] = 1\n",
    "\n",
    "    target_one_hot_tr[0] = target_one_hot_tr[0][sort_index[test_sample_id]]\n",
    "    infer_input_one_hot_tensor = torch.autograd.Variable(target_one_hot_tr)\n",
    "\n",
    "#     print(sample_f_tensor)\n",
    "    result_predict_scores_initial, sample_f_h =defense_model(sample_f_tensor,_,infer_input_one_hot_tensor)\n",
    "    result_predict_scores_initial = result_predict_scores_initial.item()\n",
    "    \n",
    "    ########## if the output score is already very close to 0.5, we can just use it for numerical reason\n",
    "    if np.abs(result_predict_scores_initial-0.5)<=1e-5:\n",
    "        success_fraction+=1.0\n",
    "        result_array[test_sample_id,:]=origin_value[0,back_index[test_sample_id,:]]\n",
    "        result_array_logits[test_sample_id,:]=origin_value_logits[0,back_index[test_sample_id,:]]\n",
    "        continue\n",
    "    last_iteration_result=np.copy(origin_value)[0,back_index[test_sample_id,:]]\n",
    "    last_iteration_result_logits=np.copy(origin_value_logits)[0,back_index[test_sample_id,:]]\n",
    "    success=True\n",
    "    c3=0.1\n",
    "    iterate_time=1\n",
    "    while success==True: \n",
    "        sample_f=np.copy(origin_value_logits)\n",
    "        j=1\n",
    "        result_max_label=-1\n",
    "        result_predict_scores=result_predict_scores_initial\n",
    "    #         sample_f_tensor = torch.from_numpy(sample_f).type(torch.FloatTensor).requires_grad_()\n",
    "    #         sample_f_tensor = softmax(sample_f_tensor).cuda()\n",
    "        while j<max_iteration and (max_label!=result_max_label or (result_predict_scores-0.5)*(result_predict_scores_initial-0.5)>0):\n",
    "            _, sample_f_h =defense_model(sample_f_tensor,_,infer_input_one_hot_tensor)\n",
    "            loss1 = torch.abs(sample_f_h)\n",
    "#             print(loss1)\n",
    "            correct_label = torch.sum(label_mask_tonser * sample_f_tensor, 1)\n",
    "            wrong_label = torch.max((1-label_mask_tonser) * sample_f_tensor - 1e8*label_mask_tonser,1).values\n",
    "            loss2 = F.relu(wrong_label-correct_label)\n",
    "#             print(loss2)\n",
    "            loss3= torch.sum(torch.abs(sample_f_tensor - torch.from_numpy(origin_value).type(torch.FloatTensor).cuda())) #L-1 norm\n",
    "#             loss3= torch.sum(torch.abs(sample_f_tensor - torch.from_numpy(origin_value).type(torch.FloatTensor))) #L-1 norm\n",
    "#             print(loss3)\n",
    "            loss = c1 * loss1 + c2 * loss2 + c3 * loss3\n",
    "            gradient_values = torch.autograd.grad(loss, sample_f_tensor)[0]\n",
    "            gradient_valuesx = gradient_values/torch.norm(gradient_values)\n",
    "\n",
    "            sample_f_logits_tensor = sample_f_logits_tensor-0.1*gradient_valuesx\n",
    "            sample_f_tensor = softmax(sample_f_logits_tensor)\n",
    "            result_predict_scores, _ = defense_model(sample_f_tensor,_,infer_input_one_hot_tensor)\n",
    "            result_predict_scores = result_predict_scores.item()\n",
    "            result_max_label = torch.argmax(sample_f_tensor).item()\n",
    "            j+=1\n",
    "        if max_label!=result_max_label:\n",
    "            if iterate_time==1:\n",
    "                print(\"failed sample for label not same for id: {},c3:{} not add noise\".format(test_sample_id,c3))\n",
    "                success_fraction-=1.0\n",
    "            break \n",
    "        result_predict_scores, _ = defense_model(sample_f_tensor,_,infer_input_one_hot_tensor)\n",
    "        if ((result_predict_scores.item()-0.5)*(result_predict_scores_initial-0.5))>0:\n",
    "            if iterate_time==1:\n",
    "                success_fraction-=1.0\n",
    "                print(\"max iteration reached with id: {}, max score: {}, prediction_score: {}, c3: {}, not add noise\".format(test_sample_id,torch.max(sample_f_tensor),result_predict_scores.item(),c3))\n",
    "            break\n",
    "        last_iteration_result[:]=sample_f_tensor.data.cpu().numpy()[0,back_index[test_sample_id,:]]\n",
    "        last_iteration_result_logits[:]=sample_f_logits_tensor.data.cpu().numpy()[0,back_index[test_sample_id,:]]\n",
    "        iterate_time+=1 \n",
    "        c3=c3*10\n",
    "        if c3>100000:\n",
    "            break\n",
    "            \n",
    "#     modified_predict_scores = np.concatenate((modified_predict_scores, result_predict_scores.item()), axis=None)\n",
    "    success_fraction+=1.0\n",
    "    result_array[test_sample_id,:]=last_iteration_result[:]\n",
    "    result_array_logits[test_sample_id,:]=last_iteration_result_logits[:]\n",
    "    if test_sample_id%100==0:\n",
    "        end = time.time() - start_time\n",
    "        start_time = time.time()\n",
    "        np.savez(result_folder+\"/attack/\"+\"Class10_1layer_No_defenss_100_epoch_32_sort_mod_softmax_epoch94_noise_data_{}.npz\".format(\"strong\"),defense_output=result_array,defense_output_logits=result_array_logits)\n",
    "        print(\"test sample id: {}, time spend per 100 test sample: {}\".format(test_sample_id, end))\n",
    "        \n",
    "print(\"Success fraction: {}\".format(success_fraction/float(f_evaluate.shape[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "success_fraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# NSH attack model\n",
    "\n",
    "defense_model.eval()\n",
    "# f_evaluate.shape[0]\n",
    "start_time = time.time()\n",
    "modified_predict_scores = np.array([])\n",
    "success_fraction = 0.\n",
    "\n",
    "for test_sample_id in np.arange(0,f_evaluate.shape[0]):\n",
    "# for test_sample_id in np.arange(0,101):\n",
    "\n",
    "    max_label=np.argmax(f_evaluate[test_sample_id,:])\n",
    "    origin_value=np.copy(f_evaluate[test_sample_id,:]).reshape(1,user_label_dim)\n",
    "    origin_value_logits=np.copy(f_evaluate_logits[test_sample_id,:]).reshape(1,user_label_dim)\n",
    "    infer_input_one_hot_tensor = infer_input_one_hot[test_sample_id,:]\n",
    "    label_mask_array[0,:]=0.0\n",
    "    label_mask_array[0,max_label]=1.0\n",
    "    label_mask_tonser = torch.from_numpy(label_mask_array).type(torch.FloatTensor).cuda()\n",
    "#     label_mask_tonser = torch.from_numpy(label_mask_array).type(torch.FloatTensor)\n",
    "    sample_f_logits=np.copy(origin_value_logits)\n",
    "    sample_f_logits_tensor = torch.from_numpy(sample_f_logits).type(torch.FloatTensor).requires_grad_()\n",
    "    sample_f_logits_tensor = sample_f_logits_tensor.cuda()\n",
    "    sample_f_tensor = softmax(sample_f_logits_tensor)\n",
    "    infer_input_one_hot_tensor = infer_input_one_hot_tensor.view(sample_f_tensor.shape)\n",
    "#     print(sample_f_tensor)\n",
    "    result_predict_scores_initial, sample_f_h =defense_model(sample_f_tensor,_,infer_input_one_hot_tensor)\n",
    "\n",
    "    result_predict_scores_initial = result_predict_scores_initial.item()\n",
    "#     break\n",
    "    ########## if the output score is already very close to 0.5, we can just use it for numerical reason\n",
    "    if np.abs(result_predict_scores_initial-0.5)<=1e-5:\n",
    "        success_fraction+=1.0\n",
    "        result_array[test_sample_id,:]=origin_value[0,back_index[test_sample_id,:]]\n",
    "        result_array_logits[test_sample_id,:]=origin_value_logits[0,back_index[test_sample_id,:]]\n",
    "        continue\n",
    "    last_iteration_result=np.copy(origin_value)[0,back_index[test_sample_id,:]]\n",
    "    last_iteration_result_logits=np.copy(origin_value_logits)[0,back_index[test_sample_id,:]]\n",
    "    success=True\n",
    "    c3=0.1\n",
    "    iterate_time=1\n",
    "    while success==True: \n",
    "        sample_f=np.copy(origin_value_logits)\n",
    "        j=1\n",
    "        result_max_label=-1\n",
    "        result_predict_scores=result_predict_scores_initial\n",
    "    #         sample_f_tensor = torch.from_numpy(sample_f).type(torch.FloatTensor).requires_grad_()\n",
    "    #         sample_f_tensor = softmax(sample_f_tensor).cuda()\n",
    "        while j<max_iteration and (max_label!=result_max_label or (result_predict_scores-0.5)*(result_predict_scores_initial-0.5)>0):\n",
    "            _, sample_f_h =defense_model(sample_f_tensor,_,infer_input_one_hot_tensor)\n",
    "            loss1 = torch.abs(sample_f_h)\n",
    "#             print(loss1)\n",
    "            correct_label = torch.sum(label_mask_tonser * sample_f_tensor, 1)\n",
    "            wrong_label = torch.max((1-label_mask_tonser) * sample_f_tensor - 1e8*label_mask_tonser,1).values\n",
    "            loss2 = F.relu(wrong_label-correct_label)\n",
    "#             print(loss2)\n",
    "            loss3= torch.sum(torch.abs(sample_f_tensor - torch.from_numpy(origin_value).type(torch.FloatTensor).cuda())) #L-1 norm\n",
    "#             loss3= torch.sum(torch.abs(sample_f_tensor - torch.from_numpy(origin_value).type(torch.FloatTensor))) #L-1 norm\n",
    "#             print(loss3)\n",
    "            loss = c1 * loss1 + c2 * loss2 + c3 * loss3\n",
    "            gradient_values = torch.autograd.grad(loss, sample_f_tensor)[0]\n",
    "            gradient_valuesx = gradient_values/torch.norm(gradient_values)\n",
    "            \n",
    "            sample_f_logits_tensor = sample_f_logits_tensor-0.1*gradient_valuesx\n",
    "            sample_f_tensor = softmax(sample_f_logits_tensor)\n",
    "            result_predict_scores, _ = defense_model(sample_f_tensor,_,infer_input_one_hot_tensor)\n",
    "            result_predict_scores = result_predict_scores.item()\n",
    "            result_max_label = torch.argmax(sample_f_tensor).item()\n",
    "            j+=1\n",
    "        if max_label!=result_max_label:\n",
    "            if iterate_time==1:\n",
    "                print(\"failed sample for label not same for id: {},c3:{} not add noise\".format(test_sample_id,c3))\n",
    "                success_fraction-=1.0\n",
    "            break \n",
    "        result_predict_scores, _ = defense_model(sample_f_tensor,_,infer_input_one_hot_tensor)\n",
    "        if ((result_predict_scores.item()-0.5)*(result_predict_scores_initial-0.5))>0:\n",
    "            if iterate_time==1:\n",
    "                success_fraction-=1.0\n",
    "                print(\"max iteration reached with id: {}, max score: {}, prediction_score: {}, c3: {}, not add noise\".format(test_sample_id,torch.max(sample_f_tensor),result_predict_scores.item(),c3))\n",
    "            break\n",
    "        last_iteration_result[:]=sample_f_tensor.data.cpu().numpy()\n",
    "        last_iteration_result_logits[:]=sample_f_logits_tensor.data.cpu().numpy()\n",
    "        iterate_time+=1 \n",
    "        c3=c3*10\n",
    "        if c3>100000:\n",
    "            break\n",
    "            \n",
    "#     modified_predict_scores = np.concatenate((modified_predict_scores, result_predict_scores.item()), axis=None)\n",
    "    success_fraction+=1.0\n",
    "    result_array[test_sample_id,:]=last_iteration_result[:]\n",
    "    result_array_logits[test_sample_id,:]=last_iteration_result_logits[:]\n",
    "    if test_sample_id%100==0:\n",
    "        end = time.time() - start_time\n",
    "        start_time = time.time()\n",
    "        np.savez(result_folder+\"/attack/\"+\"Small_1_layer_No_defenss_60_epoch_54_softmax_epoch90_NSH_noise_data_{}.npz\".format(\"strong\"),defense_output=result_array,defense_output_logits=result_array_logits)\n",
    "        print(\"test sample id: {}, time spend per 100 test sample: {}\".format(test_sample_id, end))\n",
    "#         break\n",
    "        \n",
    "print(\"Success fraction: {}\".format(success_fraction/float(f_evaluate.shape[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "success_fraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# f_evaluate.shape[0]\n",
    "start_time = time.time()\n",
    "success_fraction = 0.0\n",
    "modified_predict_scores = np.array([])\n",
    "\n",
    "for test_sample_id in np.arange(0,f_evaluate.shape[0]):\n",
    "    max_label=np.argmax(f_evaluate[test_sample_id,:])\n",
    "    origin_value=np.copy(f_evaluate[test_sample_id,:]).reshape(1,user_label_dim)\n",
    "    origin_value_logits=np.copy(f_evaluate_logits[test_sample_id,:]).reshape(1,user_label_dim)\n",
    "    label_mask_array[0,:]=0.0\n",
    "    label_mask_array[0,max_label]=1.0\n",
    "    label_mask_tonser = torch.from_numpy(label_mask_array).type(torch.FloatTensor).cuda()\n",
    "#     label_mask_tonser = torch.from_numpy(label_mask_array).type(torch.FloatTensor)\n",
    "    sample_f_logits=np.copy(origin_value_logits)\n",
    "    sample_f_logits_tensor = torch.from_numpy(sample_f_logits).type(torch.FloatTensor).requires_grad_()\n",
    "    sample_f_logits_tensor = sample_f_logits_tensor.cuda()\n",
    "    sample_f_tensor = softmax(sample_f_logits_tensor)\n",
    "#     print(sample_f_tensor)\n",
    "    result_predict_scores_initial, sample_f_h =defense_model(sample_f_tensor)\n",
    "    result_predict_scores_initial = result_predict_scores_initial.item()\n",
    "    \n",
    "    ########## if the output score is already very close to 0.5, we can just use it for numerical reason\n",
    "    if np.abs(result_predict_scores_initial-0.5)<=1e-5:\n",
    "        success_fraction+=1.0\n",
    "        result_array[test_sample_id,:]=origin_value[0,back_index[test_sample_id,:]]\n",
    "        result_array_logits[test_sample_id,:]=origin_value_logits[0,back_index[test_sample_id,:]]\n",
    "        continue\n",
    "    last_iteration_result=np.copy(origin_value)[0,back_index[test_sample_id,:]]\n",
    "    last_iteration_result_logits=np.copy(origin_value_logits)[0,back_index[test_sample_id,:]]\n",
    "    success=True\n",
    "    c3=0.1\n",
    "    iterate_time=1\n",
    "    while success==True: \n",
    "        sample_f=np.copy(origin_value_logits)\n",
    "        j=1\n",
    "        result_max_label=-1\n",
    "        result_predict_scores=result_predict_scores_initial\n",
    "    #         sample_f_tensor = torch.from_numpy(sample_f).type(torch.FloatTensor).requires_grad_()\n",
    "    #         sample_f_tensor = softmax(sample_f_tensor).cuda()\n",
    "        while j<max_iteration and (max_label!=result_max_label or (result_predict_scores-0.5)*(result_predict_scores_initial-0.5)>0):\n",
    "            _, sample_f_h =defense_model(sample_f_tensor)\n",
    "            loss1 = torch.abs(sample_f_h)\n",
    "#             print(loss1)\n",
    "            correct_label = torch.sum(label_mask_tonser * sample_f_tensor, 1)\n",
    "            wrong_label = torch.max((1-label_mask_tonser) * sample_f_tensor - 1e8*label_mask_tonser,1).values\n",
    "            loss2 = F.relu(wrong_label-correct_label)\n",
    "#             print(loss2)\n",
    "            loss3= torch.sum(torch.abs(sample_f_tensor - torch.from_numpy(origin_value).type(torch.FloatTensor).cuda())) #L-1 norm\n",
    "#             loss3= torch.sum(torch.abs(sample_f_tensor - torch.from_numpy(origin_value).type(torch.FloatTensor))) #L-1 norm\n",
    "#             print(loss3)\n",
    "            loss = c1 * loss1 + c2 * loss2 + c3 * loss3\n",
    "            gradient_values = torch.autograd.grad(loss, sample_f_tensor)[0]\n",
    "            gradient_valuesx = gradient_values/torch.norm(gradient_values)\n",
    "\n",
    "            sample_f_logits_tensor = sample_f_logits_tensor-0.1*gradient_valuesx\n",
    "            sample_f_tensor = softmax(sample_f_logits_tensor)\n",
    "            result_predict_scores, _ = defense_model(sample_f_tensor)\n",
    "            result_predict_scores = result_predict_scores.item()\n",
    "            result_max_label = torch.argmax(sample_f_tensor).item()\n",
    "            j+=1\n",
    "        if max_label!=result_max_label:\n",
    "            if iterate_time==1:\n",
    "                print(\"failed sample for label not same for id: {},c3:{} not add noise\".format(test_sample_id,c3))\n",
    "                success_fraction-=1.0\n",
    "            break \n",
    "        result_predict_scores, _ = defense_model(sample_f_tensor)\n",
    "        if ((result_predict_scores.item()-0.5)*(result_predict_scores_initial-0.5))>0:\n",
    "            if iterate_time==1:\n",
    "                success_fraction-=1.0\n",
    "                print(\"max iteration reached with id: {}, max score: {}, prediction_score: {}, c3: {}, not add noise\".format(test_sample_id,torch.max(sample_f_tensor),result_predict_scores.item(),c3))\n",
    "            break\n",
    "        last_iteration_result[:]=sample_f_tensor.data.cpu().numpy()[0,back_index[test_sample_id,:]]\n",
    "        last_iteration_result_logits[:]=sample_f_logits_tensor.data.cpu().numpy()[0,back_index[test_sample_id,:]]\n",
    "        iterate_time+=1 \n",
    "        c3=c3*10\n",
    "        if c3>100000:\n",
    "            break\n",
    "            \n",
    "#     modified_predict_scores = np.concatenate((modified_predict_scores, result_predict_scores.item()), axis=None)\n",
    "    success_fraction+=1.0\n",
    "    result_array[test_sample_id,:]=last_iteration_result[:]\n",
    "    result_array_logits[test_sample_id,:]=last_iteration_result_logits[:]\n",
    "    if test_sample_id%100==0:\n",
    "        end = time.time() - start_time\n",
    "        start_time = time.time()\n",
    "        np.savez(result_folder+\"/attack/\"+\"Class10_1layer_No_defenss_100_epoch_32_softmax_defensemodel_epoch77_noise_data_{}.npz\".format(\"modified\"),defense_output=result_array,defense_output_logits=result_array_logits)\n",
    "        print(\"test sample id: {}, time spend per 100 test sample: {}\".format(test_sample_id, end))\n",
    "        \n",
    "print(\"Success fraction: {}\".format(success_fraction/float(f_evaluate.shape[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "success_fraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "result_array[9999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "test_array = result_array[0:100, :]\n",
    "test_array_logits = result_array_logits[0:100, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "test_array[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "test_array_logits[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "one_hot_tr = torch.from_numpy((np.zeros((f_evaluate_tensor.size()[0],f_evaluate_tensor.size(1))))).cuda().type(torch.cuda.FloatTensor)\n",
    "target_one_hot_tr = one_hot_tr.scatter_(1, y_evaluate_attacker_tensor.type(torch.cuda.LongTensor).view([-1,1]).data,1)\n",
    "infer_input_one_hot = torch.autograd.Variable(target_one_hot_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# memg test\n",
    "defense_model.eval()\n",
    "\n",
    "# softmax = nn.Softmax()\n",
    "\n",
    "# f_evaluate_logits_tensor = torch.from_numpy(f_evaluate_logits).type(torch.FloatTensor)\n",
    "# f_evaluate_tensor = torch.from_numpy(np.sort(f_evaluate_origin,axis=1)).type(torch.FloatTensor)\n",
    "# f_evaluate_tensor = torch.from_numpy(f_evaluate_origin).type(torch.FloatTensor)\n",
    "f_evaluate_tensor = torch.from_numpy(f_evaluate).type(torch.FloatTensor)\n",
    "# f_evaluate_tensor = torch.from_numpy(np.sort(origin_array,axis=1)).type(torch.FloatTensor)\n",
    "# f_evaluate_tensor = torch.from_numpy(origin_array).type(torch.FloatTensor)\n",
    "\n",
    "batch_size = 128\n",
    "len_t =  (len(f_evaluate_tensor)//batch_size)+1\n",
    "print('len_t: ', len_t)\n",
    "# predict_origin = np.zeros(f_evaluate.shape[0],dtype=np.float)\n",
    "predict_origin= np.array([])\n",
    "for ind in range(len_t):\n",
    "    # measure data loading time\n",
    "    inputs = f_evaluate_tensor[ind*batch_size:(ind+1)*batch_size]\n",
    "    input_one_hot_tensor = infer_input_one_hot[ind*batch_size:(ind+1)*batch_size]\n",
    "    attack_output, attack_output_h = defense_model(inputs)\n",
    "#     attack_output, attack_output_h = defense_model(inputs, _ ,input_one_hot_tensor)\n",
    "    predict_origin = np.concatenate((predict_origin, attack_output.data.cpu().numpy()), axis=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "defense_model.eval()\n",
    "\n",
    "# softmax = nn.Softmax()\n",
    "\n",
    "# f_evaluate_logits_tensor = torch.from_numpy(f_evaluate_logits).type(torch.FloatTensor)\n",
    "# f_evaluate_tensor = torch.from_numpy(np.sort(f_evaluate_origin,axis=1)).type(torch.FloatTensor)\n",
    "f_evaluate_tensor = torch.from_numpy(f_evaluate_origin).type(torch.FloatTensor)\n",
    "# f_evaluate_tensor = torch.from_numpy(f_evaluate).type(torch.FloatTensor)\n",
    "\n",
    "# f_evaluate_tensor = torch.from_numpy(np.sort(origin_array,axis=1)).type(torch.FloatTensor)\n",
    "# f_evaluate_tensor = torch.from_numpy(origin_array).type(torch.FloatTensor)\n",
    "\n",
    "batch_size = 128\n",
    "len_t =  (len(f_evaluate_tensor)//batch_size)+1\n",
    "print('len_t: ', len_t)\n",
    "# predict_origin = np.zeros(f_evaluate.shape[0],dtype=np.float)\n",
    "predict_origin= np.array([])\n",
    "for ind in range(len_t):\n",
    "    # measure data loading time\n",
    "    inputs = f_evaluate_tensor[ind*batch_size:(ind+1)*batch_size]\n",
    "    targets = y_evaluate_attacker_tensor[ind*batch_size:(ind+1)*batch_size]\n",
    "    \n",
    "    sort_inputs, indices= torch.sort(inputs)\n",
    "        \n",
    "    one_hot_tr = torch.from_numpy((np.zeros((inputs.size()[0],outputs.size(1))))).cuda().type(torch.cuda.FloatTensor)\n",
    "    target_one_hot_tr = one_hot_tr.scatter_(1, targets.type(torch.cuda.LongTensor).view([-1,1]).data,1)\n",
    "\n",
    "    for i in range(len(indices)):\n",
    "        target_one_hot_tr[i] = target_one_hot_tr[i][indices[i]]\n",
    "\n",
    "    infer_input_one_hot = torch.autograd.Variable(target_one_hot_tr)\n",
    "    \n",
    "#     attack_output, attack_output_h = defense_model(inputs)\n",
    "    attack_output, attack_output_h = defense_model(sort_inputs, _ ,infer_input_one_hot)\n",
    "    predict_origin = np.concatenate((predict_origin, attack_output.data.cpu().numpy()), axis=None)\n",
    "#     if infer_input_one_hot[:,99] == 0:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "result_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "f_evaluate[3499]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "test_data = f_evaluate[3499]\n",
    "# test_data = [0.09613917, 0.09760948, 0.09762944, 0.09764805, 0.09819929,0.09827515, 0.09849446, 0.09960721, 0.10178852, 0.1016092]\n",
    "np.sum(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "test_data_tensor = torch.from_numpy(np.sort(test_data)).type(torch.FloatTensor).cuda()\n",
    "test_data_tensor = test_data_tensor.view(1,-1)\n",
    "test_data_tensor.shape\n",
    "attack_output, attack_output_h = defense_model(test_data_tensor)\n",
    "attack_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "max_data = f_evaluate[:,9]\n",
    "max_data.shape\n",
    "max_data_train = max_data[:3500]\n",
    "max_data_test = max_data[3500:]\n",
    "sort_max_data_train = np.sort(max_data_train)\n",
    "sort_max_data_test = np.sort(max_data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "sort_max_data_train[3500-2483]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "sort_max_data_test[1750]\n",
    "np.sum(sort_max_data_test>0.85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "predict_modified= np.array([])\n",
    "# np.sort(result_array,axis=1)\n",
    "# result_array_tensor = torch.from_numpy(np.sort(result_array,axis=1)).type(torch.FloatTensor).cuda()\n",
    "result_array_tensor = torch.from_numpy(result_array).type(torch.FloatTensor).cuda()\n",
    "\n",
    "for ind in range(len_t):\n",
    "    # measure data loading time\n",
    "    inputs = result_array_tensor[ind*batch_size:(ind+1)*batch_size]\n",
    "    input_one_hot_tensor = infer_input_one_hot[ind*batch_size:(ind+1)*batch_size]\n",
    "#     attack_output, attack_output_h = defense_model(inputs)\n",
    "    attack_output, attack_output_h = defense_model(inputs, _ ,input_one_hot_tensor)\n",
    "\n",
    "    predict_modified = np.concatenate((predict_modified, attack_output.data.cpu().numpy()), axis=None)\n",
    "#     break\n",
    "\n",
    "# predict_modified.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "predict_modified= np.array([])\n",
    "# np.sort(result_array,axis=1)\n",
    "# result_array_tensor = torch.from_numpy(np.sort(result_array,axis=1)).type(torch.FloatTensor).cuda()\n",
    "result_array_tensor = torch.from_numpy(result_array).type(torch.FloatTensor).cuda()\n",
    "\n",
    "for ind in range(len_t):\n",
    "    # measure data loading time\n",
    "    inputs = result_array_tensor[ind*batch_size:(ind+1)*batch_size]\n",
    "    targets = y_evaluate_attacker_tensor[ind*batch_size:(ind+1)*batch_size]\n",
    "    \n",
    "    sort_inputs, indices= torch.sort(inputs)\n",
    "        \n",
    "    one_hot_tr = torch.from_numpy((np.zeros((inputs.size()[0],outputs.size(1))))).cuda().type(torch.cuda.FloatTensor)\n",
    "    target_one_hot_tr = one_hot_tr.scatter_(1, targets.type(torch.cuda.LongTensor).view([-1,1]).data,1)\n",
    "\n",
    "    for i in range(len(indices)):\n",
    "        target_one_hot_tr[i] = target_one_hot_tr[i][indices[i]]\n",
    "\n",
    "    infer_input_one_hot = torch.autograd.Variable(target_one_hot_tr)\n",
    "    \n",
    "#     attack_output, attack_output_h = defense_model(inputs)\n",
    "    attack_output, attack_output_h = defense_model(sort_inputs, _ ,infer_input_one_hot)\n",
    "\n",
    "    predict_modified = np.concatenate((predict_modified, attack_output.data.cpu().numpy()), axis=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "predict_origin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# f_evaluate_noise = f_evaluate_origin\n",
    "# predict_modified = predict_origin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# memg test\n",
    "scenario='full'\n",
    "if scenario=='full':\n",
    "    predict_result_origin=np.where(predict_origin > 0.5, 1, 0)\n",
    "#     predict_result_defense=np.where(predict_modified > 0.5, 1, 0)\n",
    "else:\n",
    "    raise NotImplementedError\n",
    "\n",
    "epsilon_value_list=[\"1.0\",\"0.7\",\"0.5\",\"0.4\",\"0.3\",\"0.2\",\"0.1\",\"0.0\"] # \"0.05\",\"0.03\",\"0.02\",\"0.01\",\n",
    "# epsilon_value_list=[\"0.2\",\"0.1\",\"0.07\",\"0.05\",\"0.03\",\"0.01\",\"0.0\"]\n",
    "# epsilon_value_list=[\"0.0\"]\n",
    "epsilon_value_list=[float(t) for t in epsilon_value_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "f_evaluate_noise = result_array\n",
    "# f_evaluate_origin = origin_array\n",
    "predict_result_defense.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "predict_origin.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "count = 0\n",
    "for i in np.arange(f_evaluate_origin.shape[0]):\n",
    "    if np.equal(predict_result_origin[i] , label_evaluate_attacker[i]):\n",
    "        count+=1\n",
    "    \n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "count_train = 0\n",
    "for i in np.arange(int(f_evaluate_origin.shape[0]*0.5)):\n",
    "    if np.equal(predict_result_origin[i] , label_evaluate_attacker[i]):\n",
    "        count_train+=1\n",
    "    \n",
    "count_test = 0\n",
    "for i in np.arange(int(f_evaluate_origin.shape[0]*0.5), f_evaluate_origin.shape[0]):\n",
    "    if np.equal(predict_result_origin[i] , label_evaluate_attacker[i]):\n",
    "        count_test+=1\n",
    "    \n",
    "print(count_train, count_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "count = 0\n",
    "for i in np.arange(f_evaluate_origin.shape[0]):\n",
    "    if np.equal(predict_result_defense[i] , label_evaluate_attacker[i]):\n",
    "        count+=1\n",
    "    \n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "count_train = 0\n",
    "for i in np.arange(int(f_evaluate_origin.shape[0]*0.5)):\n",
    "    if np.equal(predict_result_defense[i] , label_evaluate_attacker[i]):\n",
    "        count_train+=1\n",
    "    \n",
    "count_test = 0\n",
    "for i in np.arange(int(f_evaluate_origin.shape[0]*0.5), f_evaluate_origin.shape[0]):\n",
    "    if np.equal(predict_result_defense[i] , label_evaluate_attacker[i]):\n",
    "        count_test+=1\n",
    "    \n",
    "print(count_train, count_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# scenario='full'\n",
    "# if scenario=='full':\n",
    "#     predict_result_origin=np.where(predict_origin > 0.5, 1, 0)\n",
    "#     predict_result_defense=np.where(predict_modified > 0.5, 1, 0)\n",
    "# else:\n",
    "#     raise NotImplementedError\n",
    "\n",
    "# epsilon_value_list=[\"1.0\",\"0.7\",\"0.5\",\"0.3\",\"0.1\",\"0.0\"]\n",
    "# epsilon_value_list=[float(t) for t in epsilon_value_list]\n",
    "\n",
    "inference_accuracy_list=[]\n",
    "ori_list = []\n",
    "noise_list = []\n",
    "for epsilon_value in epsilon_value_list: \n",
    "    inference_accuracy=0.0\n",
    "    ori = 0.0\n",
    "    noi = 0.0\n",
    "    max_noise = 0.0\n",
    "    np.random.seed(100)  \n",
    "    for i in np.arange(f_evaluate_origin.shape[0]):\n",
    "        distortion_noise=np.sum(np.abs(f_evaluate_origin[i,:]-f_evaluate_noise[i,:]))\n",
    "        if distortion_noise > max_noise:\n",
    "            max_noise = distortion_noise\n",
    "        p_value=0.0\n",
    "        if np.abs(predict_origin[i]-0.5)<=np.abs(predict_modified[i]-0.5):\n",
    "            p_value=0.0\n",
    "        else:\n",
    "            p_value=min(epsilon_value/distortion_noise,1.0)\n",
    "        \n",
    "        if predict_result_origin[i]==label_evaluate_attacker[i]:\n",
    "            ori += 1\n",
    "            inference_accuracy+=1.0-p_value\n",
    "        if predict_result_defense[i]==label_evaluate_attacker[i]:\n",
    "            noi += 1\n",
    "            inference_accuracy+=p_value\n",
    "#         print('distortion_noise: ', distortion_noise, ' p_value: ',p_value,' inference_accuracy: ',inference_accuracy)\n",
    "    inference_accuracy_list.append(inference_accuracy/(float(f_evaluate_origin.shape[0])))\n",
    "    ori_list.append(ori)\n",
    "    noise_list.append(noi)\n",
    "#     break\n",
    "    \n",
    "print(\"Budget list: {}\".format(epsilon_value_list))\n",
    "print(\"inference accuracy list: {}\".format(inference_accuracy_list))\n",
    "print(\"ori_list: {}\".format(ori_list))\n",
    "print(\"noise_list: {}\".format(noise_list))\n",
    "print(\"max_noise: {}\".format(max_noise))\n",
    "# Budget list: [1.0, 0.7, 0.5, 0.3, 0.1, 0.0]\n",
    "# inference accuracy list: [0.5021911142220747, 0.5048992830892228, 0.5120250427638868, 0.5286259040624035, 0.5731544218872452, 0.60825]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from matplotlib import pyplot\n",
    "from matplotlib.pylab import plt\n",
    "# pyplot.plot(predict_origin)\n",
    "# pyplot.plot(f_evaluate_origin[3])\n",
    "# pyplot.plot(f_evaluate_origin[4])\n",
    "# plt.plot(f_evaluate_origin[0])\n",
    "# plt.plot(f_evaluate_origin[1])\n",
    "# plt.plot(f_evaluate_origin[2])\n",
    "for i in range(100):\n",
    "#     plt.plot(f_evaluate_origin[i])\n",
    "    plt.plot(f_evaluate[i])\n",
    "#     plt.plot(result_array[i])\n",
    "#     plt.plot(sort_result_array[i])\n",
    "# for i in range(f_evaluate_origin.shape[0]):\n",
    "#     pyplot.plot(f_evaluate_origin[i])\n",
    "    \n",
    "# plt.ylim(0, 0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "predict_train = []\n",
    "predict_test = []\n",
    "\n",
    "for i in range(len(predict_origin)):\n",
    "    if predict_origin[i] > 0.5:\n",
    "        predict_train.append(i)\n",
    "    else:\n",
    "        predict_test.append(i)\n",
    "        \n",
    "print(len(predict_train))\n",
    "print(len(predict_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(30,20))\n",
    "plt.ylim(0.05,0.25)\n",
    "for i in range(len(predict_train)):\n",
    "#     plt.plot(f_evaluate_origin[i])\n",
    "    plt.plot(f_evaluate[predict_train[i]])\n",
    "\n",
    "plt.show()\n",
    "# fig.savefig('Class10_1layer_Modify_min_sort_diff55_alpha0_beta10_defense_epoch_7_predict_train.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "fig = plt.figure(figsize=(30,20))\n",
    "plt.ylim(0.05,0.25)\n",
    "for i in range(len(predict_test)):\n",
    "#     plt.plot(f_evaluate_origin[i])\n",
    "    plt.plot(f_evaluate[predict_test[i]])\n",
    "\n",
    "plt.show()\n",
    "# fig.savefig('Class10_1layer_Modify_min_sort_diff55_alpha0_beta10_defense_epoch_7_predict_test.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# No_defense_20_epoch_2_prune_99_retrain_epoch_99\n",
    "\n",
    "fig = plt.figure(figsize=(30,20))\n",
    "plt.ylim(0.05,0.25)\n",
    "# for i in range(3500,7000):\n",
    "for i in range(2500,5000):\n",
    "#     plt.plot(result_array[i])\n",
    "    pyplot.plot(f_evaluate_origin[i])\n",
    "# fig.savefig('Class10_1layer_Modify_min_sort_diff55_alpha0_beta10_defense_epoch_7_testset.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(30,20))\n",
    "plt.ylim(0.05,0.25)\n",
    "# for i in range(0,3500):\n",
    "for i in range(0,2500):\n",
    "#     plt.plot(result_array[i])\n",
    "    pyplot.plot(f_evaluate_origin[i])\n",
    "# fig.savefig('Class10_1layer_Modify_min_sort_diff55_alpha0_beta10_defense_epoch_7_traintset.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "sort_result_array = np.sort(result_array,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "f_evaluate[:,9].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "hsit_train = np.histogram(f_evaluate[0:2500,9],range=[0.1,0.25],bins=10)\n",
    "sum(hsit_train[0])\n",
    "hsit_train\n",
    "# plt.hist(f_evaluate[0:2500,9],range=[0.1,0.25],bins=20)\n",
    "plt.hist(f_evaluate[0:2500,9],bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "hsit_test = np.histogram(f_evaluate[2500:5000,9],range=[0.1,0.25],bins=10)\n",
    "hsit_test\n",
    "# sum(hsit_test[0])\n",
    "# plt.hist(f_evaluate[2500:5000,9],range=[0.1,0.25],bins=20)\n",
    "plt.hist(f_evaluate[2500:5000,9],bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "fig = plt.figure(figsize=(30,20))\n",
    "plt.ylim(0.05,0.25)\n",
    "for i in range(2500,5000):\n",
    "#     plt.plot(sort_result_array[i])\n",
    "    pyplot.plot(f_evaluate[i])\n",
    "# fig.savefig('Class10_1layer_Modify_min_sort_diff55_alpha0_beta10_defense_epoch_7_sort_testset.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "fig = plt.figure(figsize=(30,20))\n",
    "plt.ylim(0.05,0.25)\n",
    "for i in range(0,2500):\n",
    "#     plt.plot(sort_result_array[i])\n",
    "    pyplot.plot(f_evaluate[i])\n",
    "# fig.savefig('Class10_1layer_Modify_min_sort_diff55_alpha0_beta10_defense_epoch_7_sort_trainset.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Modify6_var_max_alpha5_defense_epoch_15\n",
    "\n",
    "fig = plt.figure(figsize=(30,20))\n",
    "# plt.ylim(-0.05, 0.65)\n",
    "for i in range(10000,20000):\n",
    "    pyplot.plot(f_evaluate_origin[i])\n",
    "#     pyplot.plot(f_evaluate_logits_origin[i])\n",
    "fig.savefig('Modify6_var_max_alpha5_defense_epoch_15_testset.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# save the results\n",
    "\n",
    "# np.savez(result_folder+\"/attack/\"+\"noise_data_{}.npz\".format(\"No_defense_20_epoch_6_40000_evaluation\"),defense_output=result_array,defense_output_logits=result_array_logits,tc_output=f_evaluate_origin,tc_output_logits=f_evaluate_logits_origin,predict_origin=predict_origin,predict_modified=predict_modified, label_evaluate=att_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "attack_model = InferenceAttack_HZ(100)\n",
    "attack_model = torch.nn.DataParallel(attack_model).cuda()\n",
    "attack_criterion = nn.MSELoss()\n",
    "at_lr = 0.0001\n",
    "state={}\n",
    "state['lr']=at_lr\n",
    "attack_optimizer = optim.Adam(attack_model.parameters(),lr=at_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "resume_att='./checkpoints_texas_prune_little_model_defense/Small_No_defense_20_epoch_20_softmax_epoch97'\n",
    "print('==> Resuming attack model from checkpoint..')\n",
    "assert os.path.isfile(resume_att), 'Error: no checkpoint directory found!'\n",
    "checkpoint_att = os.path.dirname(resume_att)\n",
    "checkpoint_att = torch.load(resume_att)\n",
    "attack_model.load_state_dict(checkpoint_att['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "r1 = np.arange(len(train_classifier_data_tr_attack))\n",
    "# np.random.shuffle(r1)\n",
    "\n",
    "check_train_trainset_data_tensor = torch.from_numpy(train_classifier_data_tr_attack[r1]).type(torch.FloatTensor)\n",
    "check_train_trainset_label_tensor = torch.from_numpy(train_classifier_label_tr_attack[r1]).type(torch.LongTensor)\n",
    "\n",
    "r2 = np.arange(len(train_attack_data))\n",
    "# np.random.shuffle(r2)\n",
    "check_train_attack_data_tensor = torch.from_numpy(train_attack_data[r2]).type(torch.FloatTensor)\n",
    "check_train_attack_label_tensor = torch.from_numpy(train_attack_label[r2]).type(torch.LongTensor)\n",
    "\n",
    "r3 = np.arange(len(train_classifier_data_te_attack))\n",
    "# np.random.shuffle(r3)\n",
    "\n",
    "check_test_trainset_data_tensor = torch.from_numpy(train_classifier_data_te_attack[r3]).type(torch.FloatTensor)\n",
    "check_test_trainset_label_tensor = torch.from_numpy(train_classifier_label_te_attack[r3]).type(torch.LongTensor)\n",
    "\n",
    "r4 = np.arange(len(test_data))\n",
    "# np.random.shuffle(r4)\n",
    "\n",
    "check_test_data_tensor = torch.from_numpy(test_data[r4]).type(torch.FloatTensor)\n",
    "check_test_label_tensor = torch.from_numpy(test_label[r4]).type(torch.LongTensor)\n",
    "\n",
    "print(len(check_train_trainset_data_tensor))\n",
    "print(len(check_train_attack_data_tensor))\n",
    "print(len(check_test_trainset_data_tensor))\n",
    "print(len(check_test_data_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# check train accuracy and test accuracy of attack model with correspond data\n",
    "\n",
    "attack_train_loss, attack_train_acc, attack_train_correct_sum = test_attack_softmax(check_train_trainset_data_tensor,check_train_trainset_label_tensor\n",
    "                                         ,check_train_attack_data_tensor,check_train_attack_label_tensor,net,attack_model,criterion,attack_criterion,optimizer,attack_optimizer,epoch,use_cuda)\n",
    "\n",
    "print ('attack_train_loss: {test_loss: .4f}, attack_train_acc: {test_acc: .4f}'.format(test_loss=attack_train_loss, test_acc=attack_train_acc))\n",
    "\n",
    "attack_test_loss, attack_test_acc, attack_test_correct_sum = test_attack_softmax(check_test_trainset_data_tensor,check_test_trainset_label_tensor\n",
    "                                         ,check_test_data_tensor,check_test_label_tensor,net,attack_model,criterion,attack_criterion,optimizer,attack_optimizer,epoch,use_cuda)\n",
    "\n",
    "print ('attack_test_loss: {test_loss: .4f}, attack_test_acc: {test_acc: .4f}'.format(test_loss=attack_test_loss, test_acc=attack_test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "check_test_trainset_data_tensor = torch.from_numpy(evaluate_train_data).type(torch.FloatTensor)\n",
    "check_test_trainset_label_tensor = torch.from_numpy(evaluate_train_label).type(torch.LongTensor)\n",
    "result_array_trainset_logits_tensor = torch.from_numpy(result_array_logits[:5000]).type(torch.FloatTensor)\n",
    "\n",
    "check_test_data_tensor = torch.from_numpy(evaluate_test_data).type(torch.FloatTensor)\n",
    "check_test_label_tensor = torch.from_numpy(evaluate_test_label).type(torch.LongTensor)\n",
    "result_array_testset_logits_tensor = torch.from_numpy(result_array_logits[5000:]).type(torch.FloatTensor)\n",
    "\n",
    "\n",
    "print(len(check_test_trainset_data_tensor))\n",
    "print(len(check_test_data_tensor))\n",
    "print(len(result_array_testset_logits_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "check_test_trainset_data_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "attack_test_loss, attack_test_acc, attack_test_correct_sum = test_attack_softmax_modify(check_test_trainset_data_tensor,check_test_trainset_label_tensor,result_array_trainset_logits_tensor\n",
    "                                         ,check_test_data_tensor,check_test_label_tensor,result_array_testset_logits_tensor,net,attack_model,criterion,attack_criterion,optimizer,attack_optimizer,epoch,use_cuda)\n",
    "\n",
    "print ('attack_test_loss: {test_loss: .4f}, attack_test_acc: {test_acc: .4f}'.format(test_loss=attack_test_loss, test_acc=attack_test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "net.eval()\n",
    "inputs = x_evaluate_attacker_tensor[0:50]\n",
    "inputs = inputs.cuda()\n",
    "inputs = torch.autograd.Variable(inputs)\n",
    "outputs,h_layer = net(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "outputs.size(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "one_hot_tr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "one_hot_tr = torch.from_numpy((np.zeros((inputs.size()[0],inputs.size(1))))).cuda().type(torch.cuda.FloatTensor)\n",
    "target_one_hot_tr = one_hot_tr.scatter_(1, torch.cat((check_test_trainset_label_tensor,check_test_label_tensor)).type(torch.cuda.LongTensor).view([-1,1]).data,1)\n",
    "\n",
    "infer_input_one_hot = torch.autograd.Variable(target_one_hot_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "predict_origin.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "batch_size = 100\n",
    "attack_model.eval()\n",
    "\n",
    "# softmax = nn.Softmax()\n",
    "\n",
    "losses = AverageMeter()\n",
    "top1 = AverageMeter()\n",
    "\n",
    "sum_correct = 0.0\n",
    "\n",
    "# f_evaluate_logits_tensor = torch.from_numpy(result_array_logits).type(torch.FloatTensor)\n",
    "\n",
    "# f_evaluate=np.sort(result_array,axis=1)\n",
    "f_evaluate_tensor = torch.from_numpy(result_array).type(torch.FloatTensor)\n",
    "# f_evaluate_tensor = torch.from_numpy(origin_array).type(torch.FloatTensor)\n",
    "# f_evaluate_tensor = torch.from_numpy(f_evaluate_origin).type(torch.FloatTensor)\n",
    "\n",
    "# comb_targets= torch.cat((check_test_trainset_label_tensor,check_test_label_tensor)).view([-1,1]).type(torch.cuda.FloatTensor)\n",
    "comb_targets = y_evaluate_attacker_tensor.cuda()\n",
    "att_labels = np.zeros(f_evaluate_tensor.size()[0])\n",
    "\n",
    "# att_labels = np.zeros(f_evaluate_prob_tensor.size()[0])\n",
    "att_labels [:5000] =1.0\n",
    "att_labels [5000:] =0.0\n",
    "# att_labels [:2000] =1.0\n",
    "# att_labels [2000:] =0.0\n",
    "is_member_labels_tensor = torch.from_numpy(att_labels).type(torch.FloatTensor)\n",
    "    \n",
    "len_t =  (len(f_evaluate_tensor)//batch_size)\n",
    "print('len_t: ', len_t)\n",
    "\n",
    "\n",
    "list_attack_output = []\n",
    "for ind in range(len_t):\n",
    "    # measure data loading time\n",
    "    inputs = f_evaluate_tensor[ind*batch_size:(ind+1)*batch_size]\n",
    "    targets = comb_targets[ind*batch_size:(ind+1)*batch_size]\n",
    "\n",
    "    \n",
    "    one_hot_tr = torch.from_numpy((np.zeros((inputs.size()[0],inputs.size(1))))).cuda().type(torch.cuda.FloatTensor)\n",
    "    target_one_hot_tr = one_hot_tr.scatter_(1, targets.type(torch.cuda.LongTensor).view([-1,1]).data,1)\n",
    "\n",
    "    infer_input_one_hot = torch.autograd.Variable(target_one_hot_tr)\n",
    "    \n",
    "#     attack_output = attack_model(inputs,_,infer_input_one_hot).view([-1])\n",
    "    attack_output, _ = attack_model(inputs,_,infer_input_one_hot)\n",
    "    attack_output = attack_output.view([-1])\n",
    "#     .view([-1])\n",
    "#     break\n",
    "    is_member_labels = is_member_labels_tensor[ind*batch_size:(ind+1)*batch_size]\n",
    "    if use_cuda:\n",
    "        is_member_labels = is_member_labels.cuda()\n",
    "\n",
    "    v_is_member_labels = torch.autograd.Variable(is_member_labels)\n",
    "\n",
    "    loss = attack_criterion(attack_output, v_is_member_labels)\n",
    "\n",
    "    # measure accuracy and record loss\n",
    "    #prec1,p5 = accuracy(attack_output.data, v_is_member_labels.data, topk=(1,2))\n",
    "    list_attack_output.append(attack_output.data.cpu().numpy())\n",
    "    prec1=np.mean(np.equal((attack_output.data.cpu().numpy() >0.5),(v_is_member_labels.data.cpu().numpy()> 0.5)))\n",
    "    losses.update(loss.data, inputs.size()[0])\n",
    "    top1.update(prec1, inputs.size()[0])\n",
    "#     print('attack_output: ', attack_output.shape, 'v_is_member_labels: ', v_is_member_labels.shape)\n",
    "    correct = np.sum(np.equal((attack_output.data.cpu().numpy().reshape(-1) > 0.5),(v_is_member_labels.data.cpu().numpy()> 0.5)))\n",
    "#     print(\"correct: \", correct)\n",
    "    sum_correct += correct\n",
    "#     break\n",
    "    # plot progress\n",
    "    if ind%100==0:\n",
    "        print  ('({batch}/{size}) | Loss: {loss:.4f} | top1: {top1: .4f} '.format(\n",
    "                batch=ind + 1,\n",
    "                size=len_t,\n",
    "                loss=losses.avg,\n",
    "                top1=top1.avg,\n",
    "                ))\n",
    "\n",
    "test_loss = losses.avg\n",
    "test_acc = top1.avg\n",
    "accurate_acc = sum_correct/10000.0\n",
    "print ('evaluate loss: {test_loss: .4f}, evaluate accuracy: {test_acc: .4f}, accurate accuracy: {accurate_acc: .4f}, sum correct: {sum_correct: .1f}'.format(test_loss=test_loss, test_acc=test_acc, accurate_acc=accurate_acc,sum_correct=sum_correct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "list_attack_output_array = np.asarray(list_attack_output)\n",
    "v_is_member_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "list_attack_output_arrayx = list_attack_output_array.reshape(-1)\n",
    "list_attack_output_arrayx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "list_attack_output_array[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "list_attack_output_arrayx[0,100:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "pyplot.plot(list_attack_output_arrayx.reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "########evaluate the performance of defense's attack model on modified data#######\n",
    "\n",
    "defense_model.eval()\n",
    "\n",
    "# softmax = nn.Softmax()\n",
    "\n",
    "losses = AverageMeter()\n",
    "top1 = AverageMeter()\n",
    "\n",
    "sum_correct = 0.0\n",
    "\n",
    "# f_evaluate_logits_tensor = torch.from_numpy(result_array_logits).type(torch.FloatTensor)\n",
    "\n",
    "f_evaluate=np.sort(result_array,axis=1)\n",
    "# f_evaluate=np.sort(origin_array,axis=1)\n",
    "# f_evaluate=np.sort(f_evaluate_origin,axis=1) \n",
    "f_evaluate_tensor = torch.from_numpy(f_evaluate).type(torch.FloatTensor)\n",
    "\n",
    "att_labels = np.zeros(f_evaluate_tensor.size()[0])\n",
    "\n",
    "# att_labels = np.zeros(f_evaluate_prob_tensor.size()[0])\n",
    "att_labels [:5000] =1.0\n",
    "att_labels [5000:] =0.0\n",
    "is_member_labels_tensor = torch.from_numpy(att_labels).type(torch.FloatTensor)\n",
    "    \n",
    "len_t =  (len(f_evaluate_tensor)//batch_size)\n",
    "print('len_t: ', len_t)\n",
    "\n",
    "list_attack_output = []\n",
    "for ind in range(len_t):\n",
    "    # measure data loading time\n",
    "    inputs = f_evaluate_tensor[ind*batch_size:(ind+1)*batch_size]\n",
    "#     targets = labels[ind*batch_size:(ind+1)*batch_size]\n",
    "\n",
    "    attack_output, attack_output_h = defense_model(inputs)\n",
    "#     .view([-1])\n",
    "#     break\n",
    "    is_member_labels = is_member_labels_tensor[ind*batch_size:(ind+1)*batch_size]\n",
    "    if use_cuda:\n",
    "        is_member_labels = is_member_labels.cuda()\n",
    "\n",
    "    v_is_member_labels = torch.autograd.Variable(is_member_labels)\n",
    "\n",
    "    loss = defense_criterion(attack_output, v_is_member_labels)\n",
    "\n",
    "    # measure accuracy and record loss\n",
    "    #prec1,p5 = accuracy(attack_output.data, v_is_member_labels.data, topk=(1,2))\n",
    "    list_attack_output.append(attack_output.data.cpu().numpy())\n",
    "    prec1=np.mean(np.equal((attack_output.data.cpu().numpy() >0.5),(v_is_member_labels.data.cpu().numpy()> 0.5)))\n",
    "    losses.update(loss.data, inputs.size()[0])\n",
    "    top1.update(prec1, inputs.size()[0])\n",
    "#     print('attack_output: ', attack_output.shape, 'v_is_member_labels: ', v_is_member_labels.shape)\n",
    "    correct = np.sum(np.equal((attack_output.data.cpu().numpy().reshape(-1) >0.5),(v_is_member_labels.data.cpu().numpy()> 0.5)))\n",
    "#     print(\"correct: \", correct)\n",
    "    sum_correct += correct\n",
    "#     break\n",
    "    # plot progress\n",
    "    if ind%100==0:\n",
    "        print  ('({batch}/{size}) | Loss: {loss:.4f} | top1: {top1: .4f} '.format(\n",
    "                batch=ind + 1,\n",
    "                size=len_t,\n",
    "                loss=losses.avg,\n",
    "                top1=top1.avg,\n",
    "                ))\n",
    "\n",
    "test_loss = losses.avg\n",
    "test_acc = top1.avg\n",
    "accurate_acc = sum_correct/10000.0\n",
    "print ('evaluate loss: {test_loss: .4f}, evaluate accuracy: {test_acc: .4f}, accurate accuracy: {accurate_acc: .4f}, sum correct: {sum_correct: .1f}'.format(test_loss=test_loss, test_acc=test_acc, accurate_acc=accurate_acc,sum_correct=sum_correct))\n",
    "\n",
    "# (1/157) | Loss: 0.2482 | top1:  0.6953 \n",
    "# (101/157) | Loss: 0.2485 | top1:  0.6144 \n",
    "# evaluate loss:  0.2496, evaluate accuracy:  0.5018, accurate accuracy:  0.5021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Get the saved location npz model res\n",
    "\n",
    "# evaluation_noise_filepath=\"/home/nux219/ML_Privacy_Regularization_master/checkpoints_texas_prune_little_model_Memguard/attack/noise_data_No_defense_20_epoch_6_40000_evaluation.npz\"\n",
    "\n",
    "# npz_defense=np.load(evaluation_noise_filepath)\n",
    "# f_evaluate_defense=npz_defense['defense_output']\n",
    "# f_evaluate_origin=npz_defense['tc_output']\n",
    "\n",
    "# f_evaluate_defense_logits=npz_defense['defense_output_logits']\n",
    "# f_evaluate_logits_origin=npz_defense['tc_output_logits']\n",
    "\n",
    "# f_evaluate_origin_score=npz_defense['predict_origin']\n",
    "# f_evaluate_defense_score=npz_defense['predict_modified']\n",
    "\n",
    "dir_path = './model_logits/Modify1_defense_100_epoch_78/'\n",
    "# txt_path = '/media/SSD_NVMe_1T/prune_model/model_params/resnet18_v2_ori_2_50/'\n",
    "if not os.path.exists(dir_path):\n",
    "    os.mkdir(dir_path)\n",
    "# txt_path = dir_path + 'f_evaluate_defense_logits.txt'\n",
    "# np.savetxt(txt_path, f_evaluate_defense_logits, fmt='%f', delimiter=',')\n",
    "# print(f_evaluate_defense_logits.shape)\n",
    "\n",
    "txt_path = dir_path + 'f_evaluate_origin_logits.txt'\n",
    "np.savetxt(txt_path, f_evaluate_logits_origin, fmt='%f', delimiter=',')\n",
    "print(f_evaluate_logits_origin.shape)\n",
    "\n",
    "# txt_path = dir_path + 'f_evaluate_defense.txt'\n",
    "# np.savetxt(txt_path, f_evaluate_defense, fmt='%f', delimiter=',')\n",
    "# print(f_evaluate_defense.shape)\n",
    "\n",
    "txt_path = dir_path + 'f_evaluate_origin.txt'\n",
    "np.savetxt(txt_path, f_evaluate_origin, fmt='%f', delimiter=',')\n",
    "print(f_evaluate_origin.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "txt_path = dir_path + 'predict_origin.txt'\n",
    "np.savetxt(txt_path, predict_origin, fmt='%f', delimiter=',')\n",
    "print(predict_origin.shape)\n",
    "\n",
    "# txt_path = dir_path + 'predict_defense.txt'\n",
    "# np.savetxt(txt_path, predict_modified, fmt='%f', delimiter=',')\n",
    "# print(predict_modified.shape)\n",
    "\n",
    "txt_path = dir_path + 'y_evaluate.txt'\n",
    "np.savetxt(txt_path, y_evaluate_attacker, fmt='%f', delimiter=',')\n",
    "print(y_evaluate_attacker.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "scenario='full'\n",
    "if scenario=='full':\n",
    "    predict_result_origin=np.where(predict_origin > 0.5, 1, 0)\n",
    "    predict_result_defense=np.where(predict_modified > 0.5, 1, 0)\n",
    "else:\n",
    "    raise NotImplementedError\n",
    "\n",
    "epsilon_value_list=[\"1.0\",\"0.7\",\"0.5\",\"0.3\",\"0.1\",\"0.0\"]\n",
    "# epsilon_value_list=[\"0.0\"]\n",
    "epsilon_value_list=[float(t) for t in epsilon_value_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "f_evaluate_noise = result_array\n",
    "# f_evaluate_origin = origin_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "count = 0\n",
    "for i in np.arange(f_evaluate_origin.shape[0]):\n",
    "    if np.equal(predict_result_origin[i] , label_evaluate_attacker[i]):\n",
    "        count+=1\n",
    "    \n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "f_evaluate_origin[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "pyplot.plot(predict_result_origin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# scenario='full'\n",
    "# if scenario=='full':\n",
    "#     predict_result_origin=np.where(predict_origin > 0.5, 1, 0)\n",
    "#     predict_result_defense=np.where(predict_modified > 0.5, 1, 0)\n",
    "# else:\n",
    "#     raise NotImplementedError\n",
    "\n",
    "# epsilon_value_list=[\"1.0\",\"0.7\",\"0.5\",\"0.3\",\"0.1\",\"0.0\"]\n",
    "# epsilon_value_list=[float(t) for t in epsilon_value_list]\n",
    "\n",
    "inference_accuracy_list=[]\n",
    "\n",
    "for epsilon_value in epsilon_value_list: \n",
    "    inference_accuracy=0.0\n",
    "\n",
    "    np.random.seed(100)  \n",
    "    for i in np.arange(f_evaluate_origin.shape[0]):\n",
    "        distortion_noise=np.sum(np.abs(f_evaluate_origin[i,:]-f_evaluate_noise[i,:]))\n",
    "        \n",
    "        p_value=0.0\n",
    "        if np.abs(predict_origin[i]-0.5)<=np.abs(predict_modified[i]-0.5):\n",
    "            p_value=0.0\n",
    "        else:\n",
    "            p_value=min(epsilon_value/distortion_noise,1.0)\n",
    "        \n",
    "        if predict_result_origin[i]==label_evaluate_attacker[i]:\n",
    "            inference_accuracy+=1.0-p_value\n",
    "        if predict_result_defense[i]==label_evaluate_attacker[i]:\n",
    "            inference_accuracy+=p_value\n",
    "#         print('distortion_noise: ', distortion_noise, ' p_value: ',p_value,' inference_accuracy: ',inference_accuracy)\n",
    "    inference_accuracy_list.append(inference_accuracy/(float(f_evaluate_origin.shape[0])))\n",
    "#     break\n",
    "    \n",
    "print(\"Budget list: {}\".format(epsilon_value_list))\n",
    "print(\"inference accuracy list: {}\".format(inference_accuracy_list))\n",
    "\n",
    "# Budget list: [1.0, 0.7, 0.5, 0.3, 0.1, 0.0]\n",
    "# inference accuracy list: [0.5021911142220747, 0.5048992830892228, 0.5120250427638868, 0.5286259040624035, 0.5731544218872452, 0.60825]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# strong sort noise result\n",
    "# NN model\n",
    "# Budget list: [1.0, 0.7, 0.5, 0.3, 0.1, 0.0]\n",
    "# inference accuracy list: [0.646396630378386, 0.6569747528528351, 0.6640105377520257, 0.6710463226512157, 0.6780821075504057, 0.6816]\n",
    "\n",
    "# NSH model\n",
    "# Budget list: [1.0, 0.7, 0.5, 0.3, 0.1, 0.0]\n",
    "# inference accuracy list: [0.5397111203340036, 0.5949816170842677, 0.631815299292593, 0.6689281014857144, 0.7064427004952366, 0.7252]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "predict_result_origin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# test_sample_id = 1\n",
    "# max_label=np.argmax(f_evaluate[test_sample_id,:])\n",
    "# origin_value=np.copy(f_evaluate[test_sample_id,:]).reshape(1,user_label_dim)\n",
    "# origin_value_logits=np.copy(f_evaluate_logits[test_sample_id,:]).reshape(1,user_label_dim)\n",
    "# label_mask_array[0,:]=0.0\n",
    "# label_mask_array[0,max_label]=1.0\n",
    "# label_mask_tonser = torch.from_numpy(label_mask_array).type(torch.FloatTensor).cuda()\n",
    "# sample_f_logits=np.copy(origin_value_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# sample_f_logits_tensor = torch.from_numpy(sample_f_logits).type(torch.FloatTensor).requires_grad_()\n",
    "# sample_f_logits_tensor = sample_f_logits_tensor.cuda()\n",
    "# sample_f_tensor = softmax(sample_f_logits_tensor)\n",
    "# result_predict_scores_initial, sample_f_h =defense_model(sample_f_tensor)\n",
    "# result_predict_scores_initial = result_predict_scores_initial.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# loss1 = torch.abs(sample_f_h)\n",
    "# loss1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# correct_label = torch.sum(label_mask_tonser * sample_f_tensor, 1)\n",
    "# wrong_label = torch.max((1-label_mask_tonser) * sample_f_tensor - 1e8*label_mask_tonser,1).values\n",
    "# loss2 = F.relu(wrong_label-correct_label)\n",
    "# loss2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# loss3= torch.sum(torch.abs(sample_f_tensor - torch.from_numpy(origin_value).type(torch.FloatTensor).cuda())) #L-1 norm\n",
    "# loss3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# loss = c1 * loss1 + c2 * loss2 + c3 * loss3\n",
    "# gradient_values = torch.autograd.grad(loss, sample_f_tensor)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# if np.abs(result_predict_scores_initial-0.5)<=1e-5:\n",
    "#         success_fraction+=1.0\n",
    "#         result_array[test_sample_id,:]=origin_value[0,back_index[test_sample_id,:]]\n",
    "#         result_array_logits[test_sample_id,:]=origin_value_logits[0,back_index[test_sample_id,:]]\n",
    "# #         continue\n",
    "# last_iteration_result=np.copy(origin_value)[0,back_index[test_sample_id,:]]\n",
    "# last_iteration_result_logits=np.copy(origin_value_logits)[0,back_index[test_sample_id,:]]\n",
    "# success=True\n",
    "# c3=0.1\n",
    "# iterate_time=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# while success==True: \n",
    "#     sample_f=np.copy(origin_value_logits)\n",
    "#     j=1\n",
    "#     result_max_label=-1\n",
    "#     result_predict_scores=result_predict_scores_initial\n",
    "# #         sample_f_tensor = torch.from_numpy(sample_f).type(torch.FloatTensor).requires_grad_()\n",
    "# #         sample_f_tensor = softmax(sample_f_tensor).cuda()\n",
    "#     while j<max_iteration and (max_label!=result_max_label or (result_predict_scores-0.5)*(result_predict_scores_initial-0.5)>0):\n",
    "#         _, sample_f_h =defense_model(sample_f_tensor)\n",
    "#         loss1 = torch.abs(sample_f_h)\n",
    "\n",
    "#         correct_label = torch.sum(label_mask_tonser * sample_f_tensor, 1)\n",
    "#         wrong_label = torch.max((1-label_mask_tonser) * sample_f_tensor - 1e8*label_mask_tonser,1).values\n",
    "#         loss2 = F.relu(wrong_label-correct_label)\n",
    "\n",
    "#         loss3= torch.sum(torch.abs(sample_f_tensor - torch.from_numpy(origin_value).type(torch.FloatTensor).cuda())) #L-1 norm\n",
    "#         loss = c1 * loss1 + c2 * loss2 + c3 * loss3\n",
    "#         gradient_values = torch.autograd.grad(loss, sample_f_tensor)[0]\n",
    "#         gradient_valuesx = gradient_values/torch.norm(gradient_values)\n",
    "\n",
    "#         sample_f_logits_tensor = sample_f_logits_tensor-0.1*gradient_valuesx\n",
    "#         sample_f_tensor = softmax(sample_f_logits_tensor)\n",
    "#         result_predict_scores, _ = defense_model(sample_f_tensor)\n",
    "#         result_predict_scores = result_predict_scores.item()\n",
    "#         result_max_label = torch.argmax(sample_f_tensor).item()\n",
    "#         j+=1\n",
    "#     if max_label!=result_max_label:\n",
    "#         if iterate_time==1:\n",
    "#             print(\"failed sample for label not same for id: {},c3:{} not add noise\".format(test_sample_id,c3))\n",
    "#             success_fraction-=1.0\n",
    "#         break \n",
    "#     result_predict_scores, _ = defense_model(sample_f_tensor)\n",
    "#     if ((result_predict_scores.item()-0.5)*(result_predict_scores_initial-0.5))>0:\n",
    "#         if iterate_time==1:\n",
    "#             print(\"max iteration reached with id: {}, max score: {}, prediction_score: {}, c3: {}, not add noise\".format(test_sample_id,np.amax(softmax(sample_f)),result_predict_scores,c3))\n",
    "#         break\n",
    "#     last_iteration_result[:]=sample_f_tensor.data.cpu().numpy()[0,back_index[test_sample_id,:]]\n",
    "#     last_iteration_result_logits[:]=sample_f_logits_tensor.data.cpu().numpy()[0,back_index[test_sample_id,:]]\n",
    "#     iterate_time+=1 \n",
    "#     c3=c3*10\n",
    "#     if c3>100000:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "last_iteration_result_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# test_data = X[int((train_classifier_ratio+train_attack_ratio)*len_train):]\n",
    "# test_label = Y[int((train_classifier_ratio+train_attack_ratio)*len_train):]\n",
    "# test_data_tensor = torch.from_numpy(test_data).type(torch.FloatTensor)\n",
    "# test_label_tensor = torch.from_numpy(test_label).type(torch.LongTensor)\n",
    "\n",
    "# print('test_data_tensor: ',len(test_data_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model = Texas()\n",
    "model = torch.nn.DataParallel(model).cuda()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "train_classifier_data_tensor = torch.from_numpy(train_classifier_data).type(torch.FloatTensor)\n",
    "train_classifier_label_tensor = torch.from_numpy(train_classifier_label).type(torch.LongTensor)\n",
    "\n",
    "test_data_tensor = torch.from_numpy(test_data).type(torch.FloatTensor)\n",
    "test_label_tensor = torch.from_numpy(test_label).type(torch.LongTensor)\n",
    "\n",
    "print('train_classifier_data_tensor: ',len(train_classifier_data_tensor))\n",
    "print('test_data_tensor: ',len(test_data_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "resume='./checkpoints_texas_prune_little_model_test/No_defense_20_epoch_6'\n",
    "print('==> Resuming from checkpoint..')\n",
    "assert os.path.isfile(resume), 'Error: no checkpoint directory found!'\n",
    "checkpoint = os.path.dirname(resume)\n",
    "checkpoint = torch.load(resume)\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "epoch = 0\n",
    "test_loss, final_test_acc = test(torch.from_numpy(test_data).type(torch.FloatTensor) ,torch.from_numpy(test_label).type(torch.LongTensor), model, criterion, epoch, use_cuda)\n",
    "\n",
    "print ('test_loss: {test_loss: .4f}, test_acc: {test_acc: .4f}'.format(test_loss=test_loss, test_acc=final_test_acc))\n",
    "\n",
    "trainset_loss, trainset_acc = test(torch.from_numpy(train_classifier_data).type(torch.FloatTensor) ,torch.from_numpy(train_classifier_label).type(torch.LongTensor), model, criterion, epoch, use_cuda)\n",
    "\n",
    "print ('trainset_loss: {trainset_loss: .4f}, trainset_acc: {trainset_acc: .4f}'.format(trainset_loss=trainset_loss, trainset_acc=trainset_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "sort_train_label_index = np.argsort(train_classifier_label)\n",
    "sort_train_label = train_classifier_label[sort_train_label_index]\n",
    "\n",
    "sort_train_data = train_classifier_data[sort_train_label_index]\n",
    "\n",
    "sort_train_label_bin = np.bincount(sort_train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "sort_test_label_index = np.argsort(test_label)\n",
    "sort_test_label = test_label[sort_test_label_index]\n",
    "\n",
    "sort_test_data = test_data[sort_test_label_index]\n",
    "\n",
    "sort_test_label_bin = np.bincount(sort_test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "sort_test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "sort_train_data_tensor = torch.from_numpy(sort_train_data).type(torch.FloatTensor)\n",
    "sort_train_label_tensor = torch.from_numpy(sort_train_label).type(torch.LongTensor)\n",
    "\n",
    "sort_test_data_tensor = torch.from_numpy(sort_test_data).type(torch.FloatTensor)\n",
    "sort_test_label_tensor = torch.from_numpy(sort_test_label).type(torch.LongTensor)\n",
    "\n",
    "print('train_classifier_data_tensor: ',len(sort_train_data_tensor))\n",
    "print('test_data_tensor: ',len(sort_test_data_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "trainset_loss, trainset_acc = test(sort_train_data_tensor ,sort_train_label_tensor, model, criterion, epoch, use_cuda)\n",
    "\n",
    "test_loss, final_test_acc = test(sort_test_data_tensor ,sort_test_label_tensor, model, criterion, epoch, use_cuda)\n",
    "\n",
    "print ('trainset_loss: {trainset_loss: .4f}, trainset_acc: {trainset_acc: .4f}'.format(trainset_loss=trainset_loss, trainset_acc=trainset_acc))\n",
    "\n",
    "print ('test_loss: {test_loss: .4f}, test_acc: {test_acc: .4f}'.format(test_loss=test_loss, test_acc=final_test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# load-attack model \n",
    "\n",
    "attack_model = InferenceAttack_HZ(100)\n",
    "attack_model = torch.nn.DataParallel(attack_model).cuda()\n",
    "attack_criterion = nn.MSELoss()\n",
    "attack_optimizer = optim.Adam(attack_model.parameters(),lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "resume_att='./checkpoints_texas_prune_little_model_test/No_defense_20_epoch_6_longtrain_attack_epoch50'\n",
    "print('==> Resuming attack model from checkpoint..')\n",
    "assert os.path.isfile(resume_att), 'Error: no checkpoint directory found!'\n",
    "checkpoint_att = os.path.dirname(resume_att)\n",
    "checkpoint_att = torch.load(resume_att)\n",
    "attack_model.load_state_dict(checkpoint_att['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Epoch: [49 | 100] , lr : 0.000100\n",
    "# (1/106) Data: 0.000s | Batch: 0.045s | | Loss: 0.2478 | top1:  0.5195 \n",
    "# (101/106) Data: 0.000s | Batch: 0.054s | | Loss: 0.2374 | top1:  0.5755 \n",
    "# train acc 0.5738897965245804\n",
    "# (1/106) Data: 0.000s | Batch: 0.033s | | Loss: 0.2637 | top1:  0.5312 \n",
    "# (101/106) Data: 0.000s | Batch: 0.031s | | Loss: 0.2585 | top1:  0.5075 \n",
    "# test acc 0.5080573295707709 0.5080573295707709"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "r1 = np.arange(len(train_classifier_data_tr_attack))\n",
    "np.random.shuffle(r1)\n",
    "\n",
    "check_train_trainset_data_tensor = torch.from_numpy(train_classifier_data_tr_attack[r1]).type(torch.FloatTensor)\n",
    "check_train_trainset_label_tensor = torch.from_numpy(train_classifier_label_tr_attack[r1]).type(torch.LongTensor)\n",
    "\n",
    "r2 = np.arange(len(train_attack_data))\n",
    "np.random.shuffle(r2)\n",
    "check_train_attack_data_tensor = torch.from_numpy(train_attack_data[r2]).type(torch.FloatTensor)\n",
    "check_train_attack_label_tensor = torch.from_numpy(train_attack_label[r2]).type(torch.LongTensor)\n",
    "\n",
    "r3 = np.arange(len(train_classifier_data_te_attack))\n",
    "np.random.shuffle(r3)\n",
    "\n",
    "check_test_trainset_data_tensor = torch.from_numpy(train_classifier_data_te_attack[r3]).type(torch.FloatTensor)\n",
    "check_test_trainset_label_tensor = torch.from_numpy(train_classifier_label_te_attack[r3]).type(torch.LongTensor)\n",
    "\n",
    "r4 = np.arange(len(test_data))\n",
    "np.random.shuffle(r4)\n",
    "\n",
    "check_test_data_tensor = torch.from_numpy(test_data[r4]).type(torch.FloatTensor)\n",
    "check_test_label_tensor = torch.from_numpy(test_label[r4]).type(torch.LongTensor)\n",
    "\n",
    "print(len(check_train_trainset_data_tensor))\n",
    "print(len(check_train_attack_data_tensor))\n",
    "print(len(check_test_trainset_data_tensor))\n",
    "print(len(check_test_data_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# check train accuracy and test accuracy of attack model with correspond data\n",
    "\n",
    "attack_train_loss, attack_train_acc, attack_train_correct_sum = test_attack(check_train_trainset_data_tensor,check_train_trainset_label_tensor\n",
    "                                         ,check_train_attack_data_tensor,check_train_attack_label_tensor,model,attack_model,criterion,attack_criterion,optimizer,attack_optimizer,epoch,use_cuda)\n",
    "\n",
    "print ('attack_train_loss: {test_loss: .4f}, attack_train_acc: {test_acc: .4f}'.format(test_loss=attack_train_loss, test_acc=attack_train_acc))\n",
    "\n",
    "attack_test_loss, attack_test_acc, attack_test_correct_sum = test_attack(check_test_trainset_data_tensor,check_test_trainset_label_tensor\n",
    "                                         ,check_test_data_tensor,check_test_label_tensor,model,attack_model,criterion,attack_criterion,optimizer,attack_optimizer,epoch,use_cuda)\n",
    "\n",
    "print ('attack_test_loss: {test_loss: .4f}, attack_test_acc: {test_acc: .4f}'.format(test_loss=attack_test_loss, test_acc=attack_test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "batch_size = 32 \n",
    "attack_test_loss, attack_test_acc, correct_sum = test_attack(check_test_trainset_data_tensor,check_test_trainset_label_tensor\n",
    "                                         ,check_test_data_tensor,check_test_label_tensor,model,attack_model,criterion,attack_criterion,optimizer,attack_optimizer,epoch,use_cuda)\n",
    "\n",
    "print ('attack_test_loss: {test_loss: .4f}, attack_test_acc: {test_acc: .4f}'.format(test_loss=attack_test_loss, test_acc=attack_test_acc))\n",
    "print('attack_test_acc: ', correct_sum / (len(check_test_trainset_label_tensor)*2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "attack_train_correct_sum "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "attack_train_correct_sum/len(check_train_trainset_data_tensor)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "len(check_test_data_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# trainset attack accuracy for trained set\n",
    "batch_size = 32 \n",
    "attack_trainset_loss, attack_trainset_acc, trainset_correct = attack_test_trainset(check_train_trainset_data_tensor,check_train_trainset_label_tensor\n",
    "                                         ,model,attack_model,criterion,attack_criterion,optimizer,attack_optimizer,epoch,use_cuda)\n",
    "# attack_trainset_loss = sum_correct / len(check_train_data_tensor)\n",
    "print ('attack_trainset_loss: {test_loss: .4f}, attack_trainset_acc: {test_acc: .4f}'.format(test_loss=attack_trainset_loss, test_acc=attack_trainset_acc))\n",
    "print('attack_trainset_acc: ', trainset_correct / len(check_train_trainset_data_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# trainset attack accuracy for trainset not trained in attack model\n",
    "batch_size = 32 \n",
    "attack_trainset_loss, attack_trainset_acc, trainset_correct = attack_test_trainset(check_test_trainset_data_tensor,check_test_trainset_label_tensor\n",
    "                                         ,model,attack_model,criterion,attack_criterion,optimizer,attack_optimizer,epoch,use_cuda)\n",
    "# attack_trainset_loss = sum_correct / len(check_train_data_tensor)\n",
    "print ('attack_trainset_loss: {test_loss: .4f}, attack_trainset_acc: {test_acc: .4f}'.format(test_loss=attack_trainset_loss, test_acc=attack_trainset_acc))\n",
    "print('attack_testset_acc: ', trainset_correct / len(check_test_trainset_data_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "trainset_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#attack accuracy for dataset not in trainset but trained in attack model\n",
    "batch_size = 32\n",
    "attack_testset_loss, attack_testset_acc, testset_correct = attack_test_testset(check_train_attack_data_tensor,check_train_attack_label_tensor\n",
    "                                         ,model,attack_model,criterion,attack_criterion,optimizer,attack_optimizer,epoch,use_cuda)\n",
    "# attack_trainset_loss = sum_correct / len(check_train_data_tensor)\n",
    "print ('attack_testset_loss: {test_loss: .4f}, attack_testset_acc: {test_acc: .4f}'.format(test_loss=attack_testset_loss, test_acc=attack_testset_acc))\n",
    "print('testset_correct_acc: ', testset_correct / len(check_train_attack_label_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#attack accuracy for testset not trained in attack model\n",
    "batch_size = 32\n",
    "attack_testset_loss, attack_testset_acc, testset_correct = attack_test_testset(check_test_data_tensor,check_test_label_tensor\n",
    "                                         ,model,attack_model,criterion,attack_criterion,optimizer,attack_optimizer,epoch,use_cuda)\n",
    "# attack_trainset_loss = sum_correct / len(check_train_data_tensor)\n",
    "print ('attack_testset_loss: {test_loss: .4f}, attack_testset_acc: {test_acc: .4f}'.format(test_loss=attack_testset_loss, test_acc=attack_testset_acc))\n",
    "print('testset_correct_acc: ', testset_correct / len(check_test_data_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "testset_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "len(check_test_label_tensor) + len(check_train_attack_label_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# train_classifier_label_tr_attack\n",
    "# train_attack_label\n",
    "# train_classifier_label_te_attack\n",
    "# test_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "sort_train_label_tr_attack_index = np.argsort(train_classifier_label_tr_attack)\n",
    "sort_train_label_tr_attack = train_classifier_label_tr_attack[sort_train_label_tr_attack_index]\n",
    "\n",
    "sort_train_data_tr_attack = train_classifier_data_tr_attack[sort_train_label_tr_attack_index]\n",
    "\n",
    "sort_train_label_tr_attack_bin = np.bincount(sort_train_label_tr_attack)\n",
    "# sort_train_label_tr_attack_bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "sort_train_label_tr_attack_bin_list = []\n",
    "for i in range(len(sort_train_label_tr_attack_bin)):\n",
    "    sort_train_label_tr_attack_bin_list.append(sort_train_label_tr_attack_bin[i])\n",
    "print(sort_train_label_tr_attack_bin_list)\n",
    "\n",
    "# [73, 61, 203, 70, 83, 78, 44, 39, 53, 61, 92, 132, 84, 43, 485, 53, 114, 61, 162, 109, 69, 317, 94, 48, 178, 64, 54, 78, 92, 74, 466, 88, 132, 93, 302, 70, 193, 116, 98, 107, 83, 76, 106, 106, 50, 242, 54, 434, 38, 180, 184, 264, 53, 57, 58, 54, 59, 245, 135, 186, 61, 87, 61, 58, 78, 518, 247, 52, 97, 52, 58, 85, 529, 55, 68, 133, 60, 56, 184, 67, 61, 210, 69, 68, 103, 52, 62, 68, 69, 57, 88, 254, 103, 351, 493, 149, 49, 441, 563, 53]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "sort_train_label_te_attack_index = np.argsort(train_classifier_label_te_attack)\n",
    "sort_train_label_te_attack = train_classifier_label_te_attack[sort_train_label_te_attack_index]\n",
    "\n",
    "sort_train_data_te_attack = train_classifier_data_te_attack[sort_train_label_te_attack_index]\n",
    "\n",
    "sort_train_label_te_attack_bin = np.bincount(sort_train_label_te_attack)\n",
    "# sort_train_label_te_attack_bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "sort_train_label_te_attack_bin_list = []\n",
    "for i in range(len(sort_train_label_te_attack_bin)):\n",
    "    sort_train_label_te_attack_bin_list.append(sort_train_label_te_attack_bin[i])\n",
    "print(sort_train_label_te_attack_bin_list)\n",
    "\n",
    "# [71, 64, 164, 63, 83, 81, 65, 57, 46, 66, 81, 149, 102, 51, 490, 50, 105, 44, 172, 115, 56, 320, 88, 43, 197, 45, 49, 81, 86, 71, 470, 47, 121, 100, 307, 73, 183, 125, 58, 94, 73, 102, 100, 114, 48, 221, 60, 447, 55, 194, 181, 269, 61, 65, 52, 68, 70, 275, 136, 151, 59, 94, 60, 47, 97, 573, 217, 56, 99, 53, 70, 49, 574, 39, 69, 142, 78, 41, 174, 61, 66, 214, 64, 71, 98, 55, 62, 75, 53, 74, 83, 276, 113, 296, 448, 158, 55, 417, 606, 55]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "sort_train_attack_label_index = np.argsort(train_attack_label)\n",
    "sort_train_attack_label = train_attack_label[sort_train_attack_label_index]\n",
    "\n",
    "sort_train_attack_data = train_attack_data[sort_train_attack_label_index]\n",
    "\n",
    "sort_train_attack_label_bin = np.bincount(sort_train_attack_label)\n",
    "# sort_train_attack_label_bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "sort_train_attack_label_bin_list = []\n",
    "for i in range(len(sort_train_attack_label_bin)):\n",
    "    sort_train_attack_label_bin_list.append(sort_train_attack_label_bin[i])\n",
    "print(sort_train_attack_label_bin_list)\n",
    "\n",
    "# [102, 107, 261, 108, 146, 127, 84, 80, 92, 97, 135, 174, 147, 69, 790, 93, 149, 72, 233, 162, 91, 521, 121, 80, 303, 111, 93, 113, 124, 96, 702, 121, 174, 137, 437, 104, 293, 160, 114, 175, 125, 130, 143, 160, 80, 376, 87, 643, 81, 274, 328, 427, 71, 87, 81, 84, 97, 361, 210, 246, 78, 106, 81, 75, 128, 778, 342, 87, 150, 70, 95, 87, 790, 65, 86, 187, 121, 88, 278, 81, 108, 335, 119, 108, 121, 77, 74, 91, 74, 98, 128, 371, 182, 458, 713, 218, 85, 613, 1003, 61]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "sort_test_label_index = np.argsort(test_label)\n",
    "sort_test_label = test_label[sort_test_label_index]\n",
    "\n",
    "sort_test_data = test_data[sort_test_label_index]\n",
    "\n",
    "sort_test_label_bin = np.bincount(sort_test_label)\n",
    "# sort_test_label_bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "sort_test_label_bin_list = []\n",
    "for i in range(len(sort_test_label_bin)):\n",
    "    sort_test_label_bin_list.append(sort_test_label_bin[i])\n",
    "print(sort_test_label_bin_list)\n",
    "\n",
    "# [95, 97, 248, 99, 122, 95, 75, 87, 71, 94, 151, 163, 172, 73, 723, 60, 157, 67, 278, 160, 118, 478, 140, 70, 310, 89, 114, 104, 126, 101, 679, 92, 187, 139, 462, 95, 320, 150, 115, 183, 133, 144, 161, 172, 95, 404, 103, 668, 84, 243, 320, 376, 77, 94, 80, 103, 87, 320, 223, 270, 93, 136, 97, 64, 145, 817, 345, 100, 170, 87, 121, 95, 794, 78, 90, 206, 111, 72, 261, 81, 77, 313, 105, 120, 110, 90, 101, 106, 80, 90, 122, 398, 183, 494, 691, 201, 81, 609, 874, 75]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# trainset and testset NOT used in attack training\n",
    "\n",
    "print(\"sort_train_label_te_attack_bin: \", sort_train_label_te_attack_bin_list)\n",
    "print(\"sort_test_label_bin_list: \", sort_test_label_bin_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# attack accuracy for each class for trainset and testset NOT used in attack training\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "len_class =  len(sort_train_label_te_attack_bin)\n",
    "sort_train_data_te_attack_acc = []\n",
    "sort_testset_class_attack_acc = []\n",
    "\n",
    "sort_train_data_te_attack_loss = []\n",
    "sort_testset_class_attack_loss = []\n",
    "\n",
    "sort_train_data_te_attack_correct = []\n",
    "sort_testset_class_attack_correct = []\n",
    "\n",
    "print('len_class: ', len_class)\n",
    "\n",
    "index_trainset = 0\n",
    "index_testset = 0\n",
    "\n",
    "for ind in range(len_class):\n",
    "\n",
    "    class_train_data_te_tensor = torch.from_numpy(sort_train_data_te_attack[index_trainset : (index_trainset+sort_train_label_te_attack_bin[ind])]).type(torch.FloatTensor)\n",
    "    class_train_label_te_tensor = torch.from_numpy(sort_train_label_te_attack[index_trainset:(index_trainset+sort_train_label_te_attack_bin[ind])]).type(torch.LongTensor)\n",
    "\n",
    "    class_test_data_tensor = torch.from_numpy(sort_test_data[index_testset : (index_testset+sort_test_label_bin[ind])]).type(torch.FloatTensor)\n",
    "    class_test_label_tensor = torch.from_numpy(sort_test_label[index_testset:(index_testset+sort_test_label_bin[ind])]).type(torch.LongTensor)\n",
    "    \n",
    "    index_trainset += sort_train_label_te_attack_bin[ind]\n",
    "    index_testset += sort_test_label_bin[ind]\n",
    "    \n",
    "    print('index_trainset: ', index_trainset)\n",
    "    print('index_testset: ', index_testset)\n",
    "    \n",
    "    attack_trainset_loss, attack_trainset_acc, trainset_correct = attack_test_trainset(class_train_data_te_tensor,class_train_label_te_tensor\n",
    "                                         ,model,attack_model,criterion,attack_criterion,optimizer,attack_optimizer,epoch,use_cuda)\n",
    "\n",
    "    attack_testset_loss, attack_testset_acc, testset_correct = attack_test_testset(class_test_data_tensor,class_test_label_tensor\n",
    "                                         ,model,attack_model,criterion,attack_criterion,optimizer,attack_optimizer,epoch,use_cuda)\n",
    "    \n",
    "    sort_train_data_te_attack_acc.append(attack_trainset_acc)\n",
    "    sort_testset_class_attack_acc.append(attack_testset_acc)\n",
    "\n",
    "    sort_train_data_te_attack_loss.append(attack_trainset_loss)\n",
    "    sort_testset_class_attack_loss.append(attack_testset_loss)\n",
    "\n",
    "    sort_train_data_te_attack_correct.append(trainset_correct)\n",
    "    sort_testset_class_attack_correct.append(testset_correct)\n",
    "    \n",
    "total_trainset_correct = sum(sort_train_data_te_attack_correct)\n",
    "total_testset_correct = sum(sort_testset_class_attack_correct)\n",
    "\n",
    "print('total_trainset_correct: ', total_trainset_correct)\n",
    "print('total_testset_correct: ', total_testset_correct)\n",
    "\n",
    "print('sort_trainset_class_attack_correct: ', sort_train_data_te_attack_correct)\n",
    "print('sort_testset_class_attack_correct: ', sort_testset_class_attack_correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# attack accuracy on trainset NOT used in attack training\n",
    "\n",
    "sort_acc_traindata_te_attack_class = sort_train_data_te_attack_correct/sort_train_label_te_attack_bin\n",
    "\n",
    "sort_acc_traindata_te_attack_class_list = []\n",
    "for i in range(len(sort_acc_traindata_te_attack_class)):\n",
    "    sort_acc_traindata_te_attack_class_list.append(sort_acc_traindata_te_attack_class[i])\n",
    "\n",
    "print(sort_acc_traindata_te_attack_class_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# attack accuracy on testset NOT used in attack training\n",
    "\n",
    "sort_acc_test_te_class_attack_class = sort_testset_class_attack_correct/sort_test_label_bin\n",
    "\n",
    "sort_acc_test_te_class_attack_class_list = []\n",
    "for i in range(len(sort_acc_test_te_class_attack_class)):\n",
    "    sort_acc_test_te_class_attack_class_list.append(sort_acc_test_te_class_attack_class[i])\n",
    "\n",
    "print(sort_acc_test_te_class_attack_class_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print(\"sort_train_tr_attack_label_bin: \", sort_train_label_tr_attack_bin_list)\n",
    "print(\"sort_test_tr_attack_label_bin: \", sort_train_attack_label_bin_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# attack accuracy for each class for trainset and testset trained for the attack\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "len_class =  len(sort_train_label_tr_attack_bin)\n",
    "sort_train_data_tr_attack_acc = []\n",
    "sort_test_tr_attack_acc = []\n",
    "\n",
    "sort_train_data_tr_attack_loss = []\n",
    "sort_test_tr_attack_loss = []\n",
    "\n",
    "sort_train_data_tr_attack_correct = []\n",
    "sort_test_tr_attack_correct = []\n",
    "\n",
    "print('len_class: ', len_class)\n",
    "\n",
    "index_trainset = 0\n",
    "index_testset = 0\n",
    "\n",
    "for ind in range(len_class):\n",
    "\n",
    "    class_train_data_tr_tensor = torch.from_numpy(sort_train_data_tr_attack[index_trainset : (index_trainset+sort_train_label_tr_attack_bin[ind])]).type(torch.FloatTensor)\n",
    "    class_train_label_tr_tensor = torch.from_numpy(sort_train_label_tr_attack[index_trainset:(index_trainset+sort_train_label_tr_attack_bin[ind])]).type(torch.LongTensor)\n",
    "\n",
    "    class_test_data_tr_tensor = torch.from_numpy(sort_train_attack_data[index_testset : (index_testset+sort_train_attack_label_bin[ind])]).type(torch.FloatTensor)\n",
    "    class_test_label_tr_tensor = torch.from_numpy(sort_train_attack_label[index_testset:(index_testset+sort_train_attack_label_bin[ind])]).type(torch.LongTensor)\n",
    "    \n",
    "    index_trainset += sort_train_label_tr_attack_bin[ind]\n",
    "    index_testset += sort_train_attack_label_bin[ind]\n",
    "    \n",
    "    print('index_trainset: ', index_trainset)\n",
    "    print('index_testset: ', index_testset)\n",
    "    \n",
    "    attack_trainset_loss, attack_trainset_acc, trainset_correct = attack_test_trainset(class_train_data_tr_tensor,class_train_label_tr_tensor, model,attack_model,criterion,attack_criterion,optimizer,attack_optimizer,epoch,use_cuda)\n",
    "\n",
    "    attack_testset_loss, attack_testset_acc, testset_correct = attack_test_testset(class_test_data_tr_tensor,class_test_label_tr_tensor, model,attack_model,criterion,attack_criterion,optimizer,attack_optimizer,epoch,use_cuda)\n",
    "\n",
    "    \n",
    "    sort_train_data_tr_attack_acc.append(attack_trainset_acc)\n",
    "    sort_test_tr_attack_acc.append(attack_testset_acc)\n",
    "\n",
    "    sort_train_data_tr_attack_loss.append(attack_trainset_loss)\n",
    "    sort_test_tr_attack_loss.append(attack_testset_loss)\n",
    "\n",
    "    sort_train_data_tr_attack_correct.append(trainset_correct)\n",
    "    sort_test_tr_attack_correct.append(testset_correct)\n",
    "    \n",
    "total_trainset_tr_correct = sum(sort_train_data_tr_attack_correct)\n",
    "total_testset_tr_correct = sum(sort_test_tr_attack_correct)\n",
    "\n",
    "print('total_trainset_tr_correct: ', total_trainset_tr_correct)\n",
    "print('total_testset_tr_correct: ', total_testset_tr_correct)\n",
    "\n",
    "print('sort_trainset_class_tr_attack_correct: ', sort_train_data_tr_attack_correct)\n",
    "print('sort_testset_class_tr_attack_correct: ', sort_test_tr_attack_correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# attack accuracy on trainset used in attack training\n",
    "sort_acc_traindata_tr_attack_class = sort_train_data_tr_attack_correct/sort_train_label_tr_attack_bin\n",
    "\n",
    "sort_acc_traindata_tr_attack_class_list = []\n",
    "for i in range(len(sort_acc_traindata_tr_attack_class)):\n",
    "    sort_acc_traindata_tr_attack_class_list.append(sort_acc_traindata_tr_attack_class[i])\n",
    "\n",
    "print(sort_acc_traindata_tr_attack_class_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# attack accuracy on testset used in attack training\n",
    "sort_acc_test_tr_class_attack_class = sort_test_tr_attack_correct/sort_train_attack_label_bin\n",
    "\n",
    "sort_acc_test_tr_class_attack_class_list = []\n",
    "for i in range(len(sort_acc_test_tr_class_attack_class)):\n",
    "    sort_acc_test_tr_class_attack_class_list.append(sort_acc_test_tr_class_attack_class[i])\n",
    "\n",
    "print(sort_acc_test_tr_class_attack_class_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# attack accuracy for each class for all trainset and testset\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "len_class =  len(sort_train_label_bin)\n",
    "sort_trainset_class_attack_acc = []\n",
    "sort_testset_class_attack_acc = []\n",
    "\n",
    "sort_trainset_class_attack_loss = []\n",
    "sort_testset_class_attack_loss = []\n",
    "\n",
    "sort_trainset_class_attack_correct = []\n",
    "sort_testset_class_attack_correct = []\n",
    "\n",
    "print('len_class: ', len_class)\n",
    "\n",
    "index_trainset = 0\n",
    "index_testset = 0\n",
    "\n",
    "for ind in range(len_class):\n",
    "\n",
    "    class_train_data_tensor = torch.from_numpy(sort_train_data[index_trainset : (index_trainset+sort_train_label_bin[ind])]).type(torch.FloatTensor)\n",
    "    class_train_label_tensor = torch.from_numpy(sort_train_label[index_trainset:(index_trainset+sort_train_label_bin[ind])]).type(torch.LongTensor)\n",
    "\n",
    "    class_test_data_tensor = torch.from_numpy(sort_test_data[index_testset : (index_testset+sort_test_label_bin[ind])]).type(torch.FloatTensor)\n",
    "    class_test_label_tensor = torch.from_numpy(sort_test_label[index_testset:(index_testset+sort_test_label_bin[ind])]).type(torch.LongTensor)\n",
    "    \n",
    "    index_trainset += sort_train_label_bin[ind]\n",
    "    index_testset += sort_test_label_bin[ind]\n",
    "    \n",
    "    print('index_trainset: ', index_trainset)\n",
    "    print('index_testset: ', index_testset)\n",
    "    \n",
    "    attack_trainset_loss, attack_trainset_acc, trainset_correct = attack_test_trainset(class_train_data_tensor,class_train_label_tensor\n",
    "                                         ,model,attack_model,criterion,attack_criterion,optimizer,attack_optimizer,epoch,use_cuda)\n",
    "\n",
    "    attack_testset_loss, attack_testset_acc, testset_correct = attack_test_testset(class_test_data_tensor,class_test_label_tensor\n",
    "                                         ,model,attack_model,criterion,attack_criterion,optimizer,attack_optimizer,epoch,use_cuda)\n",
    "    \n",
    "    sort_trainset_class_attack_acc.append(attack_trainset_acc)\n",
    "    sort_testset_class_attack_acc.append(attack_testset_acc)\n",
    "\n",
    "    sort_trainset_class_attack_loss.append(attack_trainset_loss)\n",
    "    sort_testset_class_attack_loss.append(attack_testset_loss)\n",
    "\n",
    "    sort_trainset_class_attack_correct.append(trainset_correct)\n",
    "    sort_testset_class_attack_correct.append(testset_correct)\n",
    "    \n",
    "total_trainset_correct = sum(sort_trainset_class_attack_correct)\n",
    "total_testset_correct = sum(sort_testset_class_attack_correct)\n",
    "\n",
    "print('total_trainset_correct: ', total_trainset_correct)\n",
    "print('total_testset_correct: ', total_testset_correct)\n",
    "\n",
    "print('sort_trainset_class_attack_correct: ', sort_trainset_class_attack_correct)\n",
    "print('sort_testset_class_attack_correct: ', sort_testset_class_attack_correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "sort_acc_train_class = sort_trainset_class_attack_correct/sort_train_label_bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# sort_acc_train_class\n",
    "sort_acc_train_class_list = []\n",
    "for i in range(len(sort_acc_train_class)):\n",
    "    sort_acc_train_class_list.append(sort_acc_train_class[i])\n",
    "\n",
    "print(sort_acc_train_class_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "sort_acc_test_class = sort_testset_class_attack_correct/sort_test_label_bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# sort_acc_test_class\n",
    "sort_acc_test_class_list = []\n",
    "for item in sort_acc_test_class:\n",
    "    sort_acc_test_class_list.append(item)\n",
    "    \n",
    "print(sort_acc_test_class_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "sort_class_attack_correct = sort_trainset_class_attack_correct + sort_testset_class_attack_correct\n",
    "print(sum(sort_class_attack_correct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from math import log\n",
    "\n",
    "# train data logits, prob, out\n",
    "\n",
    "batch_size = 128\n",
    "model.eval()\n",
    "sort_train_total_out = []\n",
    "softmax = nn.Softmax()\n",
    "len_t =  (len(sort_train_data_tensor)//batch_size)+1\n",
    "sort_train_logits = []\n",
    "sort_train_prob = []\n",
    "print('len_t: ', len_t)\n",
    "for ind in range(len_t):\n",
    "    # measure data loading time\n",
    "    inputs = sort_train_data_tensor[ind*batch_size:(ind+1)*batch_size]\n",
    "    targets = sort_train_label_tensor[ind*batch_size:(ind+1)*batch_size]\n",
    "#     print((ind+1)*batch_size)\n",
    "    if use_cuda:\n",
    "        inputs, targets = inputs.cuda(), targets.cuda()\n",
    "    inputs, targets = torch.autograd.Variable(inputs), torch.autograd.Variable(targets)\n",
    "\n",
    "    # compute output\n",
    "    outputs,_ = model(inputs)\n",
    "    outputs_value = outputs.data.cpu().numpy()\n",
    "#     for i in range(len(outputs_value)):\n",
    "#         sort_train_logits.append(outputs_value[i])\n",
    "#     print('outputs.shape: ',outputs_value.shape)\n",
    "    loss = criterion(outputs, targets)\n",
    "    prob_outputs = softmax(outputs)\n",
    "    prob_outputs_value = prob_outputs.data.cpu().numpy()\n",
    "#     for i in range(len(prob_outputs_value)):\n",
    "#         sort_train_prob.append(prob_outputs_value[i])\n",
    "#     print('prob_outputs_value: ', prob_outputs_value.shape)\n",
    "#     print(prob_outputs_value.shape)\n",
    "    for i in range(len(prob_outputs_value)):\n",
    "        sort_train_logits.append(outputs_value[i])\n",
    "        sort_train_prob.append(prob_outputs_value[i])\n",
    "        score = prob_outputs_value[i]\n",
    "        sum_s = 0.\n",
    "#         print('score.shape: ', score.shape)\n",
    "        for s in score:\n",
    "            sum_s = sum_s + s*log(s)\n",
    "#         print(sum_s)\n",
    "        ne = -1/log(100) * sum_s\n",
    "#         print(ne)\n",
    "        sort_train_total_out.append(ne)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "train_count = np.histogram(sort_train_total_out, bins=20)\n",
    "np.set_printoptions(suppress=True)\n",
    "print('train_count: ',train_count[0])\n",
    "print('train_count_bins: ' ,train_count[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "train_total_out_sort = np.sort(sort_train_total_out)\n",
    "train_count_center = []\n",
    "count = 0\n",
    "train_count_index = train_count[0]\n",
    "for i in range(len(train_count_index)):\n",
    "    if train_count_index[i] == 1:\n",
    "        train_count_center.append(train_total_out_sort[count])\n",
    "    else:\n",
    "        train_count_center.append(np.average(train_total_out_sort[count:(count+train_count_index[i]-1)]))\n",
    "    print(count, count+train_count_index[i]-1)\n",
    "    count += train_count_index[i]\n",
    "\n",
    "print(train_count_center)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "len(sort_train_logits)\n",
    "sort_train_logits_array = np.asarray(sort_train_logits)\n",
    "sort_train_logits_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "sort_train_prob_array = np.asarray(sort_train_prob)\n",
    "sort_train_prob_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "max(sort_train_logits_array[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print(len(sort_train_total_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "sort_train_label_bin = np.bincount(sort_train_label)\n",
    "print(sort_train_label_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "sort_train_label_bin_list = []\n",
    "for i in range(len(sort_train_label_bin)):\n",
    "    sort_train_label_bin_list.append(sort_train_label_bin[i])\n",
    "print(sort_train_label_bin_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "index = 0\n",
    "dir_path = './model_logits/No_defense_20_epoch_2_prune_99_retrain_epoch_99/'\n",
    "# txt_path = '/media/SSD_NVMe_1T/prune_model/model_params/resnet18_v2_ori_2_50/'\n",
    "if not os.path.exists(dir_path):\n",
    "    os.mkdir(dir_path)\n",
    "txt_path = dir_path + 'sort_train_logits_array/'\n",
    "if not os.path.exists(txt_path):\n",
    "    os.mkdir(txt_path)\n",
    "for i in range(len(sort_train_label_bin)): #len(sort_train_label_bin)\n",
    "    print(index)\n",
    "    temp_array = []\n",
    "    temp_range = sort_train_label_bin[i]\n",
    "    temp_array = sort_train_logits_array[index:index+temp_range]\n",
    "    index += temp_range\n",
    "    np.savetxt(txt_path+'class_'+str(i)+'.txt', temp_array, fmt='%f', delimiter=',')\n",
    "    print(temp_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "index = 0\n",
    "dir_path = './model_logits/No_defense_20_epoch_2_prune_99_retrain_epoch_99/'\n",
    "# txt_path = '/media/SSD_NVMe_1T/prune_model/model_params/resnet18_v2_ori_2_50/'\n",
    "if not os.path.exists(dir_path):\n",
    "    os.mkdir(dir_path)\n",
    "txt_path = dir_path + 'sort_train_prob_array/'\n",
    "if not os.path.exists(txt_path):\n",
    "    os.mkdir(txt_path)\n",
    "for i in range(len(sort_train_label_bin)): #len(sort_train_label_bin)\n",
    "    print(index)\n",
    "    temp_array = []\n",
    "    temp_range = sort_train_label_bin[i]\n",
    "    temp_array = sort_train_prob_array[index:index+temp_range]\n",
    "    index += temp_range\n",
    "    np.savetxt(txt_path+'class_'+str(i)+'.txt', temp_array, fmt='%f', delimiter=',')\n",
    "    print(temp_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "batch_size = 128\n",
    "model.eval()\n",
    "\n",
    "sort_train_acc = []\n",
    "sort_train_loss = []\n",
    "sort_correct = []\n",
    "\n",
    "index = 0\n",
    "losses = AverageMeter()\n",
    "top1 = AverageMeter()\n",
    "top5 = AverageMeter()\n",
    "\n",
    "for ind in range(len(sort_train_label_bin)):\n",
    "    # measure data loading time\n",
    "    inputs = sort_train_data_tensor[index:(index+sort_train_label_bin[ind])]\n",
    "    targets = sort_train_label_tensor[index:(index+sort_train_label_bin[ind])]\n",
    "    index += sort_train_label_bin[ind]\n",
    "#     print('inputs.shape: ', inputs.shape)\n",
    "#     print('targets.shape: ', targets.shape)\n",
    "#     print('index: ', index)\n",
    "    if use_cuda:\n",
    "        inputs, targets = inputs.cuda(), targets.cuda()\n",
    "    inputs, targets = torch.autograd.Variable(inputs), torch.autograd.Variable(targets)\n",
    "\n",
    "    # compute output\n",
    "    outputs,_ = model(inputs)\n",
    "    \n",
    "    loss = criterion(outputs, targets)\n",
    "    \n",
    "    # measure accuracy and record loss\n",
    "    prec1, prec5 = accuracy(outputs.data, targets.data, topk=(1, 5))\n",
    "    \n",
    "    output = outputs.data\n",
    "    target = targets.data\n",
    "    _, pred = output.topk(1, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred)) \n",
    "    correct_number = correct[0].view(-1).float().sum(0).item()\n",
    "    sort_correct.append(correct_number)\n",
    "    \n",
    "    sort_train_acc.append(prec1.item())\n",
    "    sort_train_loss.append(loss.item())\n",
    "    \n",
    "    losses.update(loss.data, inputs.size()[0])\n",
    "    top1.update(prec1, inputs.size()[0])\n",
    "    top5.update(prec5, inputs.size()[0])\n",
    "#     print('prec1: ', prec1)\n",
    "#     print('loss: ', loss)\n",
    "#     break\n",
    "\n",
    "print('sort_train_acc: ', sort_train_acc)\n",
    "print('sort_train_loss: ', sort_train_loss)\n",
    "print('sort_correct: ', sort_correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "sum(sort_correct)/len(sort_train_total_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "output = outputs.data\n",
    "target = targets.data\n",
    "batch_size = target.size(0)\n",
    "_, pred = output.topk(5, 1, True, True)\n",
    "pred = pred.t()\n",
    "correct = pred.eq(target.view(1, -1).expand_as(pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "correct.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "correct[0].view(-1).float().sum(0).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "sort_train_label[143]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "len(sort_train_label_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "np.std(sort_train_total_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "len(sort_train_total_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "len(sort_test_label_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# test data logits, prob, out\n",
    "batch_size = 128\n",
    "\n",
    "model.eval()\n",
    "sort_test_total_out = []\n",
    "sort_test_logits = []\n",
    "sort_test_prob = []\n",
    "softmax = nn.Softmax()\n",
    "len_t =  (len(sort_test_label_tensor)//batch_size)+1\n",
    "print(len_t)\n",
    "for ind in range(len_t):\n",
    "    # measure data loading time\n",
    "    inputs = sort_test_data_tensor[ind*batch_size:(ind+1)*batch_size]\n",
    "    targets = sort_test_label_tensor[ind*batch_size:(ind+1)*batch_size]\n",
    "    if use_cuda:\n",
    "        inputs, targets = inputs.cuda(), targets.cuda()\n",
    "    inputs, targets = torch.autograd.Variable(inputs), torch.autograd.Variable(targets)\n",
    "    \n",
    "    # compute output\n",
    "    outputs,_ = model(inputs)\n",
    "    outputs_value = outputs.data.cpu().numpy()\n",
    "#     loss = criterion(outputs, targets)\n",
    "    prob_outputs = softmax(outputs)\n",
    "    prob_outputs_value = prob_outputs.data.cpu().numpy()\n",
    "    for i in range(len(prob_outputs_value)):\n",
    "        sort_test_logits.append(outputs_value[i])\n",
    "        sort_test_prob.append(prob_outputs_value[i])\n",
    "        score = prob_outputs_value[i]\n",
    "        sum_s = 0.\n",
    "#         print('score.shape: ', score.shape)\n",
    "        for s in score:\n",
    "            sum_s = sum_s + s*log(s)\n",
    "#         print(sum_s)\n",
    "        ne = -1/log(100) * sum_s\n",
    "#         print(ne)\n",
    "        sort_test_total_out.append(ne)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "test_count = np.histogram(sort_test_total_out, bins=20)\n",
    "np.set_printoptions(suppress=True)\n",
    "print('test_count: ',test_count[0])\n",
    "print('test_count_center: ' ,test_count[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "test_total_out_sort = np.sort(sort_test_total_out)\n",
    "test_count_center = []\n",
    "count = 0\n",
    "test_count_index = test_count[0]\n",
    "for i in range(len(test_count_index)):\n",
    "    if test_count_index[i] == 1:\n",
    "        test_count_center.append(test_total_out_sort[count])\n",
    "    else:\n",
    "        test_count_center.append(np.average(test_total_out_sort[count:(count+test_count_index[i]-1)]))\n",
    "    print(count, count+test_count_index[i]-1)\n",
    "    count += test_count_index[i]\n",
    "\n",
    "print(test_count_center)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "sort_test_logits_array = np.asarray(sort_test_logits)\n",
    "sort_test_logits_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "sort_test_prob_array = np.asarray(sort_test_prob)\n",
    "sort_test_prob_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "max(sort_test_logits_array[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "sort_test_label_bin = np.bincount(sort_test_label)\n",
    "print(sort_test_label_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "sum(sort_test_label_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "sort_test_label_bin_list = []\n",
    "for i in range(len(sort_test_label_bin)):\n",
    "    sort_test_label_bin_list.append(sort_test_label_bin[i])\n",
    "print(sort_test_label_bin_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "sort_test_label[95:192]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "index = 0\n",
    "dir_path = './model_logits/No_defense_20_epoch_2_prune_99_retrain_epoch_99/'\n",
    "# txt_path = '/media/SSD_NVMe_1T/prune_model/model_params/resnet18_v2_ori_2_50/'\n",
    "if not os.path.exists(dir_path):\n",
    "    os.mkdir(dir_path)\n",
    "txt_path = dir_path + 'sort_test_logits_array/'\n",
    "if not os.path.exists(txt_path):\n",
    "    os.mkdir(txt_path)\n",
    "for i in range(len(sort_test_label_bin)): #len(sort_train_label_bin)\n",
    "    print(index)\n",
    "    temp_array = []\n",
    "    temp_range = sort_test_label_bin[i]\n",
    "    temp_array = sort_test_logits_array[index:index+temp_range]\n",
    "    index += temp_range\n",
    "    np.savetxt(txt_path+'class_'+str(i)+'.txt', temp_array, fmt='%f', delimiter=',')\n",
    "    print(temp_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "index = 0\n",
    "dir_path = './model_logits/No_defense_20_epoch_2_prune_99_retrain_epoch_99/'\n",
    "# txt_path = '/media/SSD_NVMe_1T/prune_model/model_params/resnet18_v2_ori_2_50/'\n",
    "if not os.path.exists(dir_path):\n",
    "    os.mkdir(dir_path)\n",
    "txt_path = dir_path + 'sort_test_prob_array/'\n",
    "if not os.path.exists(txt_path):\n",
    "    os.mkdir(txt_path)\n",
    "for i in range(len(sort_test_label_bin)): #len(sort_train_label_bin)\n",
    "    print(index)\n",
    "    temp_array = []\n",
    "    temp_range = sort_test_label_bin[i]\n",
    "    temp_array = sort_test_prob_array[index:index+temp_range]\n",
    "    index += temp_range\n",
    "    np.savetxt(txt_path+'class_'+str(i)+'.txt', temp_array, fmt='%f', delimiter=',')\n",
    "    print(temp_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "batch_size = 128\n",
    "model.eval()\n",
    "\n",
    "sort_test_acc = []\n",
    "sort_test_loss = []\n",
    "sort_test_correct = []\n",
    "\n",
    "index = 0\n",
    "losses = AverageMeter()\n",
    "top1 = AverageMeter()\n",
    "top5 = AverageMeter()\n",
    "\n",
    "for ind in range(len(sort_test_label_bin)):\n",
    "    # measure data loading time\n",
    "    inputs = sort_test_data_tensor[index:(index+sort_test_label_bin[ind])]\n",
    "    targets = sort_test_label_tensor[index:(index+sort_test_label_bin[ind])]\n",
    "    index += sort_test_label_bin[ind]\n",
    "#     print('inputs.shape: ', inputs.shape)\n",
    "#     print('targets.shape: ', targets.shape)\n",
    "#     print('index: ', index)\n",
    "    if use_cuda:\n",
    "        inputs, targets = inputs.cuda(), targets.cuda()\n",
    "    inputs, targets = torch.autograd.Variable(inputs), torch.autograd.Variable(targets)\n",
    "\n",
    "    # compute output\n",
    "    outputs,_ = model(inputs)\n",
    "    \n",
    "    loss = criterion(outputs, targets)\n",
    "    \n",
    "    # measure accuracy and record loss\n",
    "    prec1, prec5 = accuracy(outputs.data, targets.data, topk=(1, 5))\n",
    "    \n",
    "    output = outputs.data\n",
    "    target = targets.data\n",
    "    _, pred = output.topk(1, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred)) \n",
    "    correct_number = correct[0].view(-1).float().sum(0).item()\n",
    "    sort_test_correct.append(correct_number)\n",
    "    \n",
    "    sort_test_acc.append(prec1.item())\n",
    "    sort_test_loss.append(loss.item())\n",
    "    \n",
    "    losses.update(loss.data, inputs.size()[0])\n",
    "    top1.update(prec1, inputs.size()[0])\n",
    "    top5.update(prec5, inputs.size()[0])\n",
    "#     print('prec1: ', prec1)\n",
    "#     print('loss: ', loss)\n",
    "#     break\n",
    "\n",
    "print('sort_test_acc: ', sort_test_acc)\n",
    "print('sort_test_loss: ', sort_test_loss)\n",
    "print('sort_test_correct: ', sort_test_correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Get the saved location npz model res\n",
    "\n",
    "evaluation_noise_filepath=\"/home/nux219/ML_Privacy_Regularization_master/checkpoints_texas_prune_little_model_Memguard/attack/noise_data_No_defense_20_epoch_6_40000_evaluation.npz\"\n",
    "\n",
    "npz_defense=np.load(evaluation_noise_filepath)\n",
    "f_evaluate_defense=npz_defense['defense_output']\n",
    "f_evaluate_origin=npz_defense['tc_output']\n",
    "\n",
    "f_evaluate_defense_logits=npz_defense['defense_output_logits']\n",
    "f_evaluate_origin_logits=npz_defense['tc_output_logits']\n",
    "\n",
    "f_evaluate_origin_score=npz_defense['predict_origin']\n",
    "f_evaluate_defense_score=npz_defense['predict_modified']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "f_evaluate_defense_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "dir_path = './model_logits/location/'\n",
    "# txt_path = '/media/SSD_NVMe_1T/prune_model/model_params/resnet18_v2_ori_2_50/'\n",
    "if not os.path.exists(dir_path):\n",
    "    os.mkdir(dir_path)\n",
    "txt_path = dir_path + 'f_evaluate_defense_logits.txt'\n",
    "np.savetxt(txt_path, f_evaluate_defense_logits, fmt='%f', delimiter=',')\n",
    "print(f_evaluate_defense_logits.shape)\n",
    "\n",
    "txt_path = dir_path + 'f_evaluate_origin_logits.txt'\n",
    "np.savetxt(txt_path, f_evaluate_origin_logits, fmt='%f', delimiter=',')\n",
    "print(f_evaluate_origin_logits.shape)\n",
    "\n",
    "txt_path = dir_path + 'f_evaluate_defense.txt'\n",
    "np.savetxt(txt_path, f_evaluate_defense, fmt='%f', delimiter=',')\n",
    "print(f_evaluate_defense.shape)\n",
    "\n",
    "txt_path = dir_path + 'f_evaluate_origin.txt'\n",
    "np.savetxt(txt_path, f_evaluate_origin, fmt='%f', delimiter=',')\n",
    "print(f_evaluate_origin.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "np.mean(f_evaluate_origin_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "np.std(sort_test_total_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "len(sort_test_total_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# prune train\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from pruned_layers import *\n",
    "import torch.nn as nn\n",
    "from summary import summary\n",
    "\n",
    "\n",
    "def prune(net, method='std', q=5.0, s=0.25):\n",
    "    # Before the training started, generate the mask\n",
    "    assert isinstance(net, nn.Module)\n",
    "    for n, m in net.named_modules():\n",
    "        if isinstance(m, PrunedConv) or isinstance(m, PruneLinear):\n",
    "            if method == 'percentage':\n",
    "                m.prune_by_percentage(q)\n",
    "            elif method == 'std':\n",
    "                m.prune_by_std(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# from pruned_layers import *\n",
    "def prune_mod(net, method='std', q=5.0, s=0.25):\n",
    "    # Before the training started, generate the mask\n",
    "    assert isinstance(net, nn.Module)\n",
    "    for n, m in net.named_modules():\n",
    "        if isinstance(m, PrunedConv) or isinstance(m, PruneLinear):\n",
    "            if method == 'percentage':\n",
    "                m.prune_by_percentage_mod(q)\n",
    "            elif method == 'std':\n",
    "                m.prune_by_std(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def prune_train(train_data,labels, model, criterion, optimizer, epoch, use_cuda,num_batchs=999999):\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "    \n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    top5 = AverageMeter()\n",
    "    \n",
    "    \n",
    "    end = time.time()\n",
    "    len_t =  (len(train_data)//batch_size)-1\n",
    "    \n",
    "    for ind in range(len_t):\n",
    "        if ind > num_batchs:\n",
    "            break\n",
    "        # measure data loading time\n",
    "        inputs = train_data[ind*batch_size:(ind+1)*batch_size]\n",
    "        targets = labels[ind*batch_size:(ind+1)*batch_size]\n",
    "        data_time.update(time.time() - end)\n",
    "        if use_cuda:\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "        inputs, targets = torch.autograd.Variable(inputs), torch.autograd.Variable(targets)\n",
    "\n",
    "        # compute output\n",
    "        outputs,_ = model(inputs)\n",
    "        \n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        prec1, prec5 = accuracy(outputs.data, targets.data, topk=(1, 5))\n",
    "        losses.update(loss.data, inputs.size()[0])\n",
    "        top1.update(prec1, inputs.size()[0])\n",
    "        top5.update(prec5, inputs.size()[0])\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        for n, m in model.named_modules():\n",
    "            if isinstance(m, PrunedConv):\n",
    "                # tensor = m.mask\n",
    "                weight = m.conv.weight.data.cpu().numpy()\n",
    "                # weight_shape = weight.shape\n",
    "                tensor = np.ones_like(weight)\n",
    "                tensor = np.where(weight==0, 0, tensor)\n",
    "                # print('mask.shape: ', tensor.shape)\n",
    "                grad_tensor = m.conv.weight.grad.data.cpu().numpy()\n",
    "                # print('grad.shape: ', grad_tensor.shape)\n",
    "                grad_tensor = np.where(tensor==0, 0, grad_tensor)\n",
    "                m.conv.weight.grad.data = torch.from_numpy(grad_tensor).to(device)\n",
    "            elif isinstance(m, PruneLinear):\n",
    "                # tensor = m.mask\n",
    "                weight = m.linear.weight.data.cpu().numpy()\n",
    "                # weight_shape = weight.shape\n",
    "                tensor = np.ones_like(weight)\n",
    "                tensor = np.where(weight==0, 0, tensor)\n",
    "                # print('linear mask.shape: ', tensor.shape)\n",
    "                grad_tensor = m.linear.weight.grad.data.cpu().numpy()\n",
    "                # print('linear grad.shape: ', grad_tensor.shape)\n",
    "                grad_tensor = np.where(tensor==0, 0, grad_tensor)\n",
    "                m.linear.weight.grad.data = torch.from_numpy(grad_tensor).to(device)\n",
    "        \n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        # plot progress\n",
    "        if ind%100==0:\n",
    "            print  ('({batch}/{size}) Data: {data:.3f}s | Batch: {bt:.3f}s | | Loss: {loss:.4f} | top1: {top1: .4f} | top5: {top5: .4f}'.format(\n",
    "                    batch=ind + 1,\n",
    "                    size=len_t,\n",
    "                    data=data_time.avg,\n",
    "                    bt=batch_time.avg,\n",
    "                    loss=losses.avg,\n",
    "                    top1=top1.avg,\n",
    "                    top5=top5.avg,\n",
    "                    ))\n",
    "    return (losses.avg, top1.avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def prune_train_with_mask(train_data,labels, model, criterion, optimizer, epoch, use_cuda,num_batchs=999999):\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "    \n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    top5 = AverageMeter()\n",
    "    \n",
    "    \n",
    "    end = time.time()\n",
    "    len_t =  (len(train_data)//batch_size)-1\n",
    "    \n",
    "    for ind in range(len_t):\n",
    "        if ind > num_batchs:\n",
    "            break\n",
    "        # measure data loading time\n",
    "        inputs = train_data[ind*batch_size:(ind+1)*batch_size]\n",
    "        targets = labels[ind*batch_size:(ind+1)*batch_size]\n",
    "        data_time.update(time.time() - end)\n",
    "        if use_cuda:\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "        inputs, targets = torch.autograd.Variable(inputs), torch.autograd.Variable(targets)\n",
    "\n",
    "        # compute output\n",
    "        outputs,_ = model(inputs)\n",
    "        \n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        prec1, prec5 = accuracy(outputs.data, targets.data, topk=(1, 5))\n",
    "        losses.update(loss.data, inputs.size()[0])\n",
    "        top1.update(prec1, inputs.size()[0])\n",
    "        top5.update(prec5, inputs.size()[0])\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        for n, m in model.named_modules():\n",
    "            if isinstance(m, PrunedConv):\n",
    "                tensor = m.mask\n",
    "#                 weight = m.conv.weight.data.cpu().numpy()\n",
    "#                 # weight_shape = weight.shape\n",
    "# #                 tensor = np.ones_like(weight)\n",
    "# #                 tensor = np.where(weight==0, 0, tensor)\n",
    "# #                 print('mask.shape: ', tensor.shape)\n",
    "                grad_tensor = m.conv.weight.grad.data.cpu().numpy()\n",
    "#                 # print('grad.shape: ', grad_tensor.shape)\n",
    "                grad_tensor = np.where(tensor==0, 0, grad_tensor)\n",
    "                m.conv.weight.grad.data = torch.from_numpy(grad_tensor).to(device)\n",
    "#                 m.conv.weight.grad.data = torch.mul(m.conv.weight.grad.data, m.mask)\n",
    "            elif isinstance(m, PruneLinear):\n",
    "                tensor = m.mask\n",
    "#                 weight = m.linear.weight.data.cpu().numpy()\n",
    "                # weight_shape = weight.shape\n",
    "#                 tensor = np.ones_like(weight)\n",
    "#                 tensor = np.where(weight==0, 0, tensor)\n",
    "#                 print('linear mask.shape: ', tensor.shape)\n",
    "                grad_tensor = m.linear.weight.grad.data.cpu().numpy()\n",
    "                # print('linear grad.shape: ', grad_tensor.shape)\n",
    "                grad_tensor = np.where(tensor==0, 0, grad_tensor)\n",
    "                m.linear.weight.grad.data = torch.from_numpy(grad_tensor).to(device)\n",
    "#                 m.linear.weight.grad.data = torch.mul(m.linear.weight.grad.data, m.mask)\n",
    "            else:\n",
    "                pass\n",
    "        \n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        # plot progress\n",
    "        if ind%100==0:\n",
    "            print  ('({batch}/{size}) Data: {data:.3f}s | Batch: {bt:.3f}s | | Loss: {loss:.4f} | top1: {top1: .4f} | top5: {top5: .4f}'.format(\n",
    "                    batch=ind + 1,\n",
    "                    size=len_t,\n",
    "                    data=data_time.avg,\n",
    "                    bt=batch_time.avg,\n",
    "                    loss=losses.avg,\n",
    "                    top1=top1.avg,\n",
    "                    top5=top5.avg,\n",
    "                    ))\n",
    "    return (losses.avg, top1.avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def prune_train_max_var_mod5(train_data,labels, model, criterion, optimizer, mean_class,var_n, epoch, use_cuda,num_batchs=999999,num_class=100, alpha = 1.0):\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "    softmax = nn.Softmax()\n",
    "\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    losses_var = AverageMeter()\n",
    "    max_train_outputs = AverageMeter()\n",
    "    min_train_outputs = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    top5 = AverageMeter()\n",
    "    \n",
    "    print('alpha: ', alpha)\n",
    "    end = time.time()\n",
    "    len_t =  (len(train_data)//batch_size)\n",
    "    \n",
    "#     mean_class = torch.from_numpy(np.zeros((num_class,num_class))).cuda().type(torch.cuda.FloatTensor)\n",
    "#     mean_class = np.zeros((num_class,num_class))\n",
    "#     var_n = np.zeros(num_class)\n",
    "#     mean_var = torch.from_numpy(np.zeros((num_class))).cuda().type(torch.cuda.FloatTensor)\n",
    "#     mean_var = np.zeros((num_class))\n",
    " \n",
    "    \n",
    "    for ind in range(len_t):\n",
    "        if ind > num_batchs:\n",
    "            break\n",
    "        # measure data loading time\n",
    "        inputs = train_data[ind*batch_size:(ind+1)*batch_size]\n",
    "        targets = labels[ind*batch_size:(ind+1)*batch_size]\n",
    "        data_time.update(time.time() - end)\n",
    "        if use_cuda:\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "        inputs, targets = torch.autograd.Variable(inputs), torch.autograd.Variable(targets)\n",
    "\n",
    "        # compute output\n",
    "        outputs,_ = model(inputs)\n",
    "        \n",
    "        soft_outputs = softmax(outputs)\n",
    "        max_outputs = torch.max(soft_outputs,1).values\n",
    "        min_outputs = torch.min(max_outputs)\n",
    "        \n",
    "#         mean_outputs = torch.mean(soft_outputs,0)\n",
    "#         var = -torch.mean(torch.sum((soft_outputs - mean_outputs).pow(2),1))\n",
    "\n",
    "        for i in range(batch_size):\n",
    "#         var_n[targets[i]] = var_n[targets[i]] + 1\n",
    "            var_n[targets[i]] += 1\n",
    "    #         mean_class[targets[i]] = mean_class[targets[i]]*(var_n[targets[i]]-1)/var_n[targets[i]] + soft_outputs[i]/var_n[targets[i]]\n",
    "            mean_class[targets[i]] = mean_class[targets[i]]*(var_n[targets[i]]-1)/var_n[targets[i]] + soft_outputs[i].data.cpu().numpy()/var_n[targets[i]]\n",
    "    #         mean_var[targets[i]] = mean_var[targets[i]]*(var_n[targets[i]]-1)/var_n[targets[i]] + torch.sum((soft_outputs[i] - mean_class[targets[i]]).pow(2))/var_n[targets[i]]\n",
    "    #         mean_var[targets[i]] = mean_var[targets[i]]*(var_n[targets[i]]-1)/var_n[targets[i]] + torch.sum((soft_outputs[i] - torch.from_numpy(mean_class[targets[i]]).cuda()).pow(2))/var_n[targets[i]]\n",
    "\n",
    "        temp_mean = torch.from_numpy(mean_class).cuda()\n",
    "        mean_var = torch.sum((soft_outputs - temp_mean[targets]).pow(2),1)\n",
    "    \n",
    "        var = torch.mean(mean_var)*alpha\n",
    "#         var = -torch.mean(torch.from_numpy(mean_var)).cuda()*alpha\n",
    "#         var = torch.autograd.Variable(var)\n",
    "        loss = criterion(outputs, targets) + var \n",
    "        \n",
    "#         loss = criterion(outputs, targets)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        prec1, prec5 = accuracy(outputs.data, targets.data, topk=(1, 5))\n",
    "        losses.update(loss.data, inputs.size()[0])\n",
    "        losses_var.update(var.data, inputs.size()[0])\n",
    "        top1.update(prec1, inputs.size()[0])\n",
    "        top5.update(prec5, inputs.size()[0])\n",
    "        max_train_outputs.update(torch.mean(max_outputs), inputs.size()[0])\n",
    "        min_train_outputs.update(min_outputs, inputs.size()[0])\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward() #retain_graph=True)\n",
    "        \n",
    "                \n",
    "        for n, m in model.named_modules():\n",
    "            if isinstance(m, PrunedConv):\n",
    "                # tensor = m.mask\n",
    "                weight = m.conv.weight.data.cpu().numpy()\n",
    "                # weight_shape = weight.shape\n",
    "                tensor = np.ones_like(weight)\n",
    "                tensor = np.where(weight==0, 0, tensor)\n",
    "                # print('mask.shape: ', tensor.shape)\n",
    "                grad_tensor = m.conv.weight.grad.data.cpu().numpy()\n",
    "                # print('grad.shape: ', grad_tensor.shape)\n",
    "                grad_tensor = np.where(tensor==0, 0, grad_tensor)\n",
    "                m.conv.weight.grad.data = torch.from_numpy(grad_tensor).to(device)\n",
    "            elif isinstance(m, PruneLinear):\n",
    "                # tensor = m.mask\n",
    "                weight = m.linear.weight.data.cpu().numpy()\n",
    "                # weight_shape = weight.shape\n",
    "                tensor = np.ones_like(weight)\n",
    "                tensor = np.where(weight==0, 0, tensor)\n",
    "                # print('linear mask.shape: ', tensor.shape)\n",
    "                grad_tensor = m.linear.weight.grad.data.cpu().numpy()\n",
    "                # print('linear grad.shape: ', grad_tensor.shape)\n",
    "                grad_tensor = np.where(tensor==0, 0, grad_tensor)\n",
    "                m.linear.weight.grad.data = torch.from_numpy(grad_tensor).to(device)\n",
    "        \n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        # plot progress\n",
    "        if ind%20==0:\n",
    "            print  ('({batch}/{size}) Data: {data:.3f}s |Batch: {bt:.3f}s| Loss: {loss:.4f} |Var: {loss_var:.4f} | Max: {tmax:.4f} | Min: {tmin:.4f}| top1: {top1: .4f} | top5: {top5: .4f}'.format(\n",
    "                    batch=ind + 1,\n",
    "                    size=len_t,\n",
    "                    data=data_time.avg,\n",
    "                    bt=batch_time.avg,\n",
    "                    loss=losses.avg,\n",
    "                    loss_var=losses_var.avg,\n",
    "                    tmax = max_train_outputs.avg,\n",
    "                    tmin = min_train_outputs.avg,\n",
    "                    top1=top1.avg,\n",
    "                    top5=top5.avg,\n",
    "                    ))\n",
    "    return (losses.avg,losses_var.avg, top1.avg)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def prune_train_mod8(train_data,labels, model, criterion, optimizer, epoch, use_cuda,num_batchs=999999, alpha = 1.0):\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "    softmax = nn.Softmax()\n",
    "\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    losses_var = AverageMeter()\n",
    "    max_train_outputs = AverageMeter()\n",
    "    min_train_outputs = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    top5 = AverageMeter()\n",
    "    \n",
    "    print('alpha: ', alpha)\n",
    "    end = time.time()\n",
    "    len_t =  (len(train_data)//batch_size)-1\n",
    "    \n",
    "    for ind in range(len_t):\n",
    "        if ind > num_batchs:\n",
    "            break\n",
    "        # measure data loading time\n",
    "        inputs = train_data[ind*batch_size:(ind+1)*batch_size]\n",
    "        targets = labels[ind*batch_size:(ind+1)*batch_size]\n",
    "        data_time.update(time.time() - end)\n",
    "        if use_cuda:\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "        inputs, targets = torch.autograd.Variable(inputs), torch.autograd.Variable(targets)\n",
    "\n",
    "        # compute output\n",
    "        outputs,_ = model(inputs)\n",
    "        \n",
    "        soft_outputs = softmax(outputs)\n",
    "        max_outputs = torch.max(soft_outputs,1).values\n",
    "        min_outputs = torch.min(max_outputs)\n",
    "        \n",
    "        mean_outputs = torch.mean(soft_outputs)\n",
    "        var = torch.mean(torch.sum((soft_outputs - mean_outputs).pow(2),1))\n",
    "        \n",
    "        loss = criterion(outputs, targets) + alpha*var \n",
    "        \n",
    "#         loss = criterion(outputs, targets)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        prec1, prec5 = accuracy(outputs.data, targets.data, topk=(1, 5))\n",
    "        losses.update(loss.data, inputs.size()[0])\n",
    "        losses_var.update(var.data, inputs.size()[0])\n",
    "        top1.update(prec1, inputs.size()[0])\n",
    "        top5.update(prec5, inputs.size()[0])\n",
    "        max_train_outputs.update(torch.mean(max_outputs), inputs.size()[0])\n",
    "        min_train_outputs.update(min_outputs, inputs.size()[0])\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        for n, m in model.named_modules():\n",
    "            if isinstance(m, PrunedConv):\n",
    "                # tensor = m.mask\n",
    "                weight = m.conv.weight.data.cpu().numpy()\n",
    "                # weight_shape = weight.shape\n",
    "                tensor = np.ones_like(weight)\n",
    "                tensor = np.where(weight==0, 0, tensor)\n",
    "                # print('mask.shape: ', tensor.shape)\n",
    "                grad_tensor = m.conv.weight.grad.data.cpu().numpy()\n",
    "                # print('grad.shape: ', grad_tensor.shape)\n",
    "                grad_tensor = np.where(tensor==0, 0, grad_tensor)\n",
    "                m.conv.weight.grad.data = torch.from_numpy(grad_tensor).to(device)\n",
    "            elif isinstance(m, PruneLinear):\n",
    "                # tensor = m.mask\n",
    "                weight = m.linear.weight.data.cpu().numpy()\n",
    "                # weight_shape = weight.shape\n",
    "                tensor = np.ones_like(weight)\n",
    "                tensor = np.where(weight==0, 0, tensor)\n",
    "                # print('linear mask.shape: ', tensor.shape)\n",
    "                grad_tensor = m.linear.weight.grad.data.cpu().numpy()\n",
    "                # print('linear grad.shape: ', grad_tensor.shape)\n",
    "                grad_tensor = np.where(tensor==0, 0, grad_tensor)\n",
    "                m.linear.weight.grad.data = torch.from_numpy(grad_tensor).to(device)\n",
    "        \n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        # plot progress\n",
    "        if ind%100==0:\n",
    "            print  ('({batch}/{size}) Data: {data:.3f}s | Batch: {bt:.3f}s| Loss: {loss:.4f} | Var: {loss_var:.4f} | Max: {tmax:.4f} | Min: {tmin:.4f}| top1: {top1: .4f} | top5: {top5: .4f}'.format(\n",
    "                    batch=ind + 1,\n",
    "                    size=len_t,\n",
    "                    data=data_time.avg,\n",
    "                    bt=batch_time.avg,\n",
    "                    loss=losses.avg,\n",
    "                    loss_var=losses_var.avg,\n",
    "                    tmax = max_train_outputs.avg,\n",
    "                    tmin = min_train_outputs.avg,\n",
    "                    top1=top1.avg,\n",
    "                    top5=top5.avg,\n",
    "                    ))\n",
    "    return (losses.avg,losses_var.avg, top1.avg)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def prune_train_mod9(train_data,labels,untrain_data, untrain_labels, model, criterion, optimizer, epoch, use_cuda,num_batchs=999999, alpha = 1.0, beta = 1.0,lamd = 1.0):\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "    softmax = nn.Softmax()\n",
    "\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    losses_d = AverageMeter()\n",
    "    losses_a = AverageMeter()\n",
    "    losses_var = AverageMeter()\n",
    "    max_train_outputs = AverageMeter()\n",
    "    max_untrain_outputs = AverageMeter()\n",
    "    min_untrain_outputs = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    top5 = AverageMeter()\n",
    "    \n",
    "    print('alpha: ', alpha, ' beta: ', beta, ', lamd: ',lamd)\n",
    "    end = time.time()\n",
    "    len_t =  (len(train_data)//batch_size)-1\n",
    "    \n",
    "    for ind in range(len_t):\n",
    "        if ind > num_batchs:\n",
    "            break\n",
    "        # measure data loading time\n",
    "        inputs = train_data[ind*batch_size:(ind+1)*batch_size]\n",
    "        targets = labels[ind*batch_size:(ind+1)*batch_size]\n",
    "        r= np.arange(untrain_data.shape[0])\n",
    "        np.random.shuffle(r)\n",
    "        untrain_inputs = untrain_data[r[:batch_size]]\n",
    "        untrain_targets = untrain_labels[r[:batch_size]]\n",
    "\n",
    "        data_time.update(time.time() - end)\n",
    "        if use_cuda:\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "            untrain_inputs, untrain_targets = untrain_inputs.cuda(), untrain_targets.cuda()\n",
    "        inputs, targets = torch.autograd.Variable(inputs), torch.autograd.Variable(targets)\n",
    "        untrain_inputs, untrain_targets = torch.autograd.Variable(untrain_inputs), torch.autograd.Variable(untrain_targets)\n",
    "\n",
    "        # compute output\n",
    "        outputs,_ = model(inputs)\n",
    "        untrain_outputs,_ = model(untrain_inputs)\n",
    "\n",
    "        soft_outputs = softmax(outputs)\n",
    "        soft_untrain_outputs = softmax(untrain_outputs)\n",
    "\n",
    "        sort_soft_outputs,_ = torch.sort(soft_outputs)\n",
    "        sort_soft_untrain_outputs,_ = torch.sort(soft_untrain_outputs)\n",
    "        \n",
    "        mean_outputs = torch.mean(soft_outputs)\n",
    "        var = torch.mean(torch.sum((soft_outputs - mean_outputs).pow(2),1))\n",
    "        \n",
    "        loss_d = alpha*(torch.mean(torch.sum(torch.abs(sort_soft_outputs - sort_soft_untrain_outputs),1)))\n",
    "#         print('loss_d: ', loss_d)\n",
    "        max_soft_outputs = torch.max(soft_outputs,1).values\n",
    "        max_soft_untrain_outputs = torch.mean(torch.max(sort_soft_untrain_outputs,1).values)\n",
    "        min_soft_untrain_outputs = torch.min(torch.max(sort_soft_untrain_outputs,1).values)\n",
    "#         print('max_soft_outputs: ', max_soft_outputs)\n",
    "#         print('max_soft_untrain_outputs: ', max_soft_untrain_outputs)\n",
    "#         print('min_soft_untrain_outputs: ', min_soft_untrain_outputs)\n",
    "#         max_untrain_outputs = max_untrain_outputs + max_soft_untrain_outputs\n",
    "        loss_a = beta*torch.mean(torch.abs(max_soft_outputs - min_soft_untrain_outputs))\n",
    "#         print('loss_a: ', loss_a)\n",
    "        loss = criterion(outputs, targets) + loss_d + loss_a + lamd*var\n",
    "#         print('loss: ', loss)\n",
    "#         print('inputs.size()[0]: ', inputs.size()[0])\n",
    "#         loss = criterion(outputs, targets)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        prec1, prec5 = accuracy(outputs.data, targets.data, topk=(1, 5))\n",
    "        losses.update(loss.data, inputs.size()[0])\n",
    "        losses_d.update(loss_d.data, untrain_inputs.size()[0])\n",
    "        losses_a.update(loss_a.data, untrain_inputs.size()[0])\n",
    "        max_train_outputs.update(torch.mean(max_soft_outputs), inputs.size()[0])\n",
    "#         max_untrain_outputs.update(max_soft_untrain_outputs, 1)\n",
    "        max_untrain_outputs.update(max_soft_untrain_outputs, inputs.size()[0])\n",
    "        min_untrain_outputs.update(min_soft_untrain_outputs, inputs.size()[0])\n",
    "        top1.update(prec1, inputs.size()[0])\n",
    "        top5.update(prec5, inputs.size()[0])\n",
    "        losses_var.update(var.data, inputs.size()[0])\n",
    "        # compute gradient and do SGD step\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        for n, m in model.named_modules():\n",
    "            if isinstance(m, PrunedConv):\n",
    "                # tensor = m.mask\n",
    "                weight = m.conv.weight.data.cpu().numpy()\n",
    "                # weight_shape = weight.shape\n",
    "                tensor = np.ones_like(weight)\n",
    "                tensor = np.where(weight==0, 0, tensor)\n",
    "                # print('mask.shape: ', tensor.shape)\n",
    "                grad_tensor = m.conv.weight.grad.data.cpu().numpy()\n",
    "                # print('grad.shape: ', grad_tensor.shape)\n",
    "                grad_tensor = np.where(tensor==0, 0, grad_tensor)\n",
    "                m.conv.weight.grad.data = torch.from_numpy(grad_tensor).to(device)\n",
    "            elif isinstance(m, PruneLinear):\n",
    "                # tensor = m.mask\n",
    "                weight = m.linear.weight.data.cpu().numpy()\n",
    "                # weight_shape = weight.shape\n",
    "                tensor = np.ones_like(weight)\n",
    "                tensor = np.where(weight==0, 0, tensor)\n",
    "                # print('linear mask.shape: ', tensor.shape)\n",
    "                grad_tensor = m.linear.weight.grad.data.cpu().numpy()\n",
    "                # print('linear grad.shape: ', grad_tensor.shape)\n",
    "                grad_tensor = np.where(tensor==0, 0, grad_tensor)\n",
    "                m.linear.weight.grad.data = torch.from_numpy(grad_tensor).to(device)\n",
    "        \n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "        \n",
    "        # plot progress\n",
    "        if ind%100==0:\n",
    "            print  ('({batch}/{size})| Loss: {loss:.4f}| Loss_d: {loss_d:.4f}| Loss_a:{loss_a:.4f}|max train:{max_train:.4f}|max untrain:{max_untrain:.4f}|min: {min_untrain:.4f}|top1:{top1: .4f}|top5:{top5: .4f}'.format(\n",
    "                    batch=ind + 1,\n",
    "                    size=len_t,\n",
    "#                     data=data_time.avg,\n",
    "#                     bt=batch_time.avg,\n",
    "                    loss=losses.avg,\n",
    "                    loss_d = losses_d.avg,\n",
    "                    loss_a = losses_a.avg,\n",
    "                    max_train = max_train_outputs.avg,\n",
    "                    max_untrain = max_untrain_outputs.avg,    #torch.mean(max_untrain_outputs),\n",
    "                    min_untrain = min_untrain_outputs.avg,\n",
    "                    top1=top1.avg,\n",
    "                    top5=top5.avg,\n",
    "                    ))\n",
    "#             print  ('({batch}/{size}) Data: {data:.3f}s | Batch: {bt:.3f}s | | Loss: {loss:.4f} |  Loss_d: {loss_d:.4f} |  Loss_a: {loss_a:.4f} | top1: {top1: .4f} | top5: {top5: .4f}'.format(\n",
    "#                     batch=ind + 1,\n",
    "#                     size=len_t,\n",
    "#                     data=data_time.avg,\n",
    "#                     bt=batch_time.avg,\n",
    "#                     loss=losses.avg,\n",
    "#                     loss_d = losses_d.avg,\n",
    "#                     loss_a = losses_a.avg,\n",
    "\n",
    "#                     top1=top1.avg,\n",
    "#                     top5=top5.avg,\n",
    "#                     ))\n",
    "    return (losses.avg, losses_d.avg, losses_a.avg, losses_var.avg, top1.avg)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def prune4layer(net, method='std', q=5.0, s=0.25, last_q=0.0,last_s=0.25, l=4):\n",
    "    # Before the training started, generate the mask\n",
    "    i = 0\n",
    "    assert isinstance(net, nn.Module)\n",
    "    for n, m in net.named_modules():\n",
    "        if i < l:\n",
    "            if isinstance(m, PrunedConv) or isinstance(m, PruneLinear):\n",
    "                i += 1\n",
    "                if method == 'percentage':\n",
    "                    m.prune_by_percentage(q)\n",
    "                elif method == 'std':\n",
    "                    m.prune_by_std(s)\n",
    "        elif i >= l:\n",
    "            if isinstance(m, PrunedConv) or isinstance(m, PruneLinear):\n",
    "                i += 1\n",
    "                if method == 'percentage':\n",
    "                    m.prune_by_percentage(last_q)\n",
    "                elif method == 'std':\n",
    "                    m.prune_by_std(last_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "train_classifier_data_length  = 10000\n",
    "\n",
    "train_classifier_data = X[:train_classifier_data_length]\n",
    "train_classifier_label = Y[:train_classifier_data_length]\n",
    "test_data = X[40000:60000]\n",
    "test_label = Y[40000:60000]\n",
    "\n",
    "lr = 0.001\n",
    "state={}\n",
    "state['lr']=lr\n",
    "# net = Texas()\n",
    "net = Texas_2layer()\n",
    "net = torch.nn.DataParallel(net).cuda()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=lr)\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "resume='./checkpoints_texas_prune_little_model_defense/Small_2layer_No_defenss_epoch_40'\n",
    "print('==> Resuming from checkpoint..')\n",
    "assert os.path.isfile(resume), 'Error: no checkpoint directory found!'\n",
    "checkpoint = os.path.dirname(resume)\n",
    "checkpoint = torch.load(resume)\n",
    "net.load_state_dict(checkpoint['state_dict'])\n",
    "epoch = 0\n",
    "test_loss, final_test_acc = test(torch.from_numpy(test_data).type(torch.FloatTensor) ,torch.from_numpy(test_label).type(torch.LongTensor), net, criterion, epoch, use_cuda)\n",
    "\n",
    "print ('test_loss: {test_loss: .4f}, test_acc: {test_acc: .4f}'.format(test_loss=test_loss, test_acc=final_test_acc))\n",
    "\n",
    "trainset_loss, trainset_acc = test(torch.from_numpy(train_classifier_data).type(torch.FloatTensor) ,torch.from_numpy(train_classifier_label).type(torch.LongTensor), net, criterion, epoch, use_cuda)\n",
    "\n",
    "print ('trainset_loss: {trainset_loss: .4f}, trainset_acc: {trainset_acc: .4f}'.format(trainset_loss=trainset_loss, trainset_acc=trainset_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print(\"-----Summary before pruning-----\")\n",
    "summary(net)\n",
    "print(\"-------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# prune(net, method='percentage', q=98, s=0.75)\n",
    "prune4layer(net, method='percentage', q=99, last_q=0,l=2)\n",
    "# prune(net, method='std', q=98, s=2.6)\n",
    "test_loss, final_test_acc = test(torch.from_numpy(test_data).type(torch.FloatTensor) ,torch.from_numpy(test_label).type(torch.LongTensor), net, criterion, epoch, use_cuda)\n",
    "\n",
    "print ('test_loss: {test_loss: .4f}, test_acc: {test_acc: .4f}'.format(test_loss=test_loss, test_acc=final_test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print(\"-----Summary After one time pruning-----\")\n",
    "summary(net)\n",
    "print(\"-------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    global state\n",
    "    if epoch in [400, 1500]:\n",
    "#     if epoch in [100, 90]:\n",
    "        state['lr'] *= 10 \n",
    "#         state['lr'] *= 1\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = state['lr']\n",
    "    if epoch in [ 200,40,500, 700]:\n",
    "#     if epoch in [100, 90]:\n",
    "        state['lr'] *= 0.1 \n",
    "#         state['lr'] *= 1\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = state['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# lr = 0.001\n",
    "batch_size=128\n",
    "best_acc = 0.0\n",
    "best_epoch = 0\n",
    "alpha = 100\n",
    "epochs = 80\n",
    "gce_alpha = 0.333 \n",
    "criterion = GuidedComplementEntropy(gce_alpha)\n",
    "for epoch in range(0, epochs):\n",
    "#     if epoch == 3:\n",
    "#         alpha = 10.0\n",
    "    adjust_learning_rate(optimizer, epoch)\n",
    "    r= np.arange(len(train_classifier_data))\n",
    "    np.random.shuffle(r)\n",
    "    train_classifier_data = train_classifier_data[r]\n",
    "    train_classifier_label = train_classifier_label[r]\n",
    "    \n",
    "    train_classifier_data_tensor = torch.from_numpy(train_classifier_data).type(torch.FloatTensor)\n",
    "    train_classifier_label_tensor = torch.from_numpy(train_classifier_label).type(torch.LongTensor)\n",
    "    \n",
    "    test_data_tensor = torch.from_numpy(test_data).type(torch.FloatTensor)\n",
    "    test_label_tensor = torch.from_numpy(test_label).type(torch.LongTensor)\n",
    "    \n",
    "    print('\\nEpoch: [%d | %d] LR: %f' % (epoch + 1, epochs, state['lr']))\n",
    "        \n",
    "    train_loss,train_var, train_acc = prune_train_mod8(train_classifier_data_tensor,train_classifier_label_tensor, net, criterion, optimizer, epoch, use_cuda, alpha = alpha)\n",
    "    print ('train acc: %.4f, train loss: %.4f, train_var: %.4f'%(train_acc, train_loss,train_var))\n",
    "    test_loss,test_var, test_acc = test_mod8(test_data_tensor,test_label_tensor, net, criterion, epoch, use_cuda)\n",
    "    #privacy_loss, privacy_acc = privacy_train(trainloader,testloader,model,inferenece_model,criterion_attack,optimizer_mem,epoch,use_cuda)\n",
    "    \n",
    "    # append logger file\n",
    "    \n",
    "    is_best = test_acc > best_acc\n",
    "    best_acc = max(test_acc, best_acc)\n",
    "    print ('test acc: %.4f, test loss: %.4f, test_var: %.4f, best acc: %.4f'%(test_acc, test_loss, test_var, best_acc))\n",
    "    \n",
    "#     save model\n",
    "    if is_best or epoch+1 == epochs:\n",
    "        if best_acc > 54:\n",
    "            best_epoch = epoch+1;\n",
    "            save_checkpoint({\n",
    "                    'epoch': epoch + 1,\n",
    "                    'state_dict': net.state_dict(),\n",
    "                    'acc': test_acc,\n",
    "                    'best_acc': best_acc,\n",
    "                    'optimizer' : optimizer.state_dict(),\n",
    "                }, False, filename='Small_GCE_Modify9_var_min_alpha100_defense_epoch_7_prune_99_4_layer_50_defense_epoch_%d'%(epoch+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# lr = 0.00010\n",
    "batch_size=128\n",
    "best_acc = 0.0\n",
    "best_epoch = 0\n",
    "alpha = 0.0\n",
    "beta = 0.0\n",
    "lamd = 100.0\n",
    "epochs=120\n",
    "gce_alpha = 0.333 \n",
    "criterion = GuidedComplementEntropy(gce_alpha)\n",
    "for epoch in range(0, epochs):\n",
    "#     if epoch == 2:\n",
    "#         best_acc = 0.0\n",
    "#         alpha = 5.0\n",
    "#     adjust_learning_rate(optimizer, epoch)\n",
    "#     if epoch== 30:\n",
    "#         alpha = 3.0\n",
    "    \n",
    "    r= np.arange(len(small_train_classifier_data))\n",
    "    np.random.shuffle(r)\n",
    "    s_train_classifier_data = small_train_classifier_data[r]\n",
    "    s_train_classifier_label = small_train_classifier_label[r]\n",
    "    \n",
    "    train_classifier_data_tensor = torch.from_numpy(s_train_classifier_data).type(torch.FloatTensor)\n",
    "    train_classifier_label_tensor = torch.from_numpy(s_train_classifier_label).type(torch.LongTensor)\n",
    "    \n",
    "    r2= np.arange(len(train_attack_data)*0.125)\n",
    "    r2 = np.intc(r2) \n",
    "    untrain_classifier_data = train_attack_data[r2]\n",
    "    untrain_classifier_label = train_attack_label[r2]\n",
    "\n",
    "    untrain_classifier_data_tensor = torch.from_numpy(untrain_classifier_data).type(torch.FloatTensor)\n",
    "    untrain_classifier_label_tensor = torch.from_numpy(untrain_classifier_label).type(torch.LongTensor)\n",
    "    \n",
    "    \n",
    "    test_data_tensor = torch.from_numpy(test_data).type(torch.FloatTensor)\n",
    "    test_label_tensor = torch.from_numpy(test_label).type(torch.LongTensor)\n",
    "    \n",
    "    print('\\nEpoch: [%d | %d] LR: %f' % (epoch + 1, epochs, state['lr']))\n",
    "        \n",
    "    train_loss, train_loss_d,train_loss_a, train_loss_var,  train_acc = prune_train_mod9(train_classifier_data_tensor,train_classifier_label_tensor,\n",
    "                                                                   untrain_classifier_data_tensor, untrain_classifier_label_tensor, \n",
    "                                                                   net, criterion, optimizer, epoch, use_cuda, alpha = alpha, beta = beta, lamd = lamd)\n",
    "    print ('train acc: %.4f, train loss: %.4f, train distance loss: %.4f, train var loss: %.4f'%(train_acc, train_loss, train_loss_d,train_loss_var))\n",
    "    test_loss,test_var, test_acc = test_mod8(test_data_tensor,test_label_tensor, net, criterion, epoch, use_cuda)\n",
    "    #privacy_loss, privacy_acc = privacy_train(trainloader,testloader,model,inferenece_model,criterion_attack,optimizer_mem,epoch,use_cuda)\n",
    "    \n",
    "    # append logger file\n",
    "    \n",
    "    is_best = test_acc > best_acc\n",
    "    best_acc = max(test_acc, best_acc)\n",
    "    print ('test acc: %.4f, test loss: %.4f, test_var: %.4f, best acc: %.4f'%(test_acc, test_loss, test_var, best_acc))\n",
    "    \n",
    "#     save model\n",
    "    if is_best or epoch+1 == epochs:\n",
    "        if epoch > 0:\n",
    "#             best_acc = 0\n",
    "            best_epoch = epoch+1;\n",
    "            save_checkpoint({\n",
    "                    'epoch': epoch + 1,\n",
    "                    'state_dict': net.state_dict(),\n",
    "                    'acc': test_acc,\n",
    "                    'best_acc': best_acc,\n",
    "                    'optimizer' : optimizer.state_dict(),\n",
    "                }, False, filename='Small_GCE_Modify10_alpha3_beta0_lamd100_defense_prune_99_retrain1_epoch_%d'%(epoch+1))\n",
    "        else : best_acc = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# lr = 0.00010\n",
    "batch_size=128\n",
    "best_acc = 0.0\n",
    "best_epoch = 0\n",
    "alpha = 0.0\n",
    "beta = 0.0\n",
    "lamd = 100.0\n",
    "epochs=200\n",
    "gce_alpha = 0.333 \n",
    "criterion = GuidedComplementEntropy(gce_alpha)\n",
    "for epoch in range(120, epochs):\n",
    "#     if epoch == 2:\n",
    "#         best_acc = 0.0\n",
    "#         alpha = 5.0\n",
    "#     adjust_learning_rate(optimizer, epoch)\n",
    "#     if epoch== 30:\n",
    "#         alpha = 3.0\n",
    "    \n",
    "    r= np.arange(len(small_train_classifier_data))\n",
    "    np.random.shuffle(r)\n",
    "    s_train_classifier_data = small_train_classifier_data[r]\n",
    "    s_train_classifier_label = small_train_classifier_label[r]\n",
    "    \n",
    "    train_classifier_data_tensor = torch.from_numpy(s_train_classifier_data).type(torch.FloatTensor)\n",
    "    train_classifier_label_tensor = torch.from_numpy(s_train_classifier_label).type(torch.LongTensor)\n",
    "    \n",
    "    r2= np.arange(len(train_attack_data)*0.125)\n",
    "    r2 = np.intc(r2) \n",
    "    untrain_classifier_data = train_attack_data[r2]\n",
    "    untrain_classifier_label = train_attack_label[r2]\n",
    "\n",
    "    untrain_classifier_data_tensor = torch.from_numpy(untrain_classifier_data).type(torch.FloatTensor)\n",
    "    untrain_classifier_label_tensor = torch.from_numpy(untrain_classifier_label).type(torch.LongTensor)\n",
    "    \n",
    "    \n",
    "    test_data_tensor = torch.from_numpy(test_data).type(torch.FloatTensor)\n",
    "    test_label_tensor = torch.from_numpy(test_label).type(torch.LongTensor)\n",
    "    \n",
    "    print('\\nEpoch: [%d | %d] LR: %f' % (epoch + 1, epochs, state['lr']))\n",
    "        \n",
    "    train_loss, train_loss_d,train_loss_a, train_loss_var,  train_acc = prune_train_mod9(train_classifier_data_tensor,train_classifier_label_tensor,\n",
    "                                                                   untrain_classifier_data_tensor, untrain_classifier_label_tensor, \n",
    "                                                                   net, criterion, optimizer, epoch, use_cuda, alpha = alpha, beta = beta, lamd = lamd)\n",
    "    print ('train acc: %.4f, train loss: %.4f, train distance loss: %.4f, train var loss: %.4f'%(train_acc, train_loss, train_loss_d,train_loss_var))\n",
    "    test_loss,test_var, test_acc = test_mod8(test_data_tensor,test_label_tensor, net, criterion, epoch, use_cuda)\n",
    "    #privacy_loss, privacy_acc = privacy_train(trainloader,testloader,model,inferenece_model,criterion_attack,optimizer_mem,epoch,use_cuda)\n",
    "    \n",
    "    # append logger file\n",
    "    \n",
    "    is_best = test_acc > best_acc\n",
    "    best_acc = max(test_acc, best_acc)\n",
    "    print ('test acc: %.4f, test loss: %.4f, test_var: %.4f, best acc: %.4f'%(test_acc, test_loss, test_var, best_acc))\n",
    "    \n",
    "#     save model\n",
    "    if is_best or epoch+1 == epochs:\n",
    "        if epoch > 0:\n",
    "#             best_acc = 0\n",
    "            best_epoch = epoch+1;\n",
    "            save_checkpoint({\n",
    "                    'epoch': epoch + 1,\n",
    "                    'state_dict': net.state_dict(),\n",
    "                    'acc': test_acc,\n",
    "                    'best_acc': best_acc,\n",
    "                    'optimizer' : optimizer.state_dict(),\n",
    "                }, False, filename='Small_GCE_Modify10_alpha3_beta0_lamd100_defense_prune_99_retrain1_epoch_%d'%(epoch+1))\n",
    "        else : best_acc = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# finetune after pruning 98\n",
    "# Small_No_defense_20_epoch_12\n",
    "\n",
    "batch_size=128\n",
    "best_acc = 0.0\n",
    "best_epoch = 0\n",
    "epochs = 140\n",
    "for epoch in range(0, epochs):\n",
    "#     adjust_learning_rate(optimizer, epoch)\n",
    "#     r= np.arange(len(train_classifier_data))\n",
    "    np.random.shuffle(r)\n",
    "    train_classifier_data = train_classifier_data[r]\n",
    "    train_classifier_label = train_classifier_label[r]\n",
    "    \n",
    "    train_classifier_data_tensor = torch.from_numpy(train_classifier_data).type(torch.FloatTensor)\n",
    "    train_classifier_label_tensor = torch.from_numpy(train_classifier_label).type(torch.LongTensor)\n",
    "    \n",
    "    \n",
    "    test_data_tensor = torch.from_numpy(test_data).type(torch.FloatTensor)\n",
    "    test_label_tensor = torch.from_numpy(test_label).type(torch.LongTensor)\n",
    "    \n",
    "    print('\\nEpoch: [%d | %d] LR: %f' % (epoch + 1, epochs, state['lr']))\n",
    "        \n",
    "    train_loss, train_acc = prune_train(train_classifier_data_tensor,train_classifier_label_tensor, net, criterion, optimizer, epoch, use_cuda)\n",
    "    print ('train acc: %.4f, train loss: %.4f'%(train_acc, train_loss))\n",
    "    test_loss, test_acc = test(test_data_tensor,test_label_tensor, net, criterion, epoch, use_cuda)\n",
    "    #privacy_loss, privacy_acc = privacy_train(trainloader,testloader,model,inferenece_model,criterion_attack,optimizer_mem,epoch,use_cuda)\n",
    "    \n",
    "    # append logger file\n",
    "    \n",
    "    is_best = test_acc > best_acc\n",
    "    best_acc = max(test_acc, best_acc)\n",
    "    print ('test acc: %.4f, test loss: %.4f, best acc: %.4f'%(test_acc, test_loss, best_acc))\n",
    "    \n",
    "    # save model\n",
    "    if is_best or epoch+1 == epochs:\n",
    "        if best_acc > 54:\n",
    "            best_epoch = epoch+1;\n",
    "            save_checkpoint({\n",
    "                    'epoch': epoch + 1,\n",
    "                    'state_dict': net.state_dict(),\n",
    "                    'acc': test_acc,\n",
    "                    'best_acc': best_acc,\n",
    "                    'optimizer' : optimizer.state_dict(),\n",
    "                }, False, filename='Small_No_defense_20_epoch_12_prune_98_retrain_epoch_%d'%(epoch+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print(\"-----Summary After fine tune pruning-----\")\n",
    "summary(net)\n",
    "print(\"-------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "attack_model = InferenceAttack_HZ(100)\n",
    "attack_model = torch.nn.DataParallel(attack_model).cuda()\n",
    "attack_criterion = nn.MSELoss()\n",
    "attack_optimizer = optim.Adam(attack_model.parameters(),lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# no defense attack on model\n",
    "# test_loss:  1.3502, test_acc:  61.5184\n",
    "# trainset_loss:  1.0334, trainset_acc:  67.9202\n",
    "# No_defense_20_epoch_2_prune_99_retrain_epoch_99\n",
    "\n",
    "best_acc= 0.0\n",
    "batch_size=128\n",
    "epochs = 100\n",
    "for epoch in range(0, epochs):\n",
    "#     adjust_learning_rate_attack(attack_optimizer, epoch)\n",
    "    \n",
    "    r= np.arange(len(train_classifier_data_tr_attack))\n",
    "    np.random.shuffle(r)\n",
    "    r1= np.arange(len(train_attack_data))\n",
    "    np.random.shuffle(r1)\n",
    "    r2 = r1[r]\n",
    "\n",
    "    train_classifier_data_tr_attack = train_classifier_data_tr_attack[r]\n",
    "    train_classifier_label_tr_attack = train_classifier_label_tr_attack[r]\n",
    "\n",
    "    tr_attack_data = train_attack_data[r2]\n",
    "    tr_attack_label = train_attack_label[r2]\n",
    "\n",
    "\n",
    "    r= np.arange(len(train_classifier_data_te_attack))\n",
    "    np.random.shuffle(r)\n",
    "    r1= np.arange(len(test_data))\n",
    "    np.random.shuffle(r1)\n",
    "    r2 = r1[r]\n",
    "\n",
    "    train_classifier_data_te_attack = train_classifier_data_te_attack[r]\n",
    "    train_classifier_label_te_attack = train_classifier_label_te_attack[r]\n",
    "\n",
    "    test_data_attack = test_data[r2]\n",
    "    test_label_attack = test_label[r2]\n",
    "\n",
    "    \n",
    "    train_classifier_data_tr_attack_tensor = torch.from_numpy(train_classifier_data_tr_attack).type(torch.FloatTensor)\n",
    "    train_classifier_label_tr_attack_tensor = torch.from_numpy(train_classifier_label_tr_attack).type(torch.LongTensor)\n",
    "\n",
    "    train_classifier_data_te_attack_tensor = torch.from_numpy(train_classifier_data_te_attack).type(torch.FloatTensor)\n",
    "    train_classifier_label_te_attack_tensor = torch.from_numpy(train_classifier_label_te_attack).type(torch.LongTensor)\n",
    "\n",
    "\n",
    "#     r= np.arange(len(train_attack_data))\n",
    "#     np.random.shuffle(r)\n",
    "\n",
    "#     train_attack_data = train_attack_data[r]\n",
    "#     train_attack_label = train_attack_label[r]\n",
    "\n",
    "    train_attack_data_tensor = torch.from_numpy(tr_attack_data).type(torch.FloatTensor)\n",
    "    train_attack_label_tensor = torch.from_numpy(tr_attack_label).type(torch.LongTensor)\n",
    "\n",
    "    test_data_tensor = torch.from_numpy(test_data_attack).type(torch.FloatTensor)\n",
    "    test_label_tensor = torch.from_numpy(test_label_attack).type(torch.LongTensor)\n",
    "    print('\\nEpoch: [%d | %d] , lr : %f'% (epoch + 1, epochs, state['lr']))\n",
    "\n",
    "\n",
    "    train_loss, train_acc = train_attack(train_classifier_data_tr_attack_tensor,train_classifier_label_tr_attack_tensor\n",
    "                                         ,train_attack_data_tensor,train_attack_label_tensor,net,attack_model,criterion,attack_criterion,optimizer,attack_optimizer,epoch,use_cuda)\n",
    "\n",
    "    print ('train acc',train_acc)\n",
    "    test_loss, test_acc = test_attack(train_classifier_data_te_attack_tensor,train_classifier_label_te_attack_tensor\n",
    "                                         ,test_data_tensor,test_label_tensor,net,attack_model,criterion,attack_criterion,optimizer,attack_optimizer,epoch,use_cuda)\n",
    "\n",
    "    is_best = test_acc>best_acc\n",
    "    \n",
    "    best_acc = max(test_acc, best_acc)\n",
    "    if is_best:\n",
    "        save_checkpoint({\n",
    "                    'epoch': epoch + 1,\n",
    "                    'state_dict': attack_model.state_dict(),\n",
    "                    'acc': test_acc,\n",
    "                    'best_acc': best_acc,\n",
    "                    'optimizer' : attack_model.state_dict(),\n",
    "                }, False, filename='No_defense_20_epoch_2_prune_99_retrain_epoch_99_longtrain_attack_epoch%d'%(epoch+1))\n",
    "    \n",
    "    \n",
    "    print ('test acc',test_acc,best_acc)\n",
    "\n",
    "print('Best classification acc:%.4f'%(final_test_acc))\n",
    "print('Best attack acc:%.4f'%(best_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# attack on model with no defense \n",
    "# No_defense_epoch_2\n",
    "# prune 85% acc: 61.1128\n",
    "best_acc= 0.0\n",
    "batch_size=128\n",
    "epochs = 50\n",
    "\n",
    "    if is_best:\n",
    "        save_checkpoint({\n",
    "                    'epoch': epoch + 1,\n",
    "                    'state_dict': attack_model.state_dict(),\n",
    "                    'acc': test_acc,\n",
    "                    'best_acc': best_acc,\n",
    "                    'optimizer' : attack_model.state_dict(),\n",
    "                }, False, filename='No_defense_epoch_2_prune_85_attack_epoch%d'%(epoch+1))\n",
    "    \n",
    "    \n",
    "    print ('test acc',test_acc,best_acc)\n",
    "\n",
    "print('Best classification acc:%.4f'%(final_test_acc))\n",
    "print('Best attack acc:%.4f'%(best_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def _quantize_layer(weight, bits=8):\n",
    "    \"\"\"\n",
    "    :param weight: A numpy array of any shape.\n",
    "    :param bits: quantization bits for weight sharing.\n",
    "    :return quantized weights and centriods.\n",
    "    \"\"\"\n",
    "    shape = weight.shape\n",
    "    min = np.min(weight)\n",
    "    max = np.max(weight)\n",
    "    # Get zero maskings\n",
    "    zero_masking = (weight == 0)\n",
    "    # Consider the 0 parameters, we have to reserve a centriod for them.\n",
    "    num_clusters = 2 ** bits + 1\n",
    "    kmeans_init = np.linspace(min, max, num_clusters)\n",
    "    kmeans = KMeans(n_clusters=num_clusters, init=kmeans_init.reshape(-1, 1), n_init=1,\n",
    "                    precompute_distances=True, algorithm='full')\n",
    "    kmeans.fit(weight.reshape(-1, 1))\n",
    "    new_weight = kmeans.cluster_centers_[kmeans.labels_].reshape(shape)\n",
    "    # Recover the zero masking\n",
    "    new_weight[zero_masking] = 0.\n",
    "    # Now exclude the zero center\n",
    "    centers = kmeans.cluster_centers_.copy()\n",
    "    zero_center_idx = np.argmin(np.abs(centers))\n",
    "    centers_ = []\n",
    "    for i in range(len(centers)):\n",
    "        if i != zero_center_idx:\n",
    "            centers_.append(centers[i])\n",
    "    centers_ = np.array(centers_)\n",
    "    return new_weight, centers_\n",
    "\n",
    "def quantize_whole_model(net, bits=8):\n",
    "    \"\"\"\n",
    "    Quantize the whole model.\n",
    "    :param net: (object) network model.\n",
    "    :return: centroids of each weight layer, used in the quantization codebook.\n",
    "    \"\"\"\n",
    "    cluster_centers = []\n",
    "    assert isinstance(net, nn.Module)\n",
    "    layer_ind = 0\n",
    "    for n, m in net.named_modules():\n",
    "        if isinstance(m, PrunedConv):\n",
    "            weight = m.conv.weight.data.cpu().numpy()\n",
    "            weight, centers = _quantize_layer(weight, bits=bits)\n",
    "            centers = centers.flatten()\n",
    "            cluster_centers.append(centers)\n",
    "            m.conv.weight.data = torch.from_numpy(weight).to(device)\n",
    "            layer_ind += 1\n",
    "            print(\"Complete %d layers quantization...\" %layer_ind)\n",
    "        elif isinstance(m, PruneLinear):\n",
    "            weight = m.linear.weight.data.cpu().numpy()\n",
    "            weight, centers = _quantize_layer(weight, bits=bits)\n",
    "            centers = centers.flatten()\n",
    "            cluster_centers.append(centers)\n",
    "            m.linear.weight.data = torch.from_numpy(weight).to(device)\n",
    "            layer_ind += 1\n",
    "            print(\"Complete %d layers quantization...\" %layer_ind)\n",
    "    return np.array(cluster_centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# from quantize import quantize_whole_model\n",
    "centers = quantize_whole_model(net, bits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print(\"-----Summary After fine tune quantization-----\")\n",
    "summary(net)\n",
    "print(\"-------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "test_loss, final_test_acc = test(torch.from_numpy(test_data).type(torch.FloatTensor) ,torch.from_numpy(test_label).type(torch.LongTensor), net, criterion, epoch, use_cuda)\n",
    "\n",
    "print ('test_loss: {test_loss: .4f}, test_acc: {test_acc: .4f}'.format(test_loss=test_loss, test_acc=final_test_acc))\n",
    "\n",
    "trainset_loss, trainset_acc = test(torch.from_numpy(train_classifier_data).type(torch.FloatTensor) ,torch.from_numpy(train_classifier_label).type(torch.LongTensor), net, criterion, epoch, use_cuda)\n",
    "\n",
    "print ('trainset_loss: {trainset_loss: .4f}, trainset_acc: {trainset_acc: .4f}'.format(trainset_loss=trainset_loss, trainset_acc=trainset_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "save_checkpoint({\n",
    "                    'epoch': epoch + 1,\n",
    "                    'state_dict': net.state_dict(),\n",
    "                    'acc': test_acc,\n",
    "                    'best_acc': best_acc,\n",
    "                    'optimizer' : optimizer.state_dict(),\n",
    "                }, False, filename='Small_No_defense_20_epoch_12_prune_99_4layer_retrain_epoch_139_quantization_5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def test_loader(testloader, model, criterion, epoch, use_cuda):\n",
    "    global best_acc\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    top5 = AverageMeter()\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "    end = time.time()\n",
    "    for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "        if use_cuda:\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "        inputs, targets = torch.autograd.Variable(inputs, volatile=True), torch.autograd.Variable(targets)\n",
    "\n",
    "        # compute output\n",
    "        outputs, y1, y3, y4, y5 = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        prec1, prec5 = accuracy(outputs.data, targets.data, topk=(1, 5))\n",
    "#         losses.update(loss.data[0], inputs.size(0))\n",
    "        losses.update(loss.data, inputs.size(0))\n",
    "        top1.update(prec1, inputs.size(0))\n",
    "        top5.update(prec5, inputs.size(0))\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        # plot progress\n",
    "        if batch_idx % 20==0:\n",
    "            \n",
    "            print ('({batch}/{size}) Data: {data:.3f}s | Batch: {bt:.3f}s | Loss: {loss:.4f} | top1: {top1: .4f} | top5: {top5: .4f}'.format(\n",
    "                        batch=batch_idx + 1,\n",
    "                        size=len(testloader),\n",
    "                        data=data_time.avg,\n",
    "                        bt=batch_time.avg,\n",
    "                        loss=losses.avg,\n",
    "                        top1=top1.avg,\n",
    "                        top5=top5.avg,\n",
    "                        ))\n",
    "    return (losses.avg, top1.avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def testloader_by_class(testloader, model, criterion, epoch, use_cuda):\n",
    "    global best_acc\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    top5 = AverageMeter()\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "    end = time.time()\n",
    "    class_count = np.zeros(100)\n",
    "    class_correct = np.zeros(100)\n",
    "    for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "        if use_cuda:\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "        inputs, targets = torch.autograd.Variable(inputs, volatile=True), torch.autograd.Variable(targets)\n",
    "\n",
    "        # compute output\n",
    "        outputs, y1, y3, y4, y5 = model(inputs)\n",
    "#         outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        prec1, prec5 = accuracy(outputs.data, targets.data, topk=(1, 5))\n",
    "        _, pred = outputs.topk(1, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(targets.view(1, -1).expand_as(pred))\n",
    "        correct = correct.data.cpu().numpy()\n",
    "        targets = targets.data.cpu().numpy()\n",
    "        for i in range(len(targets)):\n",
    "            class_count[targets[i]] += 1\n",
    "            class_correct[targets[i]] += correct[0,i]\n",
    "#         losses.update(loss.data[0], inputs.size(0))\n",
    "        losses.update(loss.data, inputs.size(0))\n",
    "        top1.update(prec1, inputs.size(0))\n",
    "        top5.update(prec5, inputs.size(0))\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        # plot progress\n",
    "        if batch_idx % 20==0:\n",
    "            \n",
    "            print ('({batch}/{size}) Data: {data:.3f}s | Batch: {bt:.3f}s | Loss: {loss:.4f} | top1: {top1: .4f} | top5: {top5: .4f}'.format(\n",
    "                        batch=batch_idx + 1,\n",
    "                        size=len(testloader),\n",
    "                        data=data_time.avg,\n",
    "                        bt=batch_time.avg,\n",
    "                        loss=losses.avg,\n",
    "                        top1=top1.avg,\n",
    "                        top5=top5.avg,\n",
    "                        ))\n",
    "    return (losses.avg, top1.avg, class_count, class_correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class black_box_benchmarks(object):\n",
    "    \n",
    "    def __init__(self, shadow_train_performance, shadow_test_performance, \n",
    "                 target_train_performance, target_test_performance, num_classes):\n",
    "        '''\n",
    "        each input contains both model predictions (shape: num_data*num_classes) and ground-truth labels. \n",
    "        '''\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        self.s_tr_outputs, self.s_tr_labels = shadow_train_performance\n",
    "        self.s_te_outputs, self.s_te_labels = shadow_test_performance\n",
    "        self.t_tr_outputs, self.t_tr_labels = target_train_performance\n",
    "        self.t_te_outputs, self.t_te_labels = target_test_performance\n",
    "        \n",
    "        self.s_tr_corr = (np.argmax(self.s_tr_outputs, axis=1)==self.s_tr_labels).astype(int)\n",
    "        self.s_te_corr = (np.argmax(self.s_te_outputs, axis=1)==self.s_te_labels).astype(int)\n",
    "        self.t_tr_corr = (np.argmax(self.t_tr_outputs, axis=1)==self.t_tr_labels).astype(int)\n",
    "        self.t_te_corr = (np.argmax(self.t_te_outputs, axis=1)==self.t_te_labels).astype(int)\n",
    "        \n",
    "        self.s_tr_conf = np.array([self.s_tr_outputs[i, self.s_tr_labels[i]] for i in range(len(self.s_tr_labels))])\n",
    "        self.s_te_conf = np.array([self.s_te_outputs[i, self.s_te_labels[i]] for i in range(len(self.s_te_labels))])\n",
    "        self.t_tr_conf = np.array([self.t_tr_outputs[i, self.t_tr_labels[i]] for i in range(len(self.t_tr_labels))])\n",
    "        self.t_te_conf = np.array([self.t_te_outputs[i, self.t_te_labels[i]] for i in range(len(self.t_te_labels))])\n",
    "        \n",
    "        self.s_tr_entr = self._entr_comp(self.s_tr_outputs)\n",
    "        self.s_te_entr = self._entr_comp(self.s_te_outputs)\n",
    "        self.t_tr_entr = self._entr_comp(self.t_tr_outputs)\n",
    "        self.t_te_entr = self._entr_comp(self.t_te_outputs)\n",
    "        \n",
    "        self.s_tr_m_entr = self._m_entr_comp(self.s_tr_outputs, self.s_tr_labels)\n",
    "        self.s_te_m_entr = self._m_entr_comp(self.s_te_outputs, self.s_te_labels)\n",
    "        self.t_tr_m_entr = self._m_entr_comp(self.t_tr_outputs, self.t_tr_labels)\n",
    "        self.t_te_m_entr = self._m_entr_comp(self.t_te_outputs, self.t_te_labels)\n",
    "        \n",
    "    \n",
    "    def _log_value(self, probs, small_value=1e-30):\n",
    "        return -np.log(np.maximum(probs, small_value))\n",
    "    \n",
    "    def _entr_comp(self, probs):\n",
    "        return np.sum(np.multiply(probs, self._log_value(probs)),axis=1)\n",
    "    \n",
    "    def _m_entr_comp(self, probs, true_labels):\n",
    "        log_probs = self._log_value(probs)\n",
    "        reverse_probs = 1-probs\n",
    "        log_reverse_probs = self._log_value(reverse_probs)\n",
    "        modified_probs = np.copy(probs)\n",
    "        modified_probs[range(true_labels.size), true_labels] = reverse_probs[range(true_labels.size), true_labels]\n",
    "        modified_log_probs = np.copy(log_reverse_probs)\n",
    "        modified_log_probs[range(true_labels.size), true_labels] = log_probs[range(true_labels.size), true_labels]\n",
    "        return np.sum(np.multiply(modified_probs, modified_log_probs),axis=1)\n",
    "    \n",
    "    def _thre_setting(self, tr_values, te_values):\n",
    "        value_list = np.concatenate((tr_values, te_values))\n",
    "        thre, max_acc = 0, 0\n",
    "        for value in value_list:\n",
    "            tr_ratio = np.sum(tr_values>=value)/(len(tr_values)+0.0)\n",
    "            te_ratio = np.sum(te_values<value)/(len(te_values)+0.0)\n",
    "            acc = 0.5*(tr_ratio + te_ratio)\n",
    "            if acc > max_acc:\n",
    "                thre, max_acc = value, acc\n",
    "        return thre\n",
    "    \n",
    "    def _mem_inf_via_corr(self):\n",
    "        # perform membership inference attack based on whether the input is correctly classified or not\n",
    "        t_tr_acc = np.sum(self.t_tr_corr)/(len(self.t_tr_corr)+0.0)\n",
    "        t_te_acc = np.sum(self.t_te_corr)/(len(self.t_te_corr)+0.0)\n",
    "        mem_inf_acc = 0.5*(t_tr_acc + 1 - t_te_acc)\n",
    "        print('With train acc {acc2:.3f} and test acc {acc3:.3f}\\nFor membership inference attack via correctness, the attack acc is {acc1:.3f} '.format(acc1=mem_inf_acc, acc2=t_tr_acc, acc3=t_te_acc) )\n",
    "        return\n",
    "    \n",
    "    def _mem_inf_thre(self, v_name, s_tr_values, s_te_values, t_tr_values, t_te_values):\n",
    "        # perform membership inference attack by thresholding feature values: the feature can be prediction confidence,\n",
    "        # (negative) prediction entropy, and (negative) modified entropy\n",
    "        t_tr_mem, t_te_non_mem = 0, 0\n",
    "        for num in range(self.num_classes):\n",
    "            thre = self._thre_setting(s_tr_values[self.s_tr_labels==num], s_te_values[self.s_te_labels==num])\n",
    "            t_tr_mem += np.sum(t_tr_values[self.t_tr_labels==num]>=thre)\n",
    "            t_te_non_mem += np.sum(t_te_values[self.t_te_labels==num]<thre)\n",
    "        mem_inf_acc = 0.5*(t_tr_mem/(len(self.t_tr_labels)+0.0) + t_te_non_mem/(len(self.t_te_labels)+0.0))\n",
    "        print('For membership inference attack via {n}, the attack acc is {acc:.3f}'.format(n=v_name,acc=mem_inf_acc))\n",
    "        return\n",
    "    \n",
    "\n",
    "    \n",
    "    def _mem_inf_benchmarks(self, all_methods=True, benchmark_methods=[]):\n",
    "        if (all_methods) or ('correctness' in benchmark_methods):\n",
    "            self._mem_inf_via_corr()\n",
    "        if (all_methods) or ('confidence' in benchmark_methods):\n",
    "            self._mem_inf_thre('confidence', self.s_tr_conf, self.s_te_conf, self.t_tr_conf, self.t_te_conf)\n",
    "        if (all_methods) or ('entropy' in benchmark_methods):\n",
    "            self._mem_inf_thre('entropy', -self.s_tr_entr, -self.s_te_entr, -self.t_tr_entr, -self.t_te_entr)\n",
    "        if (all_methods) or ('modified entropy' in benchmark_methods):\n",
    "            self._mem_inf_thre('modified entropy', -self.s_tr_m_entr, -self.s_te_m_entr, -self.t_tr_m_entr, -self.t_te_m_entr)\n",
    "\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def tensor_data_create(features, labels):\n",
    "    tensor_x = torch.stack([torch.FloatTensor(i) for i in features]) # transform to torch tensors\n",
    "    tensor_y = torch.stack([torch.LongTensor([i]) for i in labels])[:,0]\n",
    "    dataset = torch.utils.data.TensorDataset(tensor_x,tensor_y)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "train_datax = train_classifier_data\n",
    "test_datax = test_data\n",
    "\n",
    "train_labelx = train_classifier_label\n",
    "test_labelx = test_label\n",
    "\n",
    "print('train_classifier_data: ', len(train_labelx))\n",
    "print('test_data: ', len(test_labelx))\n",
    "\n",
    "np.random.seed(100)\n",
    "train_len = train_datax.shape[0]\n",
    "r = np.arange(train_len)\n",
    "np.random.shuffle(r)\n",
    "shadow_indices = r[:train_len//2]\n",
    "target_indices = r[train_len//2:]\n",
    "\n",
    "shadow_train_data, shadow_train_label = train_datax[shadow_indices], train_labelx[shadow_indices]\n",
    "target_train_data, target_train_label = train_datax[target_indices], train_labelx[target_indices]\n",
    "\n",
    "test_len = 1*train_len\n",
    "r = np.arange(test_len)\n",
    "np.random.shuffle(r)\n",
    "shadow_indices = r[:test_len//2]\n",
    "target_indices = r[test_len//2:]\n",
    "\n",
    "shadow_test_data, shadow_test_label = test_datax[shadow_indices], test_labelx[shadow_indices]\n",
    "target_test_data, target_test_label = test_datax[target_indices], test_labelx[target_indices]\n",
    "\n",
    "print('shadow_train_data: ', len(shadow_train_data))\n",
    "print('shadow_test_data: ', len(shadow_test_data))\n",
    "\n",
    "\n",
    "shadow_train = tensor_data_create(shadow_train_data, shadow_train_label)\n",
    "shadow_train_loader = torch.utils.data.DataLoader(shadow_train, batch_size=batch_size, shuffle=True, num_workers=1)\n",
    "\n",
    "shadow_test = tensor_data_create(shadow_test_data, shadow_test_label)\n",
    "shadow_test_loader = torch.utils.data.DataLoader(shadow_test, batch_size=batch_size, shuffle=True, num_workers=1)\n",
    "\n",
    "target_train = tensor_data_create(target_train_data, target_train_label)\n",
    "target_train_loader = torch.utils.data.DataLoader(target_train, batch_size=batch_size, shuffle=True, num_workers=1)\n",
    "\n",
    "target_test = tensor_data_create(target_test_data, target_test_label)\n",
    "target_test_loader = torch.utils.data.DataLoader(target_test, batch_size=batch_size, shuffle=True, num_workers=1)\n",
    "print('Data loading finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# load modified entropy attack\n",
    "test_loss, final_test_acc = test_loader(shadow_train_loader, net, criterion, epoch, use_cuda)\n",
    "print ('Classification accuracy: %.2f'%(final_test_acc))\n",
    "\n",
    "test_loss, final_test_acc = test_loader(shadow_test_loader, net, criterion, epoch, use_cuda)\n",
    "print ('Classification accuracy: %.2f'%(final_test_acc))\n",
    "\n",
    "test_loss, final_test_acc = test_loader(target_train_loader, net, criterion, epoch, use_cuda)\n",
    "print ('Classification accuracy: %.2f'%(final_test_acc))\n",
    "\n",
    "test_loss, final_test_acc = test_loader(target_test_loader, net, criterion, epoch, use_cuda)\n",
    "print ('Classification accuracy: %.2f'%(final_test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "test_loss, final_test_acc, s_tr_class, s_tr_correct = testloader_by_class(shadow_train_loader, net, criterion, epoch, use_cuda)\n",
    "print ('Classification accuracy: %.2f'%(final_test_acc))\n",
    "\n",
    "test_loss, final_test_acc, t_tr_class, t_tr_correct = testloader_by_class(target_train_loader, net, criterion, epoch, use_cuda)\n",
    "print ('Classification accuracy: %.2f'%(final_test_acc))\n",
    "\n",
    "test_loss, final_test_acc, s_te_class, s_te_correct = testloader_by_class(shadow_test_loader, net, criterion, epoch, use_cuda)\n",
    "print ('Classification accuracy: %.2f'%(final_test_acc))\n",
    "\n",
    "test_loss, final_test_acc, t_te_class, t_te_correct = testloader_by_class(target_test_loader, net, criterion, epoch, use_cuda)\n",
    "print ('Classification accuracy: %.2f'%(final_test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def softmax_by_row(logits, T = 1.0):\n",
    "    mx = np.max(logits, axis=-1, keepdims=True)\n",
    "    exp = np.exp((logits - mx)/T)\n",
    "    denominator = np.sum(exp, axis=-1, keepdims=True)\n",
    "    return exp/denominator\n",
    "\n",
    "\n",
    "\n",
    "def _model_predictions(model, dataloader):\n",
    "    return_outputs, return_labels = [], []\n",
    "\n",
    "    for (inputs, labels) in dataloader:\n",
    "        return_labels.append(labels.numpy())\n",
    "        outputs, y1, y3, y4, y5 = model.forward(inputs.cuda()) \n",
    "        return_outputs.append( softmax_by_row(outputs.data.cpu().numpy()) )\n",
    "    return_outputs = np.concatenate(return_outputs)\n",
    "    return_labels = np.concatenate(return_labels)\n",
    "    return (return_outputs, return_labels)\n",
    "\n",
    "shadow_train_performance = _model_predictions(net, shadow_train_loader)\n",
    "shadow_test_performance = _model_predictions(net, shadow_test_loader)\n",
    "\n",
    "target_train_performance = _model_predictions(net, target_train_loader)\n",
    "target_test_performance = _model_predictions(net, target_test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print('Perform membership inference attacks!!!')\n",
    "MIA = black_box_benchmarks(shadow_train_performance,shadow_test_performance,\n",
    "                     target_train_performance,target_test_performance,num_classes=100)\n",
    "res = MIA._mem_inf_benchmarks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "risk_score = calculate_risk_score(MIA.s_tr_m_entr, MIA.s_te_m_entr, MIA.s_tr_labels, MIA.s_te_labels, MIA.t_tr_m_entr, MIA.t_tr_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for i in range(len(risk_score)):\n",
    "#     print(risk_score[i])\n",
    "    if risk_score[i] is None:\n",
    "        risk_score[i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "x = np.sort(risk_score)\n",
    "y = range(risk_score.size)\n",
    "plt.plot(x,y, label = 'risk_score')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.hist(risk_score, bins=20, label = 'risk_score')\n",
    "plt.legend()\n",
    "plt.show\n",
    "\n",
    "\n",
    "np.sum(risk_score<=0.5)\n",
    "count = []\n",
    "for i in range(10):\n",
    "    tmp = np.sum(risk_score>(0.1*(i+1)))\n",
    "    count.append(tmp)\n",
    "    print(0.1*i+0.1, tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "fig = plt.figure(figsize=(20,15))\n",
    "# plt.ylim(0, 0.7)\n",
    "plt.plot(np.sort(res.s_tr_m_entr),range(risk_score.size), label = 's_tr_m_entr')\n",
    "plt.plot(np.sort(res.s_te_m_entr),range(risk_score.size),  label = 's_te_m_entr')\n",
    "plt.plot(np.sort(res.t_tr_m_entr),range(risk_score.size),  label = 't_tr_m_entr')\n",
    "plt.plot(np.sort(res.t_te_m_entr),range(risk_score.size),  label = 't_te_m_entr')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# load class wise \n",
    "\n",
    "self = res\n",
    "np.array([self.s_tr_outputs[i, self.s_tr_labels[i]] for i in range(len(self.s_tr_labels))])\n",
    "\n",
    "t_tr_mem, t_te_non_mem = 0, 0\n",
    "class_mem_res = []\n",
    "class_nonmem_res = []\n",
    "class_attack_acc = []\n",
    "class_mem_num = []\n",
    "class_nonmem_num = []\n",
    "conf_thre = []\n",
    "s_tr_values = self.s_tr_conf\n",
    "s_te_values = self.s_te_conf\n",
    "t_tr_values = self.t_tr_conf\n",
    "t_te_values = self.t_te_conf\n",
    "v_name = 'confidence'\n",
    "for num in range(self.num_classes):\n",
    "    thre = self._thre_setting(s_tr_values[self.s_tr_labels==num], s_te_values[self.s_te_labels==num])\n",
    "    conf_thre.append(thre)\n",
    "    class_mem = np.sum(t_tr_values[self.t_tr_labels==num]>=thre)\n",
    "    class_nonmem = np.sum(t_te_values[self.t_te_labels==num]<thre)\n",
    "    class_mem_res.append(class_mem)\n",
    "    class_nonmem_res.append(class_nonmem)\n",
    "    t_tr_mem += class_mem\n",
    "    t_te_non_mem += class_nonmem\n",
    "    class_mem_num.append(np.sum(self.t_tr_labels==num))\n",
    "    class_nonmem_num.append(np.sum(self.t_te_labels==num))\n",
    "    class_attack_acc.append( 0.5*(class_mem/(np.sum(self.t_tr_labels==num)+0.0) + class_nonmem/(np.sum(self.t_te_labels==num)+0.0)) )\n",
    "    \n",
    "mem_inf_acc = 0.5*(t_tr_mem/(len(self.t_tr_labels)+0.0) + t_te_non_mem/(len(self.t_te_labels)+0.0))\n",
    "print('For membership inference attack via {n}, the attack acc is {acc:.3f}'.format(n=v_name,acc=mem_inf_acc))\n",
    "\n",
    "class_mem_res = np.asarray(class_mem_res)\n",
    "class_nonmem_res = np.asarray(class_nonmem_res)\n",
    "class_attack_acc = np.asarray(class_attack_acc)\n",
    "class_mem_num = np.asarray(class_mem_num)\n",
    "class_nonmem_num = np.asarray(class_nonmem_num)\n",
    "conf_thre = np.asarray(conf_thre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "trainset_correct = s_tr_correct + t_tr_correct\n",
    "tr_correct_index = np.argsort(trainset_correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "fig = plt.figure(figsize=(20,15))\n",
    "# plt.ylim(0, 0.7)\n",
    "plt.plot(np.sort(res.s_tr_conf),range(risk_score.size), label = 's_tr_m_entr')\n",
    "plt.plot(np.sort(res.s_te_conf),range(risk_score.size),  label = 's_te_m_entr')\n",
    "plt.plot(np.sort(res.t_tr_conf),range(risk_score.size),  label = 't_tr_m_entr')\n",
    "plt.plot(np.sort(res.t_te_conf),range(risk_score.size),  label = 't_te_m_entr')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "t_tr_acc =  t_tr_correct/ t_tr_class\n",
    "# print(t_tr_acc )\n",
    "t_te_acc = t_te_correct/t_te_class\n",
    "# print(t_te_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "fig = plt.figure(figsize=(15,10))\n",
    "\n",
    "plt.plot(np.sort(conf_thre), label = 'conf_thre')\n",
    "\n",
    "# plt.plot(class_attack_acc, label = 'class_attack_acc')\n",
    "plt.legend()\n",
    "plt.show\n",
    "\n",
    "conf_thre[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "t_acc_gap = t_tr_acc - t_te_acc\n",
    "t_gap_index = np.argsort(t_acc_gap)\n",
    "\n",
    "fig = plt.figure(figsize=(15,10))\n",
    "\n",
    "# plt.ylim(0, 0.7)\n",
    "# plt.plot(class_mem_num, label = 'class_mem')\n",
    "# plt.plot(class_nonmem_num,  label = 'class_nonmem')\n",
    "# plt.plot(train_acc[gap_index], label = 'train_acc')\n",
    "# plt.plot(test_acc[gap_index],  label = 'test_acc')\n",
    "# plt.plot(t_tr_acc[t_gap_index], label = 't_tr_acc')\n",
    "# plt.plot(t_te_acc[t_gap_index], label = 't_te_acc')\n",
    "plt.plot(class_attack_acc[t_gap_index], label = 'class_attack_acc')\n",
    "plt.plot(t_acc_gap[t_gap_index],  label = 't_acc_gap')\n",
    "plt.legend()\n",
    "\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# load class wise  m_entr_thre\n",
    "\n",
    "self = res\n",
    "# np.array([self.s_tr_outputs[i, self.s_tr_labels[i]] for i in range(len(self.s_tr_labels))])\n",
    "\n",
    "t_tr_mem, t_te_non_mem = 0, 0\n",
    "class_mem_res = []\n",
    "class_nonmem_res = []\n",
    "class_attack_acc = []\n",
    "class_mem_num = []\n",
    "class_nonmem_num = []\n",
    "m_entr_thre = []\n",
    "s_tr_values = -self.s_tr_m_entr\n",
    "s_te_values = -self.s_te_m_entr\n",
    "t_tr_values = -self.t_tr_m_entr\n",
    "t_te_values = -self.t_te_m_entr\n",
    "v_name = 'modified entropy'\n",
    "for num in range(self.num_classes):\n",
    "    thre = self._thre_setting(s_tr_values[self.s_tr_labels==num], s_te_values[self.s_te_labels==num])\n",
    "#     thre = -2\n",
    "    m_entr_thre.append(thre)\n",
    "    class_mem = np.sum(t_tr_values[self.t_tr_labels==num]>=thre)\n",
    "    class_nonmem = np.sum(t_te_values[self.t_te_labels==num]<thre)\n",
    "    class_mem_res.append(class_mem)\n",
    "    class_nonmem_res.append(class_nonmem)\n",
    "    t_tr_mem += class_mem\n",
    "    t_te_non_mem += class_nonmem\n",
    "    class_mem_num.append(np.sum(self.t_tr_labels==num))\n",
    "    class_nonmem_num.append(np.sum(self.t_te_labels==num))\n",
    "    class_attack_acc.append( 0.5*(class_mem/(np.sum(self.t_tr_labels==num)+0.0) + class_nonmem/(np.sum(self.t_te_labels==num)+0.0)) )\n",
    "    \n",
    "mem_inf_acc = 0.5*(t_tr_mem/(len(self.t_tr_labels)+0.0) + t_te_non_mem/(len(self.t_te_labels)+0.0))\n",
    "print('For membership inference attack via {n}, the attack acc is {acc:.3f}'.format(n=v_name,acc=mem_inf_acc))\n",
    "\n",
    "class_mem_res = np.asarray(class_mem_res)\n",
    "class_nonmem_res = np.asarray(class_nonmem_res)\n",
    "class_attack_acc = np.asarray(class_attack_acc)\n",
    "class_mem_num = np.asarray(class_mem_num)\n",
    "class_nonmem_num = np.asarray(class_nonmem_num)\n",
    "m_entr_thre = np.asarray(m_entr_thre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "fig = plt.figure(figsize=(20,15))\n",
    "# plt.ylim(0, 0.7)\n",
    "plt.plot(np.sort(-res.s_tr_m_entr),range(risk_score.size), label = 's_tr_m_entr')\n",
    "plt.plot(np.sort(-res.s_te_m_entr),range(risk_score.size),  label = 's_te_m_entr')\n",
    "plt.plot(np.sort(-res.t_tr_m_entr),range(risk_score.size),  label = 't_tr_m_entr')\n",
    "plt.plot(np.sort(-res.t_te_m_entr),range(risk_score.size),  label = 't_te_m_entr')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "t_tr_acc =  t_tr_correct/ t_tr_class\n",
    "# print(t_tr_acc )\n",
    "t_te_acc = t_te_correct/t_te_class\n",
    "# print(t_te_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "m_entr_index = np.argsort(m_entr_thre)\n",
    "\n",
    "fig = plt.figure(figsize=(15,10))\n",
    "\n",
    "plt.plot(m_entr_thre[m_entr_index], label = 'm_entr_thre')\n",
    "\n",
    "# plt.plot(class_attack_acc, label = 'class_attack_acc')\n",
    "plt.legend()\n",
    "plt.show\n",
    "\n",
    "m_entr_thre[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "t_acc_gap = t_tr_acc - t_te_acc\n",
    "t_gap_index = np.argsort(t_acc_gap)\n",
    "\n",
    "fig = plt.figure(figsize=(15,10))\n",
    "\n",
    "# plt.ylim(0, 0.7)\n",
    "# plt.plot(class_mem_num, label = 'class_mem')\n",
    "# plt.plot(class_nonmem_num,  label = 'class_nonmem')\n",
    "# plt.plot(train_acc[gap_index], label = 'train_acc')\n",
    "# plt.plot(test_acc[gap_index],  label = 'test_acc')\n",
    "# plt.plot(t_tr_acc[t_gap_index], label = 't_tr_acc')\n",
    "# plt.plot(t_te_acc[t_gap_index], label = 't_te_acc')\n",
    "plt.plot(class_attack_acc[t_gap_index], label = 'class_attack_acc')\n",
    "plt.plot(t_acc_gap[t_gap_index],  label = 't_acc_gap')\n",
    "# plt.plot(class_attack_acc[m_entr_index], label = 'class_attack_acc')\n",
    "# plt.plot(t_acc_gap[m_entr_index],  label = 't_acc_gap')\n",
    "plt.legend()\n",
    "\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "class_attack_acc_index = np.argsort(class_attack_acc)\n",
    "\n",
    "fig = plt.figure(figsize=(15,10))\n",
    "\n",
    "# plt.ylim(0, 0.7)\n",
    "# plt.plot(class_mem_num, label = 'class_mem')\n",
    "# plt.plot(class_nonmem_num,  label = 'class_nonmem')\n",
    "# plt.plot(train_acc[gap_index], label = 'train_acc')\n",
    "# plt.plot(test_acc[gap_index],  label = 'test_acc')\n",
    "# plt.plot(t_tr_acc[t_gap_index], label = 't_tr_acc')\n",
    "# plt.plot(t_te_acc[t_gap_index], label = 't_te_acc')\n",
    "plt.plot(class_attack_acc[class_attack_acc_index], label = 'class_attack_acc')\n",
    "plt.plot(t_acc_gap[class_attack_acc_index],  label = 't_acc_gap')\n",
    "# plt.plot(class_attack_acc[m_entr_index], label = 'class_attack_acc')\n",
    "# plt.plot(t_acc_gap[m_entr_index],  label = 't_acc_gap')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "encoding": "# coding: utf-8",
   "executable": "/usr/bin/env python",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
